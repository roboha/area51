{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np #matrix math\n",
    "import math\n",
    "import tensorflow as tf #machine learning\n",
    "import matplotlib.pyplot as plt #plotting\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_channels = 1\n",
    "len_edge = 28\n",
    "bs = 32\n",
    "n_filters = [1, 16, 16]\n",
    "h_dim = 133\n",
    "latent_dim = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape, name):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial, name=name)\n",
    "\n",
    "def bias_variable(shape, name):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial, name=name)\n",
    "    \n",
    "def fc_layer(inp, channels_in, channels_out, name='fc'):\n",
    "    with tf.name_scope(name):\n",
    "        w = tf.Variable(tf.zeros([channels_in, channels_out]), name='W')\n",
    "        b = tf.Variable(tf.zeros([channels_out]), name='B')\n",
    "        return tf.nn.relu(tf.matmul(inp, w) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'reconstructed_images:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use TensorBoard to visualize: this code fails to create meaningful latent variables\n",
    "#(within a batch, each looks the same), and therefore also fails at reconstruction.\n",
    "#Both log-likelihood error and KL divergence appear to develop \"normally\", yet KL drops to 0 very quickly?\n",
    "\n",
    "with tf.name_scope('Input'):\n",
    "    X = tf.placeholder(tf.float32, shape=([None, len_edge, len_edge, num_channels]))#bs\n",
    "    tf.summary.image('input_images', X, max_outputs=5)\n",
    "\n",
    "cur_input = X\n",
    "\n",
    "Ws = []    \n",
    "shapes = []\n",
    "\n",
    "for l, n_out in enumerate(n_filters[1:]):\n",
    "    n_input = cur_input.get_shape().as_list()[3]\n",
    "    shapes.append(cur_input.get_shape().as_list())\n",
    "    with tf.name_scope('conv_indecon_' + str(l)):\n",
    "        W = tf.Variable(tf.random_uniform([3, 3, n_input, n_out], -1.0/math.sqrt(n_input), 1.0/math.sqrt(n_input)), name='weights')\n",
    "        b = tf.Variable(tf.zeros([n_out]), name='bias')\n",
    "        Ws.append(W)\n",
    "        conv = tf.nn.conv2d(cur_input, W, strides=[1, 2, 2, 1], padding='SAME')\n",
    "        act = tf.nn.sigmoid(conv+b)#tf.nn.relu(conv,b)    \n",
    "    cur_input = act\n",
    "\n",
    "with tf.name_scope('Dense'):\n",
    "    with tf.name_scope('Fully_Encode'):\n",
    "        flattened = tf.reshape(cur_input, [-1, 7 * 7 * n_filters[-1]])# ...\n",
    "        \n",
    "        W_enc = weight_variable([7 * 7 * n_filters[-1], h_dim], 'W_enc')\n",
    "        b_enc = bias_variable([h_dim], 'b_enc')        \n",
    "        full1 = tf.nn.sigmoid(tf.matmul(flattened, W_enc) + b_enc)\n",
    "#        full1 = fc_layer(flattened, 7 * 7 * n_filters[-1], h_dim, 'fc1')\n",
    "    with tf.name_scope('Mu'):\n",
    "        W_mu = weight_variable([h_dim, latent_dim], 'W_mu')\n",
    "        b_mu = bias_variable([latent_dim], 'b_mu')\n",
    "        mu = tf.matmul(full1, W_mu) + b_mu\n",
    "    with tf.name_scope('Logstd'):\n",
    "        W_logstd = weight_variable([h_dim, latent_dim], 'W_logstd')\n",
    "        b_logstd = bias_variable([latent_dim], 'b_logstd')\n",
    "        logstd = tf.matmul(full1, W_logstd) + b_logstd\n",
    "    with tf.name_scope('VAE_final'):\n",
    "        noise = tf.random_normal([1, latent_dim])\n",
    "        z = mu + tf.multiply(noise, tf.exp(.5*logstd))\n",
    "    with tf.name_scope('Fully_Decode'):\n",
    "        \n",
    "        W_dec1 = weight_variable([latent_dim, h_dim], 'W_dec1')\n",
    "        b_dec1 = bias_variable([h_dim], 'b_dec1')\n",
    "        \n",
    "        full2 = tf.nn.sigmoid(tf.matmul(z, W_dec1) + b_dec1)\n",
    "        \n",
    "        W_dec2 = weight_variable([h_dim, 7 * 7 * n_filters[-1]], 'W_dec2')\n",
    "        b_dec2 = bias_variable([7*7*n_filters[-1]], 'b_dec2')\n",
    "        \n",
    "        full3 = tf.nn.sigmoid(tf.matmul(full2, W_dec2) + b_dec2)\n",
    "#        full2 = fc_layer(z, latent_dim, h_dim, 'fc2')\n",
    "#        full3 = fc_layer(full2, h_dim, 7 * 7 * n_filters[-1], 'fc3')\n",
    "        reshaped = tf.reshape(full3, [-1, 7, 7, n_filters[-1]])\n",
    "        \n",
    "z_visual = tf.reshape(z, [-1, 4, 4, 1])\n",
    "tf.summary.image('latents', z_visual, max_outputs=5)\n",
    "tf.summary.histogram('Latent', z)\n",
    "\n",
    "Ws.reverse()\n",
    "shapes.reverse()\n",
    "cur_input = reshaped\n",
    "\n",
    "for l, shape in enumerate(shapes):\n",
    "    cur_name = 'deconv' + str(l)  \n",
    "    W = Ws[l]    \n",
    "    with tf.name_scope('conv_indecon_' + str(len(Ws)-(l+1))):\n",
    "        b = tf.Variable(tf.zeros([W.get_shape().as_list()[2]]), name='bias_dec_'+str(l))\n",
    "        dec = tf.nn.conv2d_transpose(cur_input, W, tf.stack([32, shape[1], shape[2], shape[3]]), strides=[1,2,2,1], padding='SAME')\n",
    "        if l+1 < len(shapes):\n",
    "            act = tf.nn.sigmoid(dec+b)\n",
    "            cur_input = act\n",
    "\n",
    "with tf.name_scope('reconst'):\n",
    "    reconstruction = tf.nn.sigmoid(dec + b)\n",
    "\n",
    "tf.summary.image('reconstructed_images', reconstruction, max_outputs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_flat = tf.contrib.layers.flatten(X)\n",
    "R_flat = tf.contrib.layers.flatten(reconstruction)\n",
    "\n",
    "log_likelihood = tf.reduce_sum(X_flat*tf.log(R_flat + 1e-9)+(1 - X_flat)*tf.log(1 - R_flat + 1e-9), reduction_indices=1)\n",
    "tf.summary.scalar('LogLike', tf.reduce_mean(log_likelihood))\n",
    "\n",
    "KL_term = -.5*tf.reduce_sum(1 + 2*logstd - tf.pow(mu,2) - tf.exp(2*logstd), reduction_indices=1)\n",
    "tf.summary.scalar('KL', tf.reduce_mean(KL_term))\n",
    "\n",
    "variational_lower_bound = tf.reduce_mean(log_likelihood - KL_term)\n",
    "tf.summary.scalar('cost', variational_lower_bound)\n",
    "\n",
    "#optimizer = tf.train.AdadeltaOptimizer().minimize(-variational_lower_bound)\n",
    "optimizer = tf.train.AdamOptimizer(1e-4).minimize(-variational_lower_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_summary = tf.summary.merge_all()\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)\n",
    "saver = tf.train.Saver()\n",
    "writer = tf.summary.FileWriter('./vae_logs/4')\n",
    "writer.add_graph(sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0, Loss: -455.818450928\n",
      "Iteration: 10, Loss: -450.066802979\n",
      "Iteration: 20, Loss: -427.35168457\n",
      "Iteration: 30, Loss: -443.567749023\n",
      "Iteration: 40, Loss: -421.608856201\n",
      "Iteration: 50, Loss: -415.92791748\n",
      "Iteration: 60, Loss: -400.367797852\n",
      "Iteration: 70, Loss: -381.932128906\n",
      "Iteration: 80, Loss: -374.0625\n",
      "Iteration: 90, Loss: -396.880310059\n",
      "Iteration: 100, Loss: -362.048461914\n",
      "Iteration: 110, Loss: -390.479736328\n",
      "Iteration: 120, Loss: -356.782623291\n",
      "Iteration: 130, Loss: -344.985656738\n",
      "Iteration: 140, Loss: -367.740234375\n",
      "Iteration: 150, Loss: -343.125823975\n",
      "Iteration: 160, Loss: -332.354675293\n",
      "Iteration: 170, Loss: -356.149017334\n",
      "Iteration: 180, Loss: -334.058807373\n",
      "Iteration: 190, Loss: -342.772827148\n",
      "Iteration: 200, Loss: -328.250183105\n",
      "Iteration: 210, Loss: -325.792419434\n",
      "Iteration: 220, Loss: -323.28918457\n",
      "Iteration: 230, Loss: -323.85144043\n",
      "Iteration: 240, Loss: -320.449401855\n",
      "Iteration: 250, Loss: -330.654052734\n",
      "Iteration: 260, Loss: -326.100646973\n",
      "Iteration: 270, Loss: -302.951965332\n",
      "Iteration: 280, Loss: -299.082550049\n",
      "Iteration: 290, Loss: -318.976196289\n",
      "Iteration: 300, Loss: -299.671325684\n",
      "Iteration: 310, Loss: -293.241394043\n",
      "Iteration: 320, Loss: -291.631866455\n",
      "Iteration: 330, Loss: -297.542236328\n",
      "Iteration: 340, Loss: -308.186706543\n",
      "Iteration: 350, Loss: -292.2215271\n",
      "Iteration: 360, Loss: -286.352233887\n",
      "Iteration: 370, Loss: -283.569580078\n",
      "Iteration: 380, Loss: -304.126190186\n",
      "Iteration: 390, Loss: -287.010314941\n",
      "Iteration: 400, Loss: -264.672851562\n",
      "Iteration: 410, Loss: -290.268829346\n",
      "Iteration: 420, Loss: -265.761352539\n",
      "Iteration: 430, Loss: -277.488830566\n",
      "Iteration: 440, Loss: -262.422790527\n",
      "Iteration: 450, Loss: -290.06072998\n",
      "Iteration: 460, Loss: -285.073913574\n",
      "Iteration: 470, Loss: -275.665100098\n",
      "Iteration: 480, Loss: -278.249420166\n",
      "Iteration: 490, Loss: -270.568237305\n",
      "Iteration: 500, Loss: -270.67565918\n",
      "Iteration: 510, Loss: -263.608093262\n",
      "Iteration: 520, Loss: -254.419403076\n",
      "Iteration: 530, Loss: -287.057281494\n",
      "Iteration: 540, Loss: -267.637756348\n",
      "Iteration: 550, Loss: -274.57913208\n",
      "Iteration: 560, Loss: -284.939117432\n",
      "Iteration: 570, Loss: -268.18548584\n",
      "Iteration: 580, Loss: -264.878112793\n",
      "Iteration: 590, Loss: -263.664031982\n",
      "Iteration: 600, Loss: -262.971221924\n",
      "Iteration: 610, Loss: -265.862854004\n",
      "Iteration: 620, Loss: -270.948486328\n",
      "Iteration: 630, Loss: -264.752258301\n",
      "Iteration: 640, Loss: -275.447692871\n",
      "Iteration: 650, Loss: -234.857391357\n",
      "Iteration: 660, Loss: -257.011230469\n",
      "Iteration: 670, Loss: -248.061950684\n",
      "Iteration: 680, Loss: -271.035095215\n",
      "Iteration: 690, Loss: -270.249755859\n",
      "Iteration: 700, Loss: -278.967956543\n",
      "Iteration: 710, Loss: -248.130157471\n",
      "Iteration: 720, Loss: -263.196166992\n",
      "Iteration: 730, Loss: -272.380615234\n",
      "Iteration: 740, Loss: -256.139404297\n",
      "Iteration: 750, Loss: -265.320678711\n",
      "Iteration: 760, Loss: -271.172485352\n",
      "Iteration: 770, Loss: -239.50567627\n",
      "Iteration: 780, Loss: -229.039474487\n",
      "Iteration: 790, Loss: -237.58430481\n",
      "Iteration: 800, Loss: -217.929977417\n",
      "Iteration: 810, Loss: -227.007385254\n",
      "Iteration: 820, Loss: -249.872711182\n",
      "Iteration: 830, Loss: -236.296737671\n",
      "Iteration: 840, Loss: -237.734115601\n",
      "Iteration: 850, Loss: -245.897827148\n",
      "Iteration: 860, Loss: -246.519927979\n",
      "Iteration: 870, Loss: -243.675109863\n",
      "Iteration: 880, Loss: -247.746017456\n",
      "Iteration: 890, Loss: -245.299484253\n",
      "Iteration: 900, Loss: -257.148803711\n",
      "Iteration: 910, Loss: -251.49017334\n",
      "Iteration: 920, Loss: -248.355514526\n",
      "Iteration: 930, Loss: -249.964080811\n",
      "Iteration: 940, Loss: -240.885894775\n",
      "Iteration: 950, Loss: -260.765563965\n",
      "Iteration: 960, Loss: -238.371459961\n",
      "Iteration: 970, Loss: -208.72177124\n",
      "Iteration: 980, Loss: -230.392089844\n",
      "Iteration: 990, Loss: -267.820922852\n",
      "Iteration: 1000, Loss: -219.347335815\n",
      "Iteration: 1010, Loss: -245.313201904\n",
      "Iteration: 1020, Loss: -230.024932861\n",
      "Iteration: 1030, Loss: -230.997909546\n",
      "Iteration: 1040, Loss: -235.996139526\n",
      "Iteration: 1050, Loss: -255.938552856\n",
      "Iteration: 1060, Loss: -246.248474121\n",
      "Iteration: 1070, Loss: -234.583084106\n",
      "Iteration: 1080, Loss: -241.16734314\n",
      "Iteration: 1090, Loss: -229.654693604\n",
      "Iteration: 1100, Loss: -245.211975098\n",
      "Iteration: 1110, Loss: -253.39263916\n",
      "Iteration: 1120, Loss: -243.953399658\n",
      "Iteration: 1130, Loss: -246.455718994\n",
      "Iteration: 1140, Loss: -232.102386475\n",
      "Iteration: 1150, Loss: -214.999511719\n",
      "Iteration: 1160, Loss: -234.221542358\n",
      "Iteration: 1170, Loss: -230.827041626\n",
      "Iteration: 1180, Loss: -239.642120361\n",
      "Iteration: 1190, Loss: -216.135864258\n",
      "Iteration: 1200, Loss: -232.170654297\n",
      "Iteration: 1210, Loss: -231.332702637\n",
      "Iteration: 1220, Loss: -247.775390625\n",
      "Iteration: 1230, Loss: -226.463928223\n",
      "Iteration: 1240, Loss: -223.941635132\n",
      "Iteration: 1250, Loss: -233.030029297\n",
      "Iteration: 1260, Loss: -231.20803833\n",
      "Iteration: 1270, Loss: -216.730499268\n",
      "Iteration: 1280, Loss: -215.452438354\n",
      "Iteration: 1290, Loss: -223.949264526\n",
      "Iteration: 1300, Loss: -237.896942139\n",
      "Iteration: 1310, Loss: -239.822052002\n",
      "Iteration: 1320, Loss: -220.198150635\n",
      "Iteration: 1330, Loss: -251.573791504\n",
      "Iteration: 1340, Loss: -229.29145813\n",
      "Iteration: 1350, Loss: -246.964263916\n",
      "Iteration: 1360, Loss: -259.11932373\n",
      "Iteration: 1370, Loss: -223.032287598\n",
      "Iteration: 1380, Loss: -245.043945312\n",
      "Iteration: 1390, Loss: -228.596801758\n",
      "Iteration: 1400, Loss: -236.623016357\n",
      "Iteration: 1410, Loss: -222.983810425\n",
      "Iteration: 1420, Loss: -230.998397827\n",
      "Iteration: 1430, Loss: -226.51751709\n",
      "Iteration: 1440, Loss: -228.881866455\n",
      "Iteration: 1450, Loss: -243.706268311\n",
      "Iteration: 1460, Loss: -216.417449951\n",
      "Iteration: 1470, Loss: -203.599502563\n",
      "Iteration: 1480, Loss: -205.831680298\n",
      "Iteration: 1490, Loss: -212.656448364\n",
      "Iteration: 1500, Loss: -240.400482178\n",
      "Iteration: 1510, Loss: -215.23638916\n",
      "Iteration: 1520, Loss: -214.895935059\n",
      "Iteration: 1530, Loss: -230.406036377\n",
      "Iteration: 1540, Loss: -211.685058594\n",
      "Iteration: 1550, Loss: -228.389984131\n",
      "Iteration: 1560, Loss: -237.915435791\n",
      "Iteration: 1570, Loss: -235.764007568\n",
      "Iteration: 1580, Loss: -225.421142578\n",
      "Iteration: 1590, Loss: -226.126647949\n",
      "Iteration: 1600, Loss: -243.029953003\n",
      "Iteration: 1610, Loss: -222.208496094\n",
      "Iteration: 1620, Loss: -227.255340576\n",
      "Iteration: 1630, Loss: -226.823394775\n",
      "Iteration: 1640, Loss: -232.187530518\n",
      "Iteration: 1650, Loss: -214.365631104\n",
      "Iteration: 1660, Loss: -198.388122559\n",
      "Iteration: 1670, Loss: -239.376525879\n",
      "Iteration: 1680, Loss: -206.418624878\n",
      "Iteration: 1690, Loss: -223.034729004\n",
      "Iteration: 1700, Loss: -290.926422119\n",
      "Iteration: 1710, Loss: -217.249420166\n",
      "Iteration: 1720, Loss: -226.151367188\n",
      "Iteration: 1730, Loss: -237.731872559\n",
      "Iteration: 1740, Loss: -234.860977173\n",
      "Iteration: 1750, Loss: -227.55657959\n",
      "Iteration: 1760, Loss: -228.809936523\n",
      "Iteration: 1770, Loss: -215.447937012\n",
      "Iteration: 1780, Loss: -219.311904907\n",
      "Iteration: 1790, Loss: -212.824554443\n",
      "Iteration: 1800, Loss: -208.68649292\n",
      "Iteration: 1810, Loss: -237.584472656\n",
      "Iteration: 1820, Loss: -213.821166992\n",
      "Iteration: 1830, Loss: -232.9659729\n",
      "Iteration: 1840, Loss: -217.946899414\n",
      "Iteration: 1850, Loss: -217.888061523\n",
      "Iteration: 1860, Loss: -228.144454956\n",
      "Iteration: 1870, Loss: -227.689697266\n",
      "Iteration: 1880, Loss: -215.143859863\n",
      "Iteration: 1890, Loss: -210.263656616\n",
      "Iteration: 1900, Loss: -211.971282959\n",
      "Iteration: 1910, Loss: -202.398468018\n",
      "Iteration: 1920, Loss: -221.960449219\n",
      "Iteration: 1930, Loss: -232.783050537\n",
      "Iteration: 1940, Loss: -221.275115967\n",
      "Iteration: 1950, Loss: -231.30557251\n",
      "Iteration: 1960, Loss: -220.640151978\n",
      "Iteration: 1970, Loss: -205.629043579\n",
      "Iteration: 1980, Loss: -208.534759521\n",
      "Iteration: 1990, Loss: -222.538696289\n",
      "Iteration: 2000, Loss: -208.996185303\n",
      "Iteration: 2010, Loss: -221.354293823\n",
      "Iteration: 2020, Loss: -220.307006836\n",
      "Iteration: 2030, Loss: -220.327636719\n",
      "Iteration: 2040, Loss: -199.178894043\n",
      "Iteration: 2050, Loss: -216.368041992\n",
      "Iteration: 2060, Loss: -209.902801514\n",
      "Iteration: 2070, Loss: -231.64239502\n",
      "Iteration: 2080, Loss: -228.076461792\n",
      "Iteration: 2090, Loss: -207.58392334\n",
      "Iteration: 2100, Loss: -210.870391846\n",
      "Iteration: 2110, Loss: -225.801864624\n",
      "Iteration: 2120, Loss: -227.139938354\n",
      "Iteration: 2130, Loss: -221.340515137\n",
      "Iteration: 2140, Loss: -219.307540894\n",
      "Iteration: 2150, Loss: -223.185211182\n",
      "Iteration: 2160, Loss: -225.95690918\n",
      "Iteration: 2170, Loss: -232.102371216\n",
      "Iteration: 2180, Loss: -211.071426392\n",
      "Iteration: 2190, Loss: -235.620452881\n",
      "Iteration: 2200, Loss: -213.74206543\n",
      "Iteration: 2210, Loss: -234.473526001\n",
      "Iteration: 2220, Loss: -233.141876221\n",
      "Iteration: 2230, Loss: -209.907714844\n",
      "Iteration: 2240, Loss: -216.427780151\n",
      "Iteration: 2250, Loss: -216.760040283\n",
      "Iteration: 2260, Loss: -224.888977051\n",
      "Iteration: 2270, Loss: -227.715240479\n",
      "Iteration: 2280, Loss: -235.437545776\n",
      "Iteration: 2290, Loss: -223.489501953\n",
      "Iteration: 2300, Loss: -211.290740967\n",
      "Iteration: 2310, Loss: -221.459381104\n",
      "Iteration: 2320, Loss: -222.630096436\n",
      "Iteration: 2330, Loss: -215.184616089\n",
      "Iteration: 2340, Loss: -217.557861328\n",
      "Iteration: 2350, Loss: -211.69644165\n",
      "Iteration: 2360, Loss: -213.115539551\n",
      "Iteration: 2370, Loss: -213.103210449\n",
      "Iteration: 2380, Loss: -212.91027832\n",
      "Iteration: 2390, Loss: -217.475311279\n",
      "Iteration: 2400, Loss: -222.475219727\n",
      "Iteration: 2410, Loss: -211.63293457\n",
      "Iteration: 2420, Loss: -203.477386475\n",
      "Iteration: 2430, Loss: -213.536407471\n",
      "Iteration: 2440, Loss: -203.40447998\n",
      "Iteration: 2450, Loss: -218.304718018\n",
      "Iteration: 2460, Loss: -206.951477051\n",
      "Iteration: 2470, Loss: -225.426239014\n",
      "Iteration: 2480, Loss: -223.810806274\n",
      "Iteration: 2490, Loss: -213.056976318\n",
      "Iteration: 2500, Loss: -214.019226074\n",
      "Iteration: 2510, Loss: -225.141586304\n",
      "Iteration: 2520, Loss: -212.21824646\n",
      "Iteration: 2530, Loss: -214.187805176\n",
      "Iteration: 2540, Loss: -220.474151611\n",
      "Iteration: 2550, Loss: -222.007507324\n",
      "Iteration: 2560, Loss: -230.325927734\n",
      "Iteration: 2570, Loss: -206.71572876\n",
      "Iteration: 2580, Loss: -224.209594727\n",
      "Iteration: 2590, Loss: -213.186889648\n",
      "Iteration: 2600, Loss: -220.520690918\n",
      "Iteration: 2610, Loss: -221.09552002\n",
      "Iteration: 2620, Loss: -224.960327148\n",
      "Iteration: 2630, Loss: -221.483108521\n",
      "Iteration: 2640, Loss: -218.147109985\n",
      "Iteration: 2650, Loss: -219.139648438\n",
      "Iteration: 2660, Loss: -224.279251099\n",
      "Iteration: 2670, Loss: -212.118377686\n",
      "Iteration: 2680, Loss: -223.533935547\n",
      "Iteration: 2690, Loss: -211.85256958\n",
      "Iteration: 2700, Loss: -203.648345947\n",
      "Iteration: 2710, Loss: -208.66746521\n",
      "Iteration: 2720, Loss: -205.994873047\n",
      "Iteration: 2730, Loss: -209.409820557\n",
      "Iteration: 2740, Loss: -215.499542236\n",
      "Iteration: 2750, Loss: -214.975860596\n",
      "Iteration: 2760, Loss: -199.313308716\n",
      "Iteration: 2770, Loss: -213.495269775\n",
      "Iteration: 2780, Loss: -212.726394653\n",
      "Iteration: 2790, Loss: -200.014419556\n",
      "Iteration: 2800, Loss: -200.880661011\n",
      "Iteration: 2810, Loss: -209.725906372\n",
      "Iteration: 2820, Loss: -225.362747192\n",
      "Iteration: 2830, Loss: -217.764434814\n",
      "Iteration: 2840, Loss: -211.270477295\n",
      "Iteration: 2850, Loss: -216.366638184\n",
      "Iteration: 2860, Loss: -198.37600708\n",
      "Iteration: 2870, Loss: -215.804840088\n",
      "Iteration: 2880, Loss: -223.068374634\n",
      "Iteration: 2890, Loss: -214.823303223\n",
      "Iteration: 2900, Loss: -210.813034058\n",
      "Iteration: 2910, Loss: -227.535736084\n",
      "Iteration: 2920, Loss: -207.08001709\n",
      "Iteration: 2930, Loss: -215.445892334\n",
      "Iteration: 2940, Loss: -207.190933228\n",
      "Iteration: 2950, Loss: -220.478790283\n",
      "Iteration: 2960, Loss: -200.358215332\n",
      "Iteration: 2970, Loss: -214.412399292\n",
      "Iteration: 2980, Loss: -212.540588379\n",
      "Iteration: 2990, Loss: -207.960968018\n",
      "Iteration: 3000, Loss: -229.558837891\n",
      "Iteration: 3010, Loss: -210.25932312\n",
      "Iteration: 3020, Loss: -193.621429443\n",
      "Iteration: 3030, Loss: -197.990386963\n",
      "Iteration: 3040, Loss: -193.682067871\n",
      "Iteration: 3050, Loss: -225.851013184\n",
      "Iteration: 3060, Loss: -205.841705322\n",
      "Iteration: 3070, Loss: -227.53894043\n",
      "Iteration: 3080, Loss: -220.939422607\n",
      "Iteration: 3090, Loss: -212.932327271\n",
      "Iteration: 3100, Loss: -213.798309326\n",
      "Iteration: 3110, Loss: -209.488677979\n",
      "Iteration: 3120, Loss: -196.576965332\n",
      "Iteration: 3130, Loss: -212.363464355\n",
      "Iteration: 3140, Loss: -206.709274292\n",
      "Iteration: 3150, Loss: -203.728134155\n",
      "Iteration: 3160, Loss: -204.492721558\n",
      "Iteration: 3170, Loss: -213.580993652\n",
      "Iteration: 3180, Loss: -214.139205933\n",
      "Iteration: 3190, Loss: -208.450424194\n",
      "Iteration: 3200, Loss: -217.325134277\n",
      "Iteration: 3210, Loss: -214.587310791\n",
      "Iteration: 3220, Loss: -198.393096924\n",
      "Iteration: 3230, Loss: -211.545318604\n",
      "Iteration: 3240, Loss: -197.960784912\n",
      "Iteration: 3250, Loss: -210.774963379\n",
      "Iteration: 3260, Loss: -206.044189453\n",
      "Iteration: 3270, Loss: -210.906341553\n",
      "Iteration: 3280, Loss: -218.657363892\n",
      "Iteration: 3290, Loss: -222.578460693\n",
      "Iteration: 3300, Loss: -221.394760132\n",
      "Iteration: 3310, Loss: -204.40032959\n",
      "Iteration: 3320, Loss: -206.030212402\n",
      "Iteration: 3330, Loss: -212.541656494\n",
      "Iteration: 3340, Loss: -215.326843262\n",
      "Iteration: 3350, Loss: -207.276062012\n",
      "Iteration: 3360, Loss: -213.813705444\n",
      "Iteration: 3370, Loss: -206.586044312\n",
      "Iteration: 3380, Loss: -207.362701416\n",
      "Iteration: 3390, Loss: -217.631011963\n",
      "Iteration: 3400, Loss: -210.635620117\n",
      "Iteration: 3410, Loss: -218.738464355\n",
      "Iteration: 3420, Loss: -201.343948364\n",
      "Iteration: 3430, Loss: -214.788864136\n",
      "Iteration: 3440, Loss: -235.657928467\n",
      "Iteration: 3450, Loss: -222.946014404\n",
      "Iteration: 3460, Loss: -217.342453003\n",
      "Iteration: 3470, Loss: -197.362258911\n",
      "Iteration: 3480, Loss: -220.352020264\n",
      "Iteration: 3490, Loss: -209.658996582\n",
      "Iteration: 3500, Loss: -212.13973999\n",
      "Iteration: 3510, Loss: -207.967330933\n",
      "Iteration: 3520, Loss: -210.672561646\n",
      "Iteration: 3530, Loss: -217.996170044\n",
      "Iteration: 3540, Loss: -219.425857544\n",
      "Iteration: 3550, Loss: -191.923034668\n",
      "Iteration: 3560, Loss: -219.451004028\n",
      "Iteration: 3570, Loss: -204.054779053\n",
      "Iteration: 3580, Loss: -212.267364502\n",
      "Iteration: 3590, Loss: -211.115905762\n",
      "Iteration: 3600, Loss: -198.771697998\n",
      "Iteration: 3610, Loss: -217.955718994\n",
      "Iteration: 3620, Loss: -205.024902344\n",
      "Iteration: 3630, Loss: -205.473815918\n",
      "Iteration: 3640, Loss: -201.296386719\n",
      "Iteration: 3650, Loss: -212.150970459\n",
      "Iteration: 3660, Loss: -209.252807617\n",
      "Iteration: 3670, Loss: -204.601577759\n",
      "Iteration: 3680, Loss: -211.315979004\n",
      "Iteration: 3690, Loss: -208.224334717\n",
      "Iteration: 3700, Loss: -215.731552124\n",
      "Iteration: 3710, Loss: -204.511108398\n",
      "Iteration: 3720, Loss: -209.506668091\n",
      "Iteration: 3730, Loss: -219.46472168\n",
      "Iteration: 3740, Loss: -195.799316406\n",
      "Iteration: 3750, Loss: -189.071304321\n",
      "Iteration: 3760, Loss: -200.228012085\n",
      "Iteration: 3770, Loss: -217.779067993\n",
      "Iteration: 3780, Loss: -205.137908936\n",
      "Iteration: 3790, Loss: -212.566192627\n",
      "Iteration: 3800, Loss: -213.786773682\n",
      "Iteration: 3810, Loss: -212.082839966\n",
      "Iteration: 3820, Loss: -202.223815918\n",
      "Iteration: 3830, Loss: -208.589263916\n",
      "Iteration: 3840, Loss: -200.640213013\n",
      "Iteration: 3850, Loss: -203.284057617\n",
      "Iteration: 3860, Loss: -197.909820557\n",
      "Iteration: 3870, Loss: -208.323623657\n",
      "Iteration: 3880, Loss: -207.513793945\n",
      "Iteration: 3890, Loss: -218.513626099\n",
      "Iteration: 3900, Loss: -196.928665161\n",
      "Iteration: 3910, Loss: -221.458740234\n",
      "Iteration: 3920, Loss: -203.260559082\n",
      "Iteration: 3930, Loss: -205.263153076\n",
      "Iteration: 3940, Loss: -191.07925415\n",
      "Iteration: 3950, Loss: -191.251251221\n",
      "Iteration: 3960, Loss: -195.724411011\n",
      "Iteration: 3970, Loss: -197.024291992\n",
      "Iteration: 3980, Loss: -202.025650024\n",
      "Iteration: 3990, Loss: -204.573226929\n",
      "Iteration: 4000, Loss: -196.611358643\n",
      "Iteration: 4010, Loss: -201.790771484\n",
      "Iteration: 4020, Loss: -224.154510498\n",
      "Iteration: 4030, Loss: -197.526885986\n",
      "Iteration: 4040, Loss: -209.726898193\n",
      "Iteration: 4050, Loss: -219.429931641\n",
      "Iteration: 4060, Loss: -204.563781738\n",
      "Iteration: 4070, Loss: -211.191009521\n",
      "Iteration: 4080, Loss: -204.44909668\n",
      "Iteration: 4090, Loss: -195.368347168\n",
      "Iteration: 4100, Loss: -200.934524536\n",
      "Iteration: 4110, Loss: -196.519439697\n",
      "Iteration: 4120, Loss: -203.427246094\n",
      "Iteration: 4130, Loss: -201.584060669\n",
      "Iteration: 4140, Loss: -191.940124512\n",
      "Iteration: 4150, Loss: -191.703292847\n",
      "Iteration: 4160, Loss: -203.723724365\n",
      "Iteration: 4170, Loss: -190.292663574\n",
      "Iteration: 4180, Loss: -199.838317871\n",
      "Iteration: 4190, Loss: -206.780273438\n",
      "Iteration: 4200, Loss: -208.273284912\n",
      "Iteration: 4210, Loss: -200.101470947\n",
      "Iteration: 4220, Loss: -209.900482178\n",
      "Iteration: 4230, Loss: -178.154602051\n",
      "Iteration: 4240, Loss: -199.652740479\n",
      "Iteration: 4250, Loss: -199.604568481\n",
      "Iteration: 4260, Loss: -199.939117432\n",
      "Iteration: 4270, Loss: -217.051818848\n",
      "Iteration: 4280, Loss: -195.093383789\n",
      "Iteration: 4290, Loss: -196.663543701\n",
      "Iteration: 4300, Loss: -205.750946045\n",
      "Iteration: 4310, Loss: -189.581451416\n",
      "Iteration: 4320, Loss: -198.997177124\n",
      "Iteration: 4330, Loss: -194.243713379\n",
      "Iteration: 4340, Loss: -214.62159729\n",
      "Iteration: 4350, Loss: -211.884078979\n",
      "Iteration: 4360, Loss: -215.371002197\n",
      "Iteration: 4370, Loss: -201.916778564\n",
      "Iteration: 4380, Loss: -186.842987061\n",
      "Iteration: 4390, Loss: -204.427352905\n",
      "Iteration: 4400, Loss: -217.08114624\n",
      "Iteration: 4410, Loss: -192.489135742\n",
      "Iteration: 4420, Loss: -199.203826904\n",
      "Iteration: 4430, Loss: -199.160858154\n",
      "Iteration: 4440, Loss: -200.029647827\n",
      "Iteration: 4450, Loss: -201.401672363\n",
      "Iteration: 4460, Loss: -200.630218506\n",
      "Iteration: 4470, Loss: -199.167022705\n",
      "Iteration: 4480, Loss: -187.34185791\n",
      "Iteration: 4490, Loss: -203.455718994\n",
      "Iteration: 4500, Loss: -199.801879883\n",
      "Iteration: 4510, Loss: -186.313278198\n",
      "Iteration: 4520, Loss: -199.082748413\n",
      "Iteration: 4530, Loss: -216.347015381\n",
      "Iteration: 4540, Loss: -198.609893799\n",
      "Iteration: 4550, Loss: -185.008361816\n",
      "Iteration: 4560, Loss: -205.76423645\n",
      "Iteration: 4570, Loss: -223.53742981\n",
      "Iteration: 4580, Loss: -204.430725098\n",
      "Iteration: 4590, Loss: -184.528060913\n",
      "Iteration: 4600, Loss: -209.466812134\n",
      "Iteration: 4610, Loss: -216.770294189\n",
      "Iteration: 4620, Loss: -215.939193726\n",
      "Iteration: 4630, Loss: -210.823638916\n",
      "Iteration: 4640, Loss: -190.937438965\n",
      "Iteration: 4650, Loss: -194.5546875\n",
      "Iteration: 4660, Loss: -205.981140137\n",
      "Iteration: 4670, Loss: -199.780700684\n",
      "Iteration: 4680, Loss: -179.57019043\n",
      "Iteration: 4690, Loss: -186.867736816\n",
      "Iteration: 4700, Loss: -207.399200439\n",
      "Iteration: 4710, Loss: -204.803314209\n",
      "Iteration: 4720, Loss: -189.783996582\n",
      "Iteration: 4730, Loss: -178.321304321\n",
      "Iteration: 4740, Loss: -193.549026489\n",
      "Iteration: 4750, Loss: -202.932907104\n",
      "Iteration: 4760, Loss: -205.021636963\n",
      "Iteration: 4770, Loss: -204.052947998\n",
      "Iteration: 4780, Loss: -192.867538452\n",
      "Iteration: 4790, Loss: -195.106964111\n",
      "Iteration: 4800, Loss: -197.749343872\n",
      "Iteration: 4810, Loss: -194.437225342\n",
      "Iteration: 4820, Loss: -192.039886475\n",
      "Iteration: 4830, Loss: -191.582107544\n",
      "Iteration: 4840, Loss: -185.524871826\n",
      "Iteration: 4850, Loss: -194.045120239\n",
      "Iteration: 4860, Loss: -194.502487183\n",
      "Iteration: 4870, Loss: -192.110336304\n",
      "Iteration: 4880, Loss: -194.880874634\n",
      "Iteration: 4890, Loss: -200.635620117\n",
      "Iteration: 4900, Loss: -189.078643799\n",
      "Iteration: 4910, Loss: -213.30027771\n",
      "Iteration: 4920, Loss: -181.093902588\n",
      "Iteration: 4930, Loss: -202.486373901\n",
      "Iteration: 4940, Loss: -211.53276062\n",
      "Iteration: 4950, Loss: -188.280548096\n",
      "Iteration: 4960, Loss: -196.055496216\n",
      "Iteration: 4970, Loss: -185.146850586\n",
      "Iteration: 4980, Loss: -195.98739624\n",
      "Iteration: 4990, Loss: -192.078353882\n",
      "Iteration: 5000, Loss: -190.508117676\n",
      "Iteration: 5010, Loss: -196.720214844\n",
      "Iteration: 5020, Loss: -211.702270508\n",
      "Iteration: 5030, Loss: -193.114578247\n",
      "Iteration: 5040, Loss: -194.280975342\n",
      "Iteration: 5050, Loss: -201.409606934\n",
      "Iteration: 5060, Loss: -178.353057861\n",
      "Iteration: 5070, Loss: -190.70262146\n",
      "Iteration: 5080, Loss: -201.197631836\n",
      "Iteration: 5090, Loss: -176.234603882\n",
      "Iteration: 5100, Loss: -193.790039062\n",
      "Iteration: 5110, Loss: -197.304199219\n",
      "Iteration: 5120, Loss: -198.848419189\n",
      "Iteration: 5130, Loss: -197.356536865\n",
      "Iteration: 5140, Loss: -194.969848633\n",
      "Iteration: 5150, Loss: -200.111206055\n",
      "Iteration: 5160, Loss: -189.083892822\n",
      "Iteration: 5170, Loss: -204.148132324\n",
      "Iteration: 5180, Loss: -215.64906311\n",
      "Iteration: 5190, Loss: -189.468933105\n",
      "Iteration: 5200, Loss: -194.754608154\n",
      "Iteration: 5210, Loss: -208.090789795\n",
      "Iteration: 5220, Loss: -206.06803894\n",
      "Iteration: 5230, Loss: -198.636703491\n",
      "Iteration: 5240, Loss: -196.961364746\n",
      "Iteration: 5250, Loss: -205.137130737\n",
      "Iteration: 5260, Loss: -196.22883606\n",
      "Iteration: 5270, Loss: -188.512680054\n",
      "Iteration: 5280, Loss: -190.020263672\n",
      "Iteration: 5290, Loss: -207.118942261\n",
      "Iteration: 5300, Loss: -199.03125\n",
      "Iteration: 5310, Loss: -191.815216064\n",
      "Iteration: 5320, Loss: -177.67276001\n",
      "Iteration: 5330, Loss: -207.283050537\n",
      "Iteration: 5340, Loss: -197.833099365\n",
      "Iteration: 5350, Loss: -197.003967285\n",
      "Iteration: 5360, Loss: -201.329544067\n",
      "Iteration: 5370, Loss: -194.226715088\n",
      "Iteration: 5380, Loss: -206.245239258\n",
      "Iteration: 5390, Loss: -196.298171997\n",
      "Iteration: 5400, Loss: -205.49961853\n",
      "Iteration: 5410, Loss: -191.550003052\n",
      "Iteration: 5420, Loss: -190.340072632\n",
      "Iteration: 5430, Loss: -204.191955566\n",
      "Iteration: 5440, Loss: -193.043823242\n",
      "Iteration: 5450, Loss: -207.083831787\n",
      "Iteration: 5460, Loss: -192.357498169\n",
      "Iteration: 5470, Loss: -196.902435303\n",
      "Iteration: 5480, Loss: -210.715881348\n",
      "Iteration: 5490, Loss: -205.302612305\n",
      "Iteration: 5500, Loss: -195.912918091\n",
      "Iteration: 5510, Loss: -199.800628662\n",
      "Iteration: 5520, Loss: -197.115814209\n",
      "Iteration: 5530, Loss: -191.871429443\n",
      "Iteration: 5540, Loss: -207.914978027\n",
      "Iteration: 5550, Loss: -198.455276489\n",
      "Iteration: 5560, Loss: -202.565032959\n",
      "Iteration: 5570, Loss: -192.474060059\n",
      "Iteration: 5580, Loss: -208.899856567\n",
      "Iteration: 5590, Loss: -185.86706543\n",
      "Iteration: 5600, Loss: -183.068969727\n",
      "Iteration: 5610, Loss: -189.473114014\n",
      "Iteration: 5620, Loss: -192.371276855\n",
      "Iteration: 5630, Loss: -209.007232666\n",
      "Iteration: 5640, Loss: -200.437911987\n",
      "Iteration: 5650, Loss: -184.526824951\n",
      "Iteration: 5660, Loss: -182.762786865\n",
      "Iteration: 5670, Loss: -199.628372192\n",
      "Iteration: 5680, Loss: -195.68989563\n",
      "Iteration: 5690, Loss: -187.453109741\n",
      "Iteration: 5700, Loss: -193.416671753\n",
      "Iteration: 5710, Loss: -193.376098633\n",
      "Iteration: 5720, Loss: -187.268554688\n",
      "Iteration: 5730, Loss: -193.774215698\n",
      "Iteration: 5740, Loss: -193.825485229\n",
      "Iteration: 5750, Loss: -209.549468994\n",
      "Iteration: 5760, Loss: -181.287261963\n",
      "Iteration: 5770, Loss: -193.274963379\n",
      "Iteration: 5780, Loss: -190.176330566\n",
      "Iteration: 5790, Loss: -199.524749756\n",
      "Iteration: 5800, Loss: -223.521209717\n",
      "Iteration: 5810, Loss: -195.418121338\n",
      "Iteration: 5820, Loss: -200.774627686\n",
      "Iteration: 5830, Loss: -202.994812012\n",
      "Iteration: 5840, Loss: -206.122695923\n",
      "Iteration: 5850, Loss: -188.943481445\n",
      "Iteration: 5860, Loss: -183.543319702\n",
      "Iteration: 5870, Loss: -196.441009521\n",
      "Iteration: 5880, Loss: -191.657211304\n",
      "Iteration: 5890, Loss: -204.894226074\n",
      "Iteration: 5900, Loss: -198.942276001\n",
      "Iteration: 5910, Loss: -211.993927002\n",
      "Iteration: 5920, Loss: -192.503387451\n",
      "Iteration: 5930, Loss: -205.958343506\n",
      "Iteration: 5940, Loss: -192.461349487\n",
      "Iteration: 5950, Loss: -212.185180664\n",
      "Iteration: 5960, Loss: -198.31803894\n",
      "Iteration: 5970, Loss: -196.100387573\n",
      "Iteration: 5980, Loss: -200.225921631\n",
      "Iteration: 5990, Loss: -195.625701904\n",
      "Iteration: 6000, Loss: -192.845077515\n",
      "Iteration: 6010, Loss: -200.675079346\n",
      "Iteration: 6020, Loss: -178.121994019\n",
      "Iteration: 6030, Loss: -214.017059326\n",
      "Iteration: 6040, Loss: -187.998718262\n",
      "Iteration: 6050, Loss: -177.839630127\n",
      "Iteration: 6060, Loss: -192.20161438\n",
      "Iteration: 6070, Loss: -192.6355896\n",
      "Iteration: 6080, Loss: -198.178497314\n",
      "Iteration: 6090, Loss: -199.962768555\n",
      "Iteration: 6100, Loss: -206.432052612\n",
      "Iteration: 6110, Loss: -208.031555176\n",
      "Iteration: 6120, Loss: -196.981872559\n",
      "Iteration: 6130, Loss: -199.861877441\n",
      "Iteration: 6140, Loss: -219.226745605\n",
      "Iteration: 6150, Loss: -201.670654297\n",
      "Iteration: 6160, Loss: -202.963378906\n",
      "Iteration: 6170, Loss: -201.61340332\n",
      "Iteration: 6180, Loss: -194.667419434\n",
      "Iteration: 6190, Loss: -195.032745361\n",
      "Iteration: 6200, Loss: -201.226516724\n",
      "Iteration: 6210, Loss: -198.070648193\n",
      "Iteration: 6220, Loss: -214.950408936\n",
      "Iteration: 6230, Loss: -178.965286255\n",
      "Iteration: 6240, Loss: -188.574005127\n",
      "Iteration: 6250, Loss: -209.915130615\n",
      "Iteration: 6260, Loss: -211.288848877\n",
      "Iteration: 6270, Loss: -192.967071533\n",
      "Iteration: 6280, Loss: -186.502410889\n",
      "Iteration: 6290, Loss: -203.969497681\n",
      "Iteration: 6300, Loss: -199.871856689\n",
      "Iteration: 6310, Loss: -192.218170166\n",
      "Iteration: 6320, Loss: -199.027496338\n",
      "Iteration: 6330, Loss: -184.912780762\n",
      "Iteration: 6340, Loss: -200.762023926\n",
      "Iteration: 6350, Loss: -193.984512329\n",
      "Iteration: 6360, Loss: -181.884094238\n",
      "Iteration: 6370, Loss: -202.82119751\n",
      "Iteration: 6380, Loss: -190.371368408\n",
      "Iteration: 6390, Loss: -193.047027588\n",
      "Iteration: 6400, Loss: -216.643371582\n",
      "Iteration: 6410, Loss: -196.166824341\n",
      "Iteration: 6420, Loss: -193.965393066\n",
      "Iteration: 6430, Loss: -198.571472168\n",
      "Iteration: 6440, Loss: -193.045028687\n",
      "Iteration: 6450, Loss: -203.505340576\n",
      "Iteration: 6460, Loss: -197.145263672\n",
      "Iteration: 6470, Loss: -192.907623291\n",
      "Iteration: 6480, Loss: -197.490905762\n",
      "Iteration: 6490, Loss: -196.564407349\n",
      "Iteration: 6500, Loss: -198.035202026\n",
      "Iteration: 6510, Loss: -197.098632812\n",
      "Iteration: 6520, Loss: -182.695495605\n",
      "Iteration: 6530, Loss: -200.872253418\n",
      "Iteration: 6540, Loss: -203.519592285\n",
      "Iteration: 6550, Loss: -205.520233154\n",
      "Iteration: 6560, Loss: -200.476638794\n",
      "Iteration: 6570, Loss: -210.524719238\n",
      "Iteration: 6580, Loss: -182.653289795\n",
      "Iteration: 6590, Loss: -197.114013672\n",
      "Iteration: 6600, Loss: -187.578140259\n",
      "Iteration: 6610, Loss: -199.155273438\n",
      "Iteration: 6620, Loss: -200.460144043\n",
      "Iteration: 6630, Loss: -209.958618164\n",
      "Iteration: 6640, Loss: -198.10256958\n",
      "Iteration: 6650, Loss: -206.920318604\n",
      "Iteration: 6660, Loss: -204.686096191\n",
      "Iteration: 6670, Loss: -194.286865234\n",
      "Iteration: 6680, Loss: -194.888122559\n",
      "Iteration: 6690, Loss: -188.192459106\n",
      "Iteration: 6700, Loss: -200.121765137\n",
      "Iteration: 6710, Loss: -203.979156494\n",
      "Iteration: 6720, Loss: -204.231140137\n",
      "Iteration: 6730, Loss: -212.284103394\n",
      "Iteration: 6740, Loss: -213.698516846\n",
      "Iteration: 6750, Loss: -187.904067993\n",
      "Iteration: 6760, Loss: -189.442703247\n",
      "Iteration: 6770, Loss: -195.816238403\n",
      "Iteration: 6780, Loss: -186.788955688\n",
      "Iteration: 6790, Loss: -192.459152222\n",
      "Iteration: 6800, Loss: -188.560394287\n",
      "Iteration: 6810, Loss: -198.836639404\n",
      "Iteration: 6820, Loss: -188.634887695\n",
      "Iteration: 6830, Loss: -192.477172852\n",
      "Iteration: 6840, Loss: -192.509155273\n",
      "Iteration: 6850, Loss: -188.192749023\n",
      "Iteration: 6860, Loss: -184.561462402\n",
      "Iteration: 6870, Loss: -182.549697876\n",
      "Iteration: 6880, Loss: -195.486694336\n",
      "Iteration: 6890, Loss: -189.777404785\n",
      "Iteration: 6900, Loss: -220.745666504\n",
      "Iteration: 6910, Loss: -198.57383728\n",
      "Iteration: 6920, Loss: -201.308807373\n",
      "Iteration: 6930, Loss: -196.044555664\n",
      "Iteration: 6940, Loss: -194.508224487\n",
      "Iteration: 6950, Loss: -206.468658447\n",
      "Iteration: 6960, Loss: -207.037231445\n",
      "Iteration: 6970, Loss: -205.457931519\n",
      "Iteration: 6980, Loss: -174.084884644\n",
      "Iteration: 6990, Loss: -195.229034424\n",
      "Iteration: 7000, Loss: -192.19871521\n",
      "Iteration: 7010, Loss: -201.638519287\n",
      "Iteration: 7020, Loss: -200.70904541\n",
      "Iteration: 7030, Loss: -181.643280029\n",
      "Iteration: 7040, Loss: -188.281723022\n",
      "Iteration: 7050, Loss: -193.981887817\n",
      "Iteration: 7060, Loss: -192.462860107\n",
      "Iteration: 7070, Loss: -208.947723389\n",
      "Iteration: 7080, Loss: -194.172927856\n",
      "Iteration: 7090, Loss: -195.60357666\n",
      "Iteration: 7100, Loss: -200.884765625\n",
      "Iteration: 7110, Loss: -204.888809204\n",
      "Iteration: 7120, Loss: -179.817260742\n",
      "Iteration: 7130, Loss: -185.672302246\n",
      "Iteration: 7140, Loss: -181.772247314\n",
      "Iteration: 7150, Loss: -208.13168335\n",
      "Iteration: 7160, Loss: -207.97088623\n",
      "Iteration: 7170, Loss: -193.294342041\n",
      "Iteration: 7180, Loss: -201.586425781\n",
      "Iteration: 7190, Loss: -202.625\n",
      "Iteration: 7200, Loss: -186.379226685\n",
      "Iteration: 7210, Loss: -185.042922974\n",
      "Iteration: 7220, Loss: -194.354187012\n",
      "Iteration: 7230, Loss: -200.391174316\n",
      "Iteration: 7240, Loss: -179.833679199\n",
      "Iteration: 7250, Loss: -196.147949219\n",
      "Iteration: 7260, Loss: -182.648345947\n",
      "Iteration: 7270, Loss: -190.721343994\n",
      "Iteration: 7280, Loss: -187.509063721\n",
      "Iteration: 7290, Loss: -195.020935059\n",
      "Iteration: 7300, Loss: -190.668655396\n",
      "Iteration: 7310, Loss: -196.389678955\n",
      "Iteration: 7320, Loss: -185.869750977\n",
      "Iteration: 7330, Loss: -198.217071533\n",
      "Iteration: 7340, Loss: -196.18661499\n",
      "Iteration: 7350, Loss: -214.246276855\n",
      "Iteration: 7360, Loss: -195.723937988\n",
      "Iteration: 7370, Loss: -197.341598511\n",
      "Iteration: 7380, Loss: -180.066726685\n",
      "Iteration: 7390, Loss: -195.928039551\n",
      "Iteration: 7400, Loss: -189.737670898\n",
      "Iteration: 7410, Loss: -201.286071777\n",
      "Iteration: 7420, Loss: -202.088394165\n",
      "Iteration: 7430, Loss: -187.5184021\n",
      "Iteration: 7440, Loss: -192.668365479\n",
      "Iteration: 7450, Loss: -188.208892822\n",
      "Iteration: 7460, Loss: -195.56211853\n",
      "Iteration: 7470, Loss: -205.531463623\n",
      "Iteration: 7480, Loss: -208.533874512\n",
      "Iteration: 7490, Loss: -179.402160645\n",
      "Iteration: 7500, Loss: -192.574234009\n",
      "Iteration: 7510, Loss: -213.332504272\n",
      "Iteration: 7520, Loss: -186.273620605\n",
      "Iteration: 7530, Loss: -209.88041687\n",
      "Iteration: 7540, Loss: -221.546524048\n",
      "Iteration: 7550, Loss: -195.47756958\n",
      "Iteration: 7560, Loss: -189.314590454\n",
      "Iteration: 7570, Loss: -191.153503418\n",
      "Iteration: 7580, Loss: -199.955230713\n",
      "Iteration: 7590, Loss: -188.621414185\n",
      "Iteration: 7600, Loss: -207.623565674\n",
      "Iteration: 7610, Loss: -188.909973145\n",
      "Iteration: 7620, Loss: -181.405700684\n",
      "Iteration: 7630, Loss: -192.635299683\n",
      "Iteration: 7640, Loss: -193.32925415\n",
      "Iteration: 7650, Loss: -188.985733032\n",
      "Iteration: 7660, Loss: -190.042449951\n",
      "Iteration: 7670, Loss: -206.344848633\n",
      "Iteration: 7680, Loss: -196.333877563\n",
      "Iteration: 7690, Loss: -202.418334961\n",
      "Iteration: 7700, Loss: -194.595428467\n",
      "Iteration: 7710, Loss: -194.521011353\n",
      "Iteration: 7720, Loss: -198.248519897\n",
      "Iteration: 7730, Loss: -209.060241699\n",
      "Iteration: 7740, Loss: -207.149230957\n",
      "Iteration: 7750, Loss: -200.599853516\n",
      "Iteration: 7760, Loss: -199.326644897\n",
      "Iteration: 7770, Loss: -210.637664795\n",
      "Iteration: 7780, Loss: -192.497451782\n",
      "Iteration: 7790, Loss: -197.726150513\n",
      "Iteration: 7800, Loss: -203.440689087\n",
      "Iteration: 7810, Loss: -184.627059937\n",
      "Iteration: 7820, Loss: -212.138183594\n",
      "Iteration: 7830, Loss: -192.081481934\n",
      "Iteration: 7840, Loss: -187.987121582\n",
      "Iteration: 7850, Loss: -201.709518433\n",
      "Iteration: 7860, Loss: -193.993988037\n",
      "Iteration: 7870, Loss: -197.362686157\n",
      "Iteration: 7880, Loss: -199.043121338\n",
      "Iteration: 7890, Loss: -188.47668457\n",
      "Iteration: 7900, Loss: -204.132263184\n",
      "Iteration: 7910, Loss: -181.954437256\n",
      "Iteration: 7920, Loss: -187.91015625\n",
      "Iteration: 7930, Loss: -197.439880371\n",
      "Iteration: 7940, Loss: -192.534622192\n",
      "Iteration: 7950, Loss: -194.883834839\n",
      "Iteration: 7960, Loss: -199.196563721\n",
      "Iteration: 7970, Loss: -197.717010498\n",
      "Iteration: 7980, Loss: -192.610321045\n",
      "Iteration: 7990, Loss: -195.81640625\n",
      "Iteration: 8000, Loss: -211.505065918\n",
      "Iteration: 8010, Loss: -208.368423462\n",
      "Iteration: 8020, Loss: -192.826919556\n",
      "Iteration: 8030, Loss: -188.080657959\n",
      "Iteration: 8040, Loss: -190.012207031\n",
      "Iteration: 8050, Loss: -199.891204834\n",
      "Iteration: 8060, Loss: -189.615692139\n",
      "Iteration: 8070, Loss: -189.765014648\n",
      "Iteration: 8080, Loss: -188.827789307\n",
      "Iteration: 8090, Loss: -184.450866699\n",
      "Iteration: 8100, Loss: -181.84614563\n",
      "Iteration: 8110, Loss: -197.300888062\n",
      "Iteration: 8120, Loss: -189.635314941\n",
      "Iteration: 8130, Loss: -204.650054932\n",
      "Iteration: 8140, Loss: -187.886108398\n",
      "Iteration: 8150, Loss: -188.139007568\n",
      "Iteration: 8160, Loss: -182.698272705\n",
      "Iteration: 8170, Loss: -177.10697937\n",
      "Iteration: 8180, Loss: -199.525817871\n",
      "Iteration: 8190, Loss: -181.098358154\n",
      "Iteration: 8200, Loss: -191.307525635\n",
      "Iteration: 8210, Loss: -208.536026001\n",
      "Iteration: 8220, Loss: -194.264007568\n",
      "Iteration: 8230, Loss: -179.202545166\n",
      "Iteration: 8240, Loss: -183.434570312\n",
      "Iteration: 8250, Loss: -186.852035522\n",
      "Iteration: 8260, Loss: -185.789489746\n",
      "Iteration: 8270, Loss: -186.485183716\n",
      "Iteration: 8280, Loss: -186.917633057\n",
      "Iteration: 8290, Loss: -193.78666687\n",
      "Iteration: 8300, Loss: -200.793518066\n",
      "Iteration: 8310, Loss: -203.265899658\n",
      "Iteration: 8320, Loss: -180.925857544\n",
      "Iteration: 8330, Loss: -186.485733032\n",
      "Iteration: 8340, Loss: -180.908782959\n",
      "Iteration: 8350, Loss: -202.629180908\n",
      "Iteration: 8360, Loss: -193.564086914\n",
      "Iteration: 8370, Loss: -195.148101807\n",
      "Iteration: 8380, Loss: -204.684753418\n",
      "Iteration: 8390, Loss: -185.32901001\n",
      "Iteration: 8400, Loss: -182.75289917\n",
      "Iteration: 8410, Loss: -209.037384033\n",
      "Iteration: 8420, Loss: -187.906707764\n",
      "Iteration: 8430, Loss: -187.607254028\n",
      "Iteration: 8440, Loss: -201.35760498\n",
      "Iteration: 8450, Loss: -168.890136719\n",
      "Iteration: 8460, Loss: -201.572875977\n",
      "Iteration: 8470, Loss: -184.176605225\n",
      "Iteration: 8480, Loss: -188.427047729\n",
      "Iteration: 8490, Loss: -200.521148682\n",
      "Iteration: 8500, Loss: -187.619277954\n",
      "Iteration: 8510, Loss: -199.645812988\n",
      "Iteration: 8520, Loss: -189.906463623\n",
      "Iteration: 8530, Loss: -193.850799561\n",
      "Iteration: 8540, Loss: -194.647094727\n",
      "Iteration: 8550, Loss: -180.560623169\n",
      "Iteration: 8560, Loss: -173.376724243\n",
      "Iteration: 8570, Loss: -212.544494629\n",
      "Iteration: 8580, Loss: -193.724395752\n",
      "Iteration: 8590, Loss: -191.487243652\n",
      "Iteration: 8600, Loss: -184.185043335\n",
      "Iteration: 8610, Loss: -189.890014648\n",
      "Iteration: 8620, Loss: -182.179168701\n",
      "Iteration: 8630, Loss: -191.225036621\n",
      "Iteration: 8640, Loss: -199.290252686\n",
      "Iteration: 8650, Loss: -190.539428711\n",
      "Iteration: 8660, Loss: -195.47454834\n",
      "Iteration: 8670, Loss: -190.042510986\n",
      "Iteration: 8680, Loss: -163.830383301\n",
      "Iteration: 8690, Loss: -174.173156738\n",
      "Iteration: 8700, Loss: -196.739685059\n",
      "Iteration: 8710, Loss: -201.78704834\n",
      "Iteration: 8720, Loss: -175.55039978\n",
      "Iteration: 8730, Loss: -201.018310547\n",
      "Iteration: 8740, Loss: -188.489715576\n",
      "Iteration: 8750, Loss: -200.287979126\n",
      "Iteration: 8760, Loss: -182.283752441\n",
      "Iteration: 8770, Loss: -171.193023682\n",
      "Iteration: 8780, Loss: -177.897979736\n",
      "Iteration: 8790, Loss: -209.488891602\n",
      "Iteration: 8800, Loss: -184.73777771\n",
      "Iteration: 8810, Loss: -201.220657349\n",
      "Iteration: 8820, Loss: -201.024795532\n",
      "Iteration: 8830, Loss: -180.810455322\n",
      "Iteration: 8840, Loss: -199.127838135\n",
      "Iteration: 8850, Loss: -209.235839844\n",
      "Iteration: 8860, Loss: -191.922790527\n",
      "Iteration: 8870, Loss: -196.599594116\n",
      "Iteration: 8880, Loss: -194.553771973\n",
      "Iteration: 8890, Loss: -181.518005371\n",
      "Iteration: 8900, Loss: -183.780700684\n",
      "Iteration: 8910, Loss: -180.233673096\n",
      "Iteration: 8920, Loss: -168.828369141\n",
      "Iteration: 8930, Loss: -176.241485596\n",
      "Iteration: 8940, Loss: -188.158157349\n",
      "Iteration: 8950, Loss: -206.732696533\n",
      "Iteration: 8960, Loss: -189.490463257\n",
      "Iteration: 8970, Loss: -198.001525879\n",
      "Iteration: 8980, Loss: -179.968841553\n",
      "Iteration: 8990, Loss: -171.083511353\n",
      "Iteration: 9000, Loss: -201.628601074\n",
      "Iteration: 9010, Loss: -193.425567627\n",
      "Iteration: 9020, Loss: -188.589569092\n",
      "Iteration: 9030, Loss: -190.603851318\n",
      "Iteration: 9040, Loss: -199.397354126\n",
      "Iteration: 9050, Loss: -186.357147217\n",
      "Iteration: 9060, Loss: -174.706283569\n",
      "Iteration: 9070, Loss: -198.663879395\n",
      "Iteration: 9080, Loss: -190.625427246\n",
      "Iteration: 9090, Loss: -220.018493652\n",
      "Iteration: 9100, Loss: -177.988372803\n",
      "Iteration: 9110, Loss: -201.177459717\n",
      "Iteration: 9120, Loss: -179.278137207\n",
      "Iteration: 9130, Loss: -211.022384644\n",
      "Iteration: 9140, Loss: -190.836395264\n",
      "Iteration: 9150, Loss: -194.158248901\n",
      "Iteration: 9160, Loss: -191.834197998\n",
      "Iteration: 9170, Loss: -178.447174072\n",
      "Iteration: 9180, Loss: -205.975311279\n",
      "Iteration: 9190, Loss: -189.752853394\n",
      "Iteration: 9200, Loss: -174.798034668\n",
      "Iteration: 9210, Loss: -195.97567749\n",
      "Iteration: 9220, Loss: -194.362228394\n",
      "Iteration: 9230, Loss: -188.959762573\n",
      "Iteration: 9240, Loss: -200.454605103\n",
      "Iteration: 9250, Loss: -176.619232178\n",
      "Iteration: 9260, Loss: -172.185195923\n",
      "Iteration: 9270, Loss: -191.281143188\n",
      "Iteration: 9280, Loss: -172.987197876\n",
      "Iteration: 9290, Loss: -198.100860596\n",
      "Iteration: 9300, Loss: -195.180847168\n",
      "Iteration: 9310, Loss: -200.512420654\n",
      "Iteration: 9320, Loss: -182.820159912\n",
      "Iteration: 9330, Loss: -180.958190918\n",
      "Iteration: 9340, Loss: -193.640213013\n",
      "Iteration: 9350, Loss: -191.42489624\n",
      "Iteration: 9360, Loss: -174.083938599\n",
      "Iteration: 9370, Loss: -180.526611328\n",
      "Iteration: 9380, Loss: -189.149291992\n",
      "Iteration: 9390, Loss: -205.356689453\n",
      "Iteration: 9400, Loss: -200.209777832\n",
      "Iteration: 9410, Loss: -200.32359314\n",
      "Iteration: 9420, Loss: -188.755157471\n",
      "Iteration: 9430, Loss: -180.557098389\n",
      "Iteration: 9440, Loss: -188.367797852\n",
      "Iteration: 9450, Loss: -186.70022583\n",
      "Iteration: 9460, Loss: -168.472564697\n",
      "Iteration: 9470, Loss: -187.015045166\n",
      "Iteration: 9480, Loss: -188.141601562\n",
      "Iteration: 9490, Loss: -191.974319458\n",
      "Iteration: 9500, Loss: -190.741500854\n",
      "Iteration: 9510, Loss: -182.854766846\n",
      "Iteration: 9520, Loss: -193.118911743\n",
      "Iteration: 9530, Loss: -185.918579102\n",
      "Iteration: 9540, Loss: -211.780426025\n",
      "Iteration: 9550, Loss: -177.263763428\n",
      "Iteration: 9560, Loss: -189.674697876\n",
      "Iteration: 9570, Loss: -177.153488159\n",
      "Iteration: 9580, Loss: -180.777008057\n",
      "Iteration: 9590, Loss: -189.642791748\n",
      "Iteration: 9600, Loss: -185.668380737\n",
      "Iteration: 9610, Loss: -178.441070557\n",
      "Iteration: 9620, Loss: -194.238433838\n",
      "Iteration: 9630, Loss: -188.447265625\n",
      "Iteration: 9640, Loss: -195.984817505\n",
      "Iteration: 9650, Loss: -181.250778198\n",
      "Iteration: 9660, Loss: -205.033416748\n",
      "Iteration: 9670, Loss: -182.626342773\n",
      "Iteration: 9680, Loss: -179.135299683\n",
      "Iteration: 9690, Loss: -185.321136475\n",
      "Iteration: 9700, Loss: -194.587844849\n",
      "Iteration: 9710, Loss: -187.388702393\n",
      "Iteration: 9720, Loss: -177.204742432\n",
      "Iteration: 9730, Loss: -174.49180603\n",
      "Iteration: 9740, Loss: -188.565979004\n",
      "Iteration: 9750, Loss: -201.356704712\n",
      "Iteration: 9760, Loss: -195.185409546\n",
      "Iteration: 9770, Loss: -194.542404175\n",
      "Iteration: 9780, Loss: -190.059249878\n",
      "Iteration: 9790, Loss: -195.599609375\n",
      "Iteration: 9800, Loss: -190.935012817\n",
      "Iteration: 9810, Loss: -180.338348389\n",
      "Iteration: 9820, Loss: -189.477081299\n",
      "Iteration: 9830, Loss: -202.610656738\n",
      "Iteration: 9840, Loss: -172.547363281\n",
      "Iteration: 9850, Loss: -208.443252563\n",
      "Iteration: 9860, Loss: -182.259338379\n",
      "Iteration: 9870, Loss: -182.954391479\n",
      "Iteration: 9880, Loss: -212.813140869\n",
      "Iteration: 9890, Loss: -178.264221191\n",
      "Iteration: 9900, Loss: -190.72668457\n",
      "Iteration: 9910, Loss: -183.198699951\n",
      "Iteration: 9920, Loss: -185.241714478\n",
      "Iteration: 9930, Loss: -205.976318359\n",
      "Iteration: 9940, Loss: -183.404647827\n",
      "Iteration: 9950, Loss: -171.437957764\n",
      "Iteration: 9960, Loss: -196.396484375\n",
      "Iteration: 9970, Loss: -174.730499268\n",
      "Iteration: 9980, Loss: -198.063491821\n",
      "Iteration: 9990, Loss: -194.078445435\n",
      "Iteration: 10000, Loss: -179.852264404\n",
      "Iteration: 10010, Loss: -184.555221558\n",
      "Iteration: 10020, Loss: -179.815063477\n",
      "Iteration: 10030, Loss: -178.506256104\n",
      "Iteration: 10040, Loss: -183.235961914\n",
      "Iteration: 10050, Loss: -190.379943848\n",
      "Iteration: 10060, Loss: -188.67767334\n",
      "Iteration: 10070, Loss: -172.775985718\n",
      "Iteration: 10080, Loss: -176.634414673\n",
      "Iteration: 10090, Loss: -193.498733521\n",
      "Iteration: 10100, Loss: -189.101715088\n",
      "Iteration: 10110, Loss: -196.703125\n",
      "Iteration: 10120, Loss: -199.102523804\n",
      "Iteration: 10130, Loss: -183.89151001\n",
      "Iteration: 10140, Loss: -180.540496826\n",
      "Iteration: 10150, Loss: -175.815917969\n",
      "Iteration: 10160, Loss: -178.397354126\n",
      "Iteration: 10170, Loss: -187.159301758\n",
      "Iteration: 10180, Loss: -187.444061279\n",
      "Iteration: 10190, Loss: -169.981781006\n",
      "Iteration: 10200, Loss: -202.044433594\n",
      "Iteration: 10210, Loss: -187.888153076\n",
      "Iteration: 10220, Loss: -175.264770508\n",
      "Iteration: 10230, Loss: -192.389984131\n",
      "Iteration: 10240, Loss: -186.722961426\n",
      "Iteration: 10250, Loss: -175.526397705\n",
      "Iteration: 10260, Loss: -192.767547607\n",
      "Iteration: 10270, Loss: -186.932815552\n",
      "Iteration: 10280, Loss: -177.165222168\n",
      "Iteration: 10290, Loss: -184.621749878\n",
      "Iteration: 10300, Loss: -182.244415283\n",
      "Iteration: 10310, Loss: -187.072097778\n",
      "Iteration: 10320, Loss: -171.869384766\n",
      "Iteration: 10330, Loss: -189.738861084\n",
      "Iteration: 10340, Loss: -170.694595337\n",
      "Iteration: 10350, Loss: -181.549362183\n",
      "Iteration: 10360, Loss: -197.379943848\n",
      "Iteration: 10370, Loss: -187.507843018\n",
      "Iteration: 10380, Loss: -188.662780762\n",
      "Iteration: 10390, Loss: -196.206542969\n",
      "Iteration: 10400, Loss: -184.721435547\n",
      "Iteration: 10410, Loss: -188.064727783\n",
      "Iteration: 10420, Loss: -185.465515137\n",
      "Iteration: 10430, Loss: -172.098068237\n",
      "Iteration: 10440, Loss: -193.012420654\n",
      "Iteration: 10450, Loss: -211.914031982\n",
      "Iteration: 10460, Loss: -202.755950928\n",
      "Iteration: 10470, Loss: -200.98046875\n",
      "Iteration: 10480, Loss: -203.1224823\n",
      "Iteration: 10490, Loss: -186.128479004\n",
      "Iteration: 10500, Loss: -191.80847168\n",
      "Iteration: 10510, Loss: -185.138366699\n",
      "Iteration: 10520, Loss: -191.315856934\n",
      "Iteration: 10530, Loss: -182.998413086\n",
      "Iteration: 10540, Loss: -185.902053833\n",
      "Iteration: 10550, Loss: -185.650787354\n",
      "Iteration: 10560, Loss: -188.305282593\n",
      "Iteration: 10570, Loss: -189.989837646\n",
      "Iteration: 10580, Loss: -183.759124756\n",
      "Iteration: 10590, Loss: -185.831329346\n",
      "Iteration: 10600, Loss: -186.278900146\n",
      "Iteration: 10610, Loss: -202.736709595\n",
      "Iteration: 10620, Loss: -175.699951172\n",
      "Iteration: 10630, Loss: -175.41317749\n",
      "Iteration: 10640, Loss: -174.668029785\n",
      "Iteration: 10650, Loss: -184.692596436\n",
      "Iteration: 10660, Loss: -185.004760742\n",
      "Iteration: 10670, Loss: -177.516174316\n",
      "Iteration: 10680, Loss: -190.737243652\n",
      "Iteration: 10690, Loss: -180.240478516\n",
      "Iteration: 10700, Loss: -186.162109375\n",
      "Iteration: 10710, Loss: -196.074386597\n",
      "Iteration: 10720, Loss: -188.579162598\n",
      "Iteration: 10730, Loss: -167.28553772\n",
      "Iteration: 10740, Loss: -188.540939331\n",
      "Iteration: 10750, Loss: -182.643936157\n",
      "Iteration: 10760, Loss: -178.833282471\n",
      "Iteration: 10770, Loss: -199.492828369\n",
      "Iteration: 10780, Loss: -189.737640381\n",
      "Iteration: 10790, Loss: -189.440048218\n",
      "Iteration: 10800, Loss: -170.270050049\n",
      "Iteration: 10810, Loss: -185.617416382\n",
      "Iteration: 10820, Loss: -191.159667969\n",
      "Iteration: 10830, Loss: -186.074035645\n",
      "Iteration: 10840, Loss: -184.505310059\n",
      "Iteration: 10850, Loss: -197.606964111\n",
      "Iteration: 10860, Loss: -204.24697876\n",
      "Iteration: 10870, Loss: -180.733703613\n",
      "Iteration: 10880, Loss: -189.931396484\n",
      "Iteration: 10890, Loss: -173.501617432\n",
      "Iteration: 10900, Loss: -194.102371216\n",
      "Iteration: 10910, Loss: -182.102630615\n",
      "Iteration: 10920, Loss: -174.753860474\n",
      "Iteration: 10930, Loss: -203.411575317\n",
      "Iteration: 10940, Loss: -176.306793213\n",
      "Iteration: 10950, Loss: -181.916564941\n",
      "Iteration: 10960, Loss: -185.215881348\n",
      "Iteration: 10970, Loss: -176.374908447\n",
      "Iteration: 10980, Loss: -181.901870728\n",
      "Iteration: 10990, Loss: -182.953323364\n",
      "Iteration: 11000, Loss: -184.262069702\n",
      "Iteration: 11010, Loss: -176.783157349\n",
      "Iteration: 11020, Loss: -205.796676636\n",
      "Iteration: 11030, Loss: -183.227752686\n",
      "Iteration: 11040, Loss: -232.267913818\n",
      "Iteration: 11050, Loss: -180.157440186\n",
      "Iteration: 11060, Loss: -175.974304199\n",
      "Iteration: 11070, Loss: -174.571548462\n",
      "Iteration: 11080, Loss: -187.580245972\n",
      "Iteration: 11090, Loss: -194.321807861\n",
      "Iteration: 11100, Loss: -178.511383057\n",
      "Iteration: 11110, Loss: -197.693603516\n",
      "Iteration: 11120, Loss: -165.963745117\n",
      "Iteration: 11130, Loss: -202.803100586\n",
      "Iteration: 11140, Loss: -180.001922607\n",
      "Iteration: 11150, Loss: -198.072189331\n",
      "Iteration: 11160, Loss: -186.609802246\n",
      "Iteration: 11170, Loss: -185.792160034\n",
      "Iteration: 11180, Loss: -189.533996582\n",
      "Iteration: 11190, Loss: -187.934143066\n",
      "Iteration: 11200, Loss: -183.830886841\n",
      "Iteration: 11210, Loss: -186.396514893\n",
      "Iteration: 11220, Loss: -173.774017334\n",
      "Iteration: 11230, Loss: -186.844696045\n",
      "Iteration: 11240, Loss: -185.194854736\n",
      "Iteration: 11250, Loss: -182.212814331\n",
      "Iteration: 11260, Loss: -181.730178833\n",
      "Iteration: 11270, Loss: -191.422271729\n",
      "Iteration: 11280, Loss: -180.531799316\n",
      "Iteration: 11290, Loss: -170.708435059\n",
      "Iteration: 11300, Loss: -190.704040527\n",
      "Iteration: 11310, Loss: -181.93321228\n",
      "Iteration: 11320, Loss: -193.560409546\n",
      "Iteration: 11330, Loss: -202.455169678\n",
      "Iteration: 11340, Loss: -191.839935303\n",
      "Iteration: 11350, Loss: -195.848449707\n",
      "Iteration: 11360, Loss: -179.244140625\n",
      "Iteration: 11370, Loss: -173.624572754\n",
      "Iteration: 11380, Loss: -177.899261475\n",
      "Iteration: 11390, Loss: -175.422393799\n",
      "Iteration: 11400, Loss: -171.565338135\n",
      "Iteration: 11410, Loss: -189.027770996\n",
      "Iteration: 11420, Loss: -185.611297607\n",
      "Iteration: 11430, Loss: -169.994720459\n",
      "Iteration: 11440, Loss: -183.762817383\n",
      "Iteration: 11450, Loss: -182.789215088\n",
      "Iteration: 11460, Loss: -180.833175659\n",
      "Iteration: 11470, Loss: -184.710540771\n",
      "Iteration: 11480, Loss: -177.851287842\n",
      "Iteration: 11490, Loss: -187.727172852\n",
      "Iteration: 11500, Loss: -173.989929199\n",
      "Iteration: 11510, Loss: -181.315917969\n",
      "Iteration: 11520, Loss: -173.686004639\n",
      "Iteration: 11530, Loss: -176.9168396\n",
      "Iteration: 11540, Loss: -187.68182373\n",
      "Iteration: 11550, Loss: -172.583358765\n",
      "Iteration: 11560, Loss: -193.896728516\n",
      "Iteration: 11570, Loss: -199.493835449\n",
      "Iteration: 11580, Loss: -175.622436523\n",
      "Iteration: 11590, Loss: -171.088653564\n",
      "Iteration: 11600, Loss: -185.839263916\n",
      "Iteration: 11610, Loss: -172.840408325\n",
      "Iteration: 11620, Loss: -163.287078857\n",
      "Iteration: 11630, Loss: -191.909118652\n",
      "Iteration: 11640, Loss: -188.205963135\n",
      "Iteration: 11650, Loss: -186.520675659\n",
      "Iteration: 11660, Loss: -184.303695679\n",
      "Iteration: 11670, Loss: -192.043060303\n",
      "Iteration: 11680, Loss: -183.730621338\n",
      "Iteration: 11690, Loss: -192.81741333\n",
      "Iteration: 11700, Loss: -180.692993164\n",
      "Iteration: 11710, Loss: -196.444091797\n",
      "Iteration: 11720, Loss: -186.488861084\n",
      "Iteration: 11730, Loss: -176.966323853\n",
      "Iteration: 11740, Loss: -196.359344482\n",
      "Iteration: 11750, Loss: -172.280517578\n",
      "Iteration: 11760, Loss: -201.459197998\n",
      "Iteration: 11770, Loss: -196.239349365\n",
      "Iteration: 11780, Loss: -183.946899414\n",
      "Iteration: 11790, Loss: -182.893981934\n",
      "Iteration: 11800, Loss: -194.266418457\n",
      "Iteration: 11810, Loss: -184.274551392\n",
      "Iteration: 11820, Loss: -208.269989014\n",
      "Iteration: 11830, Loss: -184.504425049\n",
      "Iteration: 11840, Loss: -188.097595215\n",
      "Iteration: 11850, Loss: -177.371765137\n",
      "Iteration: 11860, Loss: -174.062744141\n",
      "Iteration: 11870, Loss: -168.056182861\n",
      "Iteration: 11880, Loss: -197.270645142\n",
      "Iteration: 11890, Loss: -184.043334961\n",
      "Iteration: 11900, Loss: -168.241149902\n",
      "Iteration: 11910, Loss: -168.762191772\n",
      "Iteration: 11920, Loss: -201.73348999\n",
      "Iteration: 11930, Loss: -181.861984253\n",
      "Iteration: 11940, Loss: -178.525909424\n",
      "Iteration: 11950, Loss: -186.325057983\n",
      "Iteration: 11960, Loss: -185.019607544\n",
      "Iteration: 11970, Loss: -192.676757812\n",
      "Iteration: 11980, Loss: -193.278579712\n",
      "Iteration: 11990, Loss: -190.666809082\n",
      "Iteration: 12000, Loss: -180.396133423\n",
      "Iteration: 12010, Loss: -204.084121704\n",
      "Iteration: 12020, Loss: -173.141235352\n",
      "Iteration: 12030, Loss: -181.279815674\n",
      "Iteration: 12040, Loss: -178.172363281\n",
      "Iteration: 12050, Loss: -168.685516357\n",
      "Iteration: 12060, Loss: -181.876937866\n",
      "Iteration: 12070, Loss: -182.531066895\n",
      "Iteration: 12080, Loss: -175.750549316\n",
      "Iteration: 12090, Loss: -191.260772705\n",
      "Iteration: 12100, Loss: -185.557281494\n",
      "Iteration: 12110, Loss: -184.22833252\n",
      "Iteration: 12120, Loss: -164.807022095\n",
      "Iteration: 12130, Loss: -173.986358643\n",
      "Iteration: 12140, Loss: -184.30670166\n",
      "Iteration: 12150, Loss: -176.088989258\n",
      "Iteration: 12160, Loss: -179.35508728\n",
      "Iteration: 12170, Loss: -190.279769897\n",
      "Iteration: 12180, Loss: -181.947860718\n",
      "Iteration: 12190, Loss: -187.758453369\n",
      "Iteration: 12200, Loss: -182.204406738\n",
      "Iteration: 12210, Loss: -180.577606201\n",
      "Iteration: 12220, Loss: -180.221817017\n",
      "Iteration: 12230, Loss: -213.270706177\n",
      "Iteration: 12240, Loss: -201.893844604\n",
      "Iteration: 12250, Loss: -188.227249146\n",
      "Iteration: 12260, Loss: -170.629257202\n",
      "Iteration: 12270, Loss: -162.356536865\n",
      "Iteration: 12280, Loss: -185.860702515\n",
      "Iteration: 12290, Loss: -183.815872192\n",
      "Iteration: 12300, Loss: -207.153030396\n",
      "Iteration: 12310, Loss: -177.384552002\n",
      "Iteration: 12320, Loss: -183.014404297\n",
      "Iteration: 12330, Loss: -178.735061646\n",
      "Iteration: 12340, Loss: -185.952804565\n",
      "Iteration: 12350, Loss: -184.336669922\n",
      "Iteration: 12360, Loss: -175.513671875\n",
      "Iteration: 12370, Loss: -190.848449707\n",
      "Iteration: 12380, Loss: -178.773590088\n",
      "Iteration: 12390, Loss: -175.110870361\n",
      "Iteration: 12400, Loss: -174.411102295\n",
      "Iteration: 12410, Loss: -172.596237183\n",
      "Iteration: 12420, Loss: -176.432296753\n",
      "Iteration: 12430, Loss: -173.474914551\n",
      "Iteration: 12440, Loss: -185.811035156\n",
      "Iteration: 12450, Loss: -174.397827148\n",
      "Iteration: 12460, Loss: -180.392150879\n",
      "Iteration: 12470, Loss: -160.488220215\n",
      "Iteration: 12480, Loss: -178.127975464\n",
      "Iteration: 12490, Loss: -177.835388184\n",
      "Iteration: 12500, Loss: -184.813247681\n",
      "Iteration: 12510, Loss: -179.430618286\n",
      "Iteration: 12520, Loss: -184.08996582\n",
      "Iteration: 12530, Loss: -195.019775391\n",
      "Iteration: 12540, Loss: -179.753234863\n",
      "Iteration: 12550, Loss: -181.863983154\n",
      "Iteration: 12560, Loss: -172.602600098\n",
      "Iteration: 12570, Loss: -220.513061523\n",
      "Iteration: 12580, Loss: -193.505249023\n",
      "Iteration: 12590, Loss: -190.977661133\n",
      "Iteration: 12600, Loss: -182.601959229\n",
      "Iteration: 12610, Loss: -186.304229736\n",
      "Iteration: 12620, Loss: -192.452148438\n",
      "Iteration: 12630, Loss: -196.995330811\n",
      "Iteration: 12640, Loss: -180.599029541\n",
      "Iteration: 12650, Loss: -180.76385498\n",
      "Iteration: 12660, Loss: -178.698867798\n",
      "Iteration: 12670, Loss: -189.715270996\n",
      "Iteration: 12680, Loss: -180.211730957\n",
      "Iteration: 12690, Loss: -180.84854126\n",
      "Iteration: 12700, Loss: -189.013183594\n",
      "Iteration: 12710, Loss: -176.065429688\n",
      "Iteration: 12720, Loss: -172.132995605\n",
      "Iteration: 12730, Loss: -175.447463989\n",
      "Iteration: 12740, Loss: -167.062957764\n",
      "Iteration: 12750, Loss: -188.719299316\n",
      "Iteration: 12760, Loss: -177.058670044\n",
      "Iteration: 12770, Loss: -168.241882324\n",
      "Iteration: 12780, Loss: -183.822021484\n",
      "Iteration: 12790, Loss: -162.733001709\n",
      "Iteration: 12800, Loss: -193.319458008\n",
      "Iteration: 12810, Loss: -179.190856934\n",
      "Iteration: 12820, Loss: -180.497131348\n",
      "Iteration: 12830, Loss: -178.967559814\n",
      "Iteration: 12840, Loss: -178.896026611\n",
      "Iteration: 12850, Loss: -172.133483887\n",
      "Iteration: 12860, Loss: -173.457061768\n",
      "Iteration: 12870, Loss: -182.546478271\n",
      "Iteration: 12880, Loss: -178.517669678\n",
      "Iteration: 12890, Loss: -167.110595703\n",
      "Iteration: 12900, Loss: -178.824188232\n",
      "Iteration: 12910, Loss: -182.393371582\n",
      "Iteration: 12920, Loss: -184.990600586\n",
      "Iteration: 12930, Loss: -173.54309082\n",
      "Iteration: 12940, Loss: -177.842651367\n",
      "Iteration: 12950, Loss: -185.776931763\n",
      "Iteration: 12960, Loss: -181.778594971\n",
      "Iteration: 12970, Loss: -183.162780762\n",
      "Iteration: 12980, Loss: -189.424621582\n",
      "Iteration: 12990, Loss: -186.605606079\n",
      "Iteration: 13000, Loss: -181.783416748\n",
      "Iteration: 13010, Loss: -170.74382019\n",
      "Iteration: 13020, Loss: -173.180877686\n",
      "Iteration: 13030, Loss: -178.294189453\n",
      "Iteration: 13040, Loss: -181.87387085\n",
      "Iteration: 13050, Loss: -157.86328125\n",
      "Iteration: 13060, Loss: -161.150054932\n",
      "Iteration: 13070, Loss: -165.588973999\n",
      "Iteration: 13080, Loss: -186.66078186\n",
      "Iteration: 13090, Loss: -175.191101074\n",
      "Iteration: 13100, Loss: -179.597320557\n",
      "Iteration: 13110, Loss: -159.630966187\n",
      "Iteration: 13120, Loss: -186.903045654\n",
      "Iteration: 13130, Loss: -163.053482056\n",
      "Iteration: 13140, Loss: -170.301971436\n",
      "Iteration: 13150, Loss: -184.773406982\n",
      "Iteration: 13160, Loss: -187.203109741\n",
      "Iteration: 13170, Loss: -164.817443848\n",
      "Iteration: 13180, Loss: -177.938430786\n",
      "Iteration: 13190, Loss: -170.618103027\n",
      "Iteration: 13200, Loss: -176.858596802\n",
      "Iteration: 13210, Loss: -195.379364014\n",
      "Iteration: 13220, Loss: -172.249389648\n",
      "Iteration: 13230, Loss: -188.105224609\n",
      "Iteration: 13240, Loss: -172.000411987\n",
      "Iteration: 13250, Loss: -179.170928955\n",
      "Iteration: 13260, Loss: -165.336227417\n",
      "Iteration: 13270, Loss: -186.131515503\n",
      "Iteration: 13280, Loss: -180.855529785\n",
      "Iteration: 13290, Loss: -183.397369385\n",
      "Iteration: 13300, Loss: -177.000061035\n",
      "Iteration: 13310, Loss: -166.517837524\n",
      "Iteration: 13320, Loss: -173.589935303\n",
      "Iteration: 13330, Loss: -164.334487915\n",
      "Iteration: 13340, Loss: -209.40322876\n",
      "Iteration: 13350, Loss: -168.521316528\n",
      "Iteration: 13360, Loss: -170.40725708\n",
      "Iteration: 13370, Loss: -186.6665802\n",
      "Iteration: 13380, Loss: -186.457977295\n",
      "Iteration: 13390, Loss: -181.905456543\n",
      "Iteration: 13400, Loss: -179.126586914\n",
      "Iteration: 13410, Loss: -174.087982178\n",
      "Iteration: 13420, Loss: -188.203491211\n",
      "Iteration: 13430, Loss: -176.779922485\n",
      "Iteration: 13440, Loss: -175.03616333\n",
      "Iteration: 13450, Loss: -172.066925049\n",
      "Iteration: 13460, Loss: -174.299133301\n",
      "Iteration: 13470, Loss: -178.29385376\n",
      "Iteration: 13480, Loss: -173.720092773\n",
      "Iteration: 13490, Loss: -175.929168701\n",
      "Iteration: 13500, Loss: -171.395355225\n",
      "Iteration: 13510, Loss: -192.487487793\n",
      "Iteration: 13520, Loss: -183.688903809\n",
      "Iteration: 13530, Loss: -186.848876953\n",
      "Iteration: 13540, Loss: -175.205383301\n",
      "Iteration: 13550, Loss: -173.43762207\n",
      "Iteration: 13560, Loss: -174.414031982\n",
      "Iteration: 13570, Loss: -161.500717163\n",
      "Iteration: 13580, Loss: -175.69670105\n",
      "Iteration: 13590, Loss: -171.304885864\n",
      "Iteration: 13600, Loss: -176.695831299\n",
      "Iteration: 13610, Loss: -171.142028809\n",
      "Iteration: 13620, Loss: -176.080322266\n",
      "Iteration: 13630, Loss: -174.520706177\n",
      "Iteration: 13640, Loss: -182.756698608\n",
      "Iteration: 13650, Loss: -175.585098267\n",
      "Iteration: 13660, Loss: -170.086776733\n",
      "Iteration: 13670, Loss: -166.928085327\n",
      "Iteration: 13680, Loss: -185.806152344\n",
      "Iteration: 13690, Loss: -172.34312439\n",
      "Iteration: 13700, Loss: -180.4894104\n",
      "Iteration: 13710, Loss: -180.180603027\n",
      "Iteration: 13720, Loss: -166.867263794\n",
      "Iteration: 13730, Loss: -164.456390381\n",
      "Iteration: 13740, Loss: -174.283065796\n",
      "Iteration: 13750, Loss: -175.322235107\n",
      "Iteration: 13760, Loss: -178.531539917\n",
      "Iteration: 13770, Loss: -181.356552124\n",
      "Iteration: 13780, Loss: -181.754974365\n",
      "Iteration: 13790, Loss: -177.540084839\n",
      "Iteration: 13800, Loss: -188.344085693\n",
      "Iteration: 13810, Loss: -182.835906982\n",
      "Iteration: 13820, Loss: -158.534851074\n",
      "Iteration: 13830, Loss: -184.97744751\n",
      "Iteration: 13840, Loss: -163.929351807\n",
      "Iteration: 13850, Loss: -161.41746521\n",
      "Iteration: 13860, Loss: -168.94354248\n",
      "Iteration: 13870, Loss: -175.916564941\n",
      "Iteration: 13880, Loss: -164.220153809\n",
      "Iteration: 13890, Loss: -160.107315063\n",
      "Iteration: 13900, Loss: -167.764160156\n",
      "Iteration: 13910, Loss: -162.814453125\n",
      "Iteration: 13920, Loss: -184.657791138\n",
      "Iteration: 13930, Loss: -159.488891602\n",
      "Iteration: 13940, Loss: -177.28024292\n",
      "Iteration: 13950, Loss: -185.298919678\n",
      "Iteration: 13960, Loss: -180.721328735\n",
      "Iteration: 13970, Loss: -189.002227783\n",
      "Iteration: 13980, Loss: -154.747207642\n",
      "Iteration: 13990, Loss: -166.248657227\n",
      "Iteration: 14000, Loss: -174.114028931\n",
      "Iteration: 14010, Loss: -171.479400635\n",
      "Iteration: 14020, Loss: -166.3565979\n",
      "Iteration: 14030, Loss: -190.509185791\n",
      "Iteration: 14040, Loss: -167.771942139\n",
      "Iteration: 14050, Loss: -172.524017334\n",
      "Iteration: 14060, Loss: -167.18699646\n",
      "Iteration: 14070, Loss: -186.338562012\n",
      "Iteration: 14080, Loss: -174.701675415\n",
      "Iteration: 14090, Loss: -159.605682373\n",
      "Iteration: 14100, Loss: -183.475021362\n",
      "Iteration: 14110, Loss: -174.189071655\n",
      "Iteration: 14120, Loss: -184.510818481\n",
      "Iteration: 14130, Loss: -176.219497681\n",
      "Iteration: 14140, Loss: -176.875152588\n",
      "Iteration: 14150, Loss: -178.238449097\n",
      "Iteration: 14160, Loss: -169.341644287\n",
      "Iteration: 14170, Loss: -166.700042725\n",
      "Iteration: 14180, Loss: -173.968261719\n",
      "Iteration: 14190, Loss: -178.535812378\n",
      "Iteration: 14200, Loss: -184.50163269\n",
      "Iteration: 14210, Loss: -176.094421387\n",
      "Iteration: 14220, Loss: -196.067016602\n",
      "Iteration: 14230, Loss: -177.047271729\n",
      "Iteration: 14240, Loss: -180.170944214\n",
      "Iteration: 14250, Loss: -172.106109619\n",
      "Iteration: 14260, Loss: -185.068817139\n",
      "Iteration: 14270, Loss: -177.719436646\n",
      "Iteration: 14280, Loss: -162.005889893\n",
      "Iteration: 14290, Loss: -183.743835449\n",
      "Iteration: 14300, Loss: -177.574874878\n",
      "Iteration: 14310, Loss: -164.543792725\n",
      "Iteration: 14320, Loss: -178.838317871\n",
      "Iteration: 14330, Loss: -192.501815796\n",
      "Iteration: 14340, Loss: -163.091552734\n",
      "Iteration: 14350, Loss: -180.514556885\n",
      "Iteration: 14360, Loss: -171.592926025\n",
      "Iteration: 14370, Loss: -180.000091553\n",
      "Iteration: 14380, Loss: -187.909729004\n",
      "Iteration: 14390, Loss: -190.99810791\n",
      "Iteration: 14400, Loss: -170.711212158\n",
      "Iteration: 14410, Loss: -175.27154541\n",
      "Iteration: 14420, Loss: -153.675811768\n",
      "Iteration: 14430, Loss: -196.803131104\n",
      "Iteration: 14440, Loss: -174.251571655\n",
      "Iteration: 14450, Loss: -174.418533325\n",
      "Iteration: 14460, Loss: -193.624481201\n",
      "Iteration: 14470, Loss: -170.99546814\n",
      "Iteration: 14480, Loss: -182.283569336\n",
      "Iteration: 14490, Loss: -168.573699951\n",
      "Iteration: 14500, Loss: -165.356384277\n",
      "Iteration: 14510, Loss: -164.347091675\n",
      "Iteration: 14520, Loss: -171.968109131\n",
      "Iteration: 14530, Loss: -167.634918213\n",
      "Iteration: 14540, Loss: -180.495544434\n",
      "Iteration: 14550, Loss: -168.823944092\n",
      "Iteration: 14560, Loss: -174.112686157\n",
      "Iteration: 14570, Loss: -165.837844849\n",
      "Iteration: 14580, Loss: -177.633422852\n",
      "Iteration: 14590, Loss: -184.629440308\n",
      "Iteration: 14600, Loss: -180.720794678\n",
      "Iteration: 14610, Loss: -185.287765503\n",
      "Iteration: 14620, Loss: -164.904998779\n",
      "Iteration: 14630, Loss: -161.546890259\n",
      "Iteration: 14640, Loss: -159.129058838\n",
      "Iteration: 14650, Loss: -176.293884277\n",
      "Iteration: 14660, Loss: -172.430282593\n",
      "Iteration: 14670, Loss: -152.064971924\n",
      "Iteration: 14680, Loss: -170.859710693\n",
      "Iteration: 14690, Loss: -196.2003479\n",
      "Iteration: 14700, Loss: -161.257293701\n",
      "Iteration: 14710, Loss: -167.988861084\n",
      "Iteration: 14720, Loss: -177.059066772\n",
      "Iteration: 14730, Loss: -169.297576904\n",
      "Iteration: 14740, Loss: -164.781707764\n",
      "Iteration: 14750, Loss: -171.120483398\n",
      "Iteration: 14760, Loss: -175.194534302\n",
      "Iteration: 14770, Loss: -167.559326172\n",
      "Iteration: 14780, Loss: -164.496856689\n",
      "Iteration: 14790, Loss: -172.471191406\n",
      "Iteration: 14800, Loss: -158.29788208\n",
      "Iteration: 14810, Loss: -159.320404053\n",
      "Iteration: 14820, Loss: -179.204452515\n",
      "Iteration: 14830, Loss: -167.711456299\n",
      "Iteration: 14840, Loss: -162.608795166\n",
      "Iteration: 14850, Loss: -159.894958496\n",
      "Iteration: 14860, Loss: -177.715881348\n",
      "Iteration: 14870, Loss: -175.993164062\n",
      "Iteration: 14880, Loss: -175.321777344\n",
      "Iteration: 14890, Loss: -173.085083008\n",
      "Iteration: 14900, Loss: -160.526748657\n",
      "Iteration: 14910, Loss: -170.617355347\n",
      "Iteration: 14920, Loss: -167.653106689\n",
      "Iteration: 14930, Loss: -169.744354248\n",
      "Iteration: 14940, Loss: -167.009033203\n",
      "Iteration: 14950, Loss: -190.724639893\n",
      "Iteration: 14960, Loss: -183.510406494\n",
      "Iteration: 14970, Loss: -196.089355469\n",
      "Iteration: 14980, Loss: -164.715240479\n",
      "Iteration: 14990, Loss: -171.356185913\n",
      "Iteration: 15000, Loss: -182.720657349\n",
      "Iteration: 15010, Loss: -166.756546021\n",
      "Iteration: 15020, Loss: -169.493057251\n",
      "Iteration: 15030, Loss: -173.875854492\n",
      "Iteration: 15040, Loss: -177.781356812\n",
      "Iteration: 15050, Loss: -186.013671875\n",
      "Iteration: 15060, Loss: -175.066680908\n",
      "Iteration: 15070, Loss: -169.731903076\n",
      "Iteration: 15080, Loss: -162.988265991\n",
      "Iteration: 15090, Loss: -164.059753418\n",
      "Iteration: 15100, Loss: -171.719512939\n",
      "Iteration: 15110, Loss: -166.045822144\n",
      "Iteration: 15120, Loss: -188.562393188\n",
      "Iteration: 15130, Loss: -186.402435303\n",
      "Iteration: 15140, Loss: -155.981414795\n",
      "Iteration: 15150, Loss: -161.808776855\n",
      "Iteration: 15160, Loss: -166.366088867\n",
      "Iteration: 15170, Loss: -177.31930542\n",
      "Iteration: 15180, Loss: -168.981460571\n",
      "Iteration: 15190, Loss: -169.557312012\n",
      "Iteration: 15200, Loss: -168.694381714\n",
      "Iteration: 15210, Loss: -167.751159668\n",
      "Iteration: 15220, Loss: -169.373062134\n",
      "Iteration: 15230, Loss: -166.845443726\n",
      "Iteration: 15240, Loss: -163.052444458\n",
      "Iteration: 15250, Loss: -190.306488037\n",
      "Iteration: 15260, Loss: -169.413635254\n",
      "Iteration: 15270, Loss: -181.886505127\n",
      "Iteration: 15280, Loss: -174.065795898\n",
      "Iteration: 15290, Loss: -180.222900391\n",
      "Iteration: 15300, Loss: -176.397476196\n",
      "Iteration: 15310, Loss: -175.565582275\n",
      "Iteration: 15320, Loss: -170.920196533\n",
      "Iteration: 15330, Loss: -180.109481812\n",
      "Iteration: 15340, Loss: -185.102752686\n",
      "Iteration: 15350, Loss: -160.605239868\n",
      "Iteration: 15360, Loss: -179.003616333\n",
      "Iteration: 15370, Loss: -183.695678711\n",
      "Iteration: 15380, Loss: -151.59866333\n",
      "Iteration: 15390, Loss: -156.436279297\n",
      "Iteration: 15400, Loss: -170.471588135\n",
      "Iteration: 15410, Loss: -169.545043945\n",
      "Iteration: 15420, Loss: -187.159622192\n",
      "Iteration: 15430, Loss: -174.857833862\n",
      "Iteration: 15440, Loss: -172.364532471\n",
      "Iteration: 15450, Loss: -189.3097229\n",
      "Iteration: 15460, Loss: -172.894439697\n",
      "Iteration: 15470, Loss: -179.263214111\n",
      "Iteration: 15480, Loss: -164.429290771\n",
      "Iteration: 15490, Loss: -197.479797363\n",
      "Iteration: 15500, Loss: -184.628692627\n",
      "Iteration: 15510, Loss: -167.734222412\n",
      "Iteration: 15520, Loss: -183.594009399\n",
      "Iteration: 15530, Loss: -165.09274292\n",
      "Iteration: 15540, Loss: -180.156219482\n",
      "Iteration: 15550, Loss: -164.5440979\n",
      "Iteration: 15560, Loss: -153.475585938\n",
      "Iteration: 15570, Loss: -159.705856323\n",
      "Iteration: 15580, Loss: -162.909744263\n",
      "Iteration: 15590, Loss: -170.176330566\n",
      "Iteration: 15600, Loss: -159.355499268\n",
      "Iteration: 15610, Loss: -178.007553101\n",
      "Iteration: 15620, Loss: -165.710113525\n",
      "Iteration: 15630, Loss: -162.805480957\n",
      "Iteration: 15640, Loss: -174.259811401\n",
      "Iteration: 15650, Loss: -157.893493652\n",
      "Iteration: 15660, Loss: -162.29083252\n",
      "Iteration: 15670, Loss: -170.631622314\n",
      "Iteration: 15680, Loss: -178.391708374\n",
      "Iteration: 15690, Loss: -178.201721191\n",
      "Iteration: 15700, Loss: -171.759689331\n",
      "Iteration: 15710, Loss: -166.242889404\n",
      "Iteration: 15720, Loss: -175.789215088\n",
      "Iteration: 15730, Loss: -160.967758179\n",
      "Iteration: 15740, Loss: -164.073760986\n",
      "Iteration: 15750, Loss: -172.793426514\n",
      "Iteration: 15760, Loss: -170.485855103\n",
      "Iteration: 15770, Loss: -166.706085205\n",
      "Iteration: 15780, Loss: -162.429290771\n",
      "Iteration: 15790, Loss: -186.927566528\n",
      "Iteration: 15800, Loss: -149.071670532\n",
      "Iteration: 15810, Loss: -192.560668945\n",
      "Iteration: 15820, Loss: -210.754180908\n",
      "Iteration: 15830, Loss: -177.565185547\n",
      "Iteration: 15840, Loss: -202.167907715\n",
      "Iteration: 15850, Loss: -173.328857422\n",
      "Iteration: 15860, Loss: -169.976303101\n",
      "Iteration: 15870, Loss: -148.412475586\n",
      "Iteration: 15880, Loss: -182.320098877\n",
      "Iteration: 15890, Loss: -169.030883789\n",
      "Iteration: 15900, Loss: -172.8074646\n",
      "Iteration: 15910, Loss: -174.465072632\n",
      "Iteration: 15920, Loss: -166.639282227\n",
      "Iteration: 15930, Loss: -182.685073853\n",
      "Iteration: 15940, Loss: -150.563369751\n",
      "Iteration: 15950, Loss: -153.912719727\n",
      "Iteration: 15960, Loss: -153.735351562\n",
      "Iteration: 15970, Loss: -174.544570923\n",
      "Iteration: 15980, Loss: -173.756530762\n",
      "Iteration: 15990, Loss: -173.902282715\n",
      "Iteration: 16000, Loss: -148.683959961\n",
      "Iteration: 16010, Loss: -171.196777344\n",
      "Iteration: 16020, Loss: -174.132339478\n",
      "Iteration: 16030, Loss: -178.147628784\n",
      "Iteration: 16040, Loss: -183.84777832\n",
      "Iteration: 16050, Loss: -165.988265991\n",
      "Iteration: 16060, Loss: -190.664093018\n",
      "Iteration: 16070, Loss: -152.115097046\n",
      "Iteration: 16080, Loss: -172.007797241\n",
      "Iteration: 16090, Loss: -169.13885498\n",
      "Iteration: 16100, Loss: -174.934265137\n",
      "Iteration: 16110, Loss: -175.843933105\n",
      "Iteration: 16120, Loss: -181.508148193\n",
      "Iteration: 16130, Loss: -168.337585449\n",
      "Iteration: 16140, Loss: -175.188842773\n",
      "Iteration: 16150, Loss: -174.530822754\n",
      "Iteration: 16160, Loss: -171.973449707\n",
      "Iteration: 16170, Loss: -157.614562988\n",
      "Iteration: 16180, Loss: -184.980133057\n",
      "Iteration: 16190, Loss: -171.166610718\n",
      "Iteration: 16200, Loss: -170.630981445\n",
      "Iteration: 16210, Loss: -171.938217163\n",
      "Iteration: 16220, Loss: -169.688018799\n",
      "Iteration: 16230, Loss: -170.835083008\n",
      "Iteration: 16240, Loss: -153.692657471\n",
      "Iteration: 16250, Loss: -169.76222229\n",
      "Iteration: 16260, Loss: -180.281005859\n",
      "Iteration: 16270, Loss: -176.778106689\n",
      "Iteration: 16280, Loss: -158.449630737\n",
      "Iteration: 16290, Loss: -174.865859985\n",
      "Iteration: 16300, Loss: -166.374557495\n",
      "Iteration: 16310, Loss: -168.532440186\n",
      "Iteration: 16320, Loss: -175.868347168\n",
      "Iteration: 16330, Loss: -168.873321533\n",
      "Iteration: 16340, Loss: -164.50151062\n",
      "Iteration: 16350, Loss: -168.397888184\n",
      "Iteration: 16360, Loss: -184.599395752\n",
      "Iteration: 16370, Loss: -168.21963501\n",
      "Iteration: 16380, Loss: -176.657012939\n",
      "Iteration: 16390, Loss: -185.742523193\n",
      "Iteration: 16400, Loss: -180.99571228\n",
      "Iteration: 16410, Loss: -156.961273193\n",
      "Iteration: 16420, Loss: -161.738647461\n",
      "Iteration: 16430, Loss: -179.869415283\n",
      "Iteration: 16440, Loss: -177.049530029\n",
      "Iteration: 16450, Loss: -188.677902222\n",
      "Iteration: 16460, Loss: -193.29826355\n",
      "Iteration: 16470, Loss: -158.353713989\n",
      "Iteration: 16480, Loss: -180.649185181\n",
      "Iteration: 16490, Loss: -177.622436523\n",
      "Iteration: 16500, Loss: -184.961273193\n",
      "Iteration: 16510, Loss: -163.987335205\n",
      "Iteration: 16520, Loss: -165.019561768\n",
      "Iteration: 16530, Loss: -160.844894409\n",
      "Iteration: 16540, Loss: -184.086380005\n",
      "Iteration: 16550, Loss: -176.330474854\n",
      "Iteration: 16560, Loss: -171.180221558\n",
      "Iteration: 16570, Loss: -177.760803223\n",
      "Iteration: 16580, Loss: -177.612792969\n",
      "Iteration: 16590, Loss: -167.668151855\n",
      "Iteration: 16600, Loss: -169.093002319\n",
      "Iteration: 16610, Loss: -173.782073975\n",
      "Iteration: 16620, Loss: -169.914916992\n",
      "Iteration: 16630, Loss: -156.470550537\n",
      "Iteration: 16640, Loss: -181.650039673\n",
      "Iteration: 16650, Loss: -171.207275391\n",
      "Iteration: 16660, Loss: -163.380279541\n",
      "Iteration: 16670, Loss: -175.821182251\n",
      "Iteration: 16680, Loss: -168.250289917\n",
      "Iteration: 16690, Loss: -177.125747681\n",
      "Iteration: 16700, Loss: -187.872558594\n",
      "Iteration: 16710, Loss: -159.468826294\n",
      "Iteration: 16720, Loss: -177.993865967\n",
      "Iteration: 16730, Loss: -167.676300049\n",
      "Iteration: 16740, Loss: -170.079055786\n",
      "Iteration: 16750, Loss: -160.569763184\n",
      "Iteration: 16760, Loss: -162.811294556\n",
      "Iteration: 16770, Loss: -189.285583496\n",
      "Iteration: 16780, Loss: -175.311065674\n",
      "Iteration: 16790, Loss: -192.311584473\n",
      "Iteration: 16800, Loss: -168.251983643\n",
      "Iteration: 16810, Loss: -174.883453369\n",
      "Iteration: 16820, Loss: -169.681182861\n",
      "Iteration: 16830, Loss: -180.896942139\n",
      "Iteration: 16840, Loss: -183.557479858\n",
      "Iteration: 16850, Loss: -176.101516724\n",
      "Iteration: 16860, Loss: -176.749603271\n",
      "Iteration: 16870, Loss: -164.430236816\n",
      "Iteration: 16880, Loss: -172.299804688\n",
      "Iteration: 16890, Loss: -159.524536133\n",
      "Iteration: 16900, Loss: -169.311737061\n",
      "Iteration: 16910, Loss: -187.605499268\n",
      "Iteration: 16920, Loss: -182.049560547\n",
      "Iteration: 16930, Loss: -158.908966064\n",
      "Iteration: 16940, Loss: -167.272827148\n",
      "Iteration: 16950, Loss: -165.300369263\n",
      "Iteration: 16960, Loss: -157.164794922\n",
      "Iteration: 16970, Loss: -176.110412598\n",
      "Iteration: 16980, Loss: -155.185119629\n",
      "Iteration: 16990, Loss: -168.58114624\n",
      "Iteration: 17000, Loss: -166.662200928\n",
      "Iteration: 17010, Loss: -161.699478149\n",
      "Iteration: 17020, Loss: -167.655273438\n",
      "Iteration: 17030, Loss: -173.200836182\n",
      "Iteration: 17040, Loss: -156.4322052\n",
      "Iteration: 17050, Loss: -169.685943604\n",
      "Iteration: 17060, Loss: -174.378051758\n",
      "Iteration: 17070, Loss: -166.423294067\n",
      "Iteration: 17080, Loss: -173.75793457\n",
      "Iteration: 17090, Loss: -164.817886353\n",
      "Iteration: 17100, Loss: -165.83404541\n",
      "Iteration: 17110, Loss: -162.804199219\n",
      "Iteration: 17120, Loss: -166.272399902\n",
      "Iteration: 17130, Loss: -174.788330078\n",
      "Iteration: 17140, Loss: -166.186462402\n",
      "Iteration: 17150, Loss: -172.823654175\n",
      "Iteration: 17160, Loss: -168.682769775\n",
      "Iteration: 17170, Loss: -166.059143066\n",
      "Iteration: 17180, Loss: -200.713317871\n",
      "Iteration: 17190, Loss: -171.285888672\n",
      "Iteration: 17200, Loss: -152.036392212\n",
      "Iteration: 17210, Loss: -182.031036377\n",
      "Iteration: 17220, Loss: -160.736938477\n",
      "Iteration: 17230, Loss: -163.187057495\n",
      "Iteration: 17240, Loss: -172.433883667\n",
      "Iteration: 17250, Loss: -169.683746338\n",
      "Iteration: 17260, Loss: -161.36126709\n",
      "Iteration: 17270, Loss: -182.468353271\n",
      "Iteration: 17280, Loss: -186.170715332\n",
      "Iteration: 17290, Loss: -175.676193237\n",
      "Iteration: 17300, Loss: -160.353637695\n",
      "Iteration: 17310, Loss: -161.43649292\n",
      "Iteration: 17320, Loss: -179.951171875\n",
      "Iteration: 17330, Loss: -183.646148682\n",
      "Iteration: 17340, Loss: -177.583023071\n",
      "Iteration: 17350, Loss: -165.27734375\n",
      "Iteration: 17360, Loss: -162.356567383\n",
      "Iteration: 17370, Loss: -183.824249268\n",
      "Iteration: 17380, Loss: -165.643951416\n",
      "Iteration: 17390, Loss: -180.023162842\n",
      "Iteration: 17400, Loss: -170.632614136\n",
      "Iteration: 17410, Loss: -176.790435791\n",
      "Iteration: 17420, Loss: -158.003082275\n",
      "Iteration: 17430, Loss: -171.423477173\n",
      "Iteration: 17440, Loss: -166.173156738\n",
      "Iteration: 17450, Loss: -173.662567139\n",
      "Iteration: 17460, Loss: -166.76751709\n",
      "Iteration: 17470, Loss: -163.831710815\n",
      "Iteration: 17480, Loss: -172.773727417\n",
      "Iteration: 17490, Loss: -165.494415283\n",
      "Iteration: 17500, Loss: -166.316558838\n",
      "Iteration: 17510, Loss: -162.529632568\n",
      "Iteration: 17520, Loss: -174.452148438\n",
      "Iteration: 17530, Loss: -159.204788208\n",
      "Iteration: 17540, Loss: -161.27822876\n",
      "Iteration: 17550, Loss: -171.673065186\n",
      "Iteration: 17560, Loss: -185.091003418\n",
      "Iteration: 17570, Loss: -181.237625122\n",
      "Iteration: 17580, Loss: -168.894592285\n",
      "Iteration: 17590, Loss: -171.823043823\n",
      "Iteration: 17600, Loss: -171.350097656\n",
      "Iteration: 17610, Loss: -157.469787598\n",
      "Iteration: 17620, Loss: -184.9765625\n",
      "Iteration: 17630, Loss: -158.441131592\n",
      "Iteration: 17640, Loss: -154.223007202\n",
      "Iteration: 17650, Loss: -163.024002075\n",
      "Iteration: 17660, Loss: -164.982315063\n",
      "Iteration: 17670, Loss: -158.288848877\n",
      "Iteration: 17680, Loss: -153.785049438\n",
      "Iteration: 17690, Loss: -159.415878296\n",
      "Iteration: 17700, Loss: -175.533966064\n",
      "Iteration: 17710, Loss: -171.746154785\n",
      "Iteration: 17720, Loss: -169.568634033\n",
      "Iteration: 17730, Loss: -175.942672729\n",
      "Iteration: 17740, Loss: -177.76625061\n",
      "Iteration: 17750, Loss: -168.022781372\n",
      "Iteration: 17760, Loss: -152.928619385\n",
      "Iteration: 17770, Loss: -154.049987793\n",
      "Iteration: 17780, Loss: -169.987365723\n",
      "Iteration: 17790, Loss: -172.992614746\n",
      "Iteration: 17800, Loss: -167.40814209\n",
      "Iteration: 17810, Loss: -160.510406494\n",
      "Iteration: 17820, Loss: -167.562362671\n",
      "Iteration: 17830, Loss: -168.486465454\n",
      "Iteration: 17840, Loss: -174.732452393\n",
      "Iteration: 17850, Loss: -153.561691284\n",
      "Iteration: 17860, Loss: -166.537734985\n",
      "Iteration: 17870, Loss: -167.714553833\n",
      "Iteration: 17880, Loss: -170.193878174\n",
      "Iteration: 17890, Loss: -164.330780029\n",
      "Iteration: 17900, Loss: -179.958190918\n",
      "Iteration: 17910, Loss: -163.519165039\n",
      "Iteration: 17920, Loss: -167.330963135\n",
      "Iteration: 17930, Loss: -177.66166687\n",
      "Iteration: 17940, Loss: -168.500274658\n",
      "Iteration: 17950, Loss: -166.899627686\n",
      "Iteration: 17960, Loss: -174.212799072\n",
      "Iteration: 17970, Loss: -173.998840332\n",
      "Iteration: 17980, Loss: -168.654769897\n",
      "Iteration: 17990, Loss: -175.26373291\n",
      "Iteration: 18000, Loss: -182.369384766\n",
      "Iteration: 18010, Loss: -170.384063721\n",
      "Iteration: 18020, Loss: -172.218200684\n",
      "Iteration: 18030, Loss: -167.842987061\n",
      "Iteration: 18040, Loss: -170.844955444\n",
      "Iteration: 18050, Loss: -158.060882568\n",
      "Iteration: 18060, Loss: -165.214248657\n",
      "Iteration: 18070, Loss: -165.18258667\n",
      "Iteration: 18080, Loss: -161.304000854\n",
      "Iteration: 18090, Loss: -170.481842041\n",
      "Iteration: 18100, Loss: -179.266082764\n",
      "Iteration: 18110, Loss: -173.105743408\n",
      "Iteration: 18120, Loss: -141.75302124\n",
      "Iteration: 18130, Loss: -168.457901001\n",
      "Iteration: 18140, Loss: -165.272766113\n",
      "Iteration: 18150, Loss: -188.902374268\n",
      "Iteration: 18160, Loss: -177.04776001\n",
      "Iteration: 18170, Loss: -171.384124756\n",
      "Iteration: 18180, Loss: -177.070983887\n",
      "Iteration: 18190, Loss: -168.206481934\n",
      "Iteration: 18200, Loss: -171.095977783\n",
      "Iteration: 18210, Loss: -173.06451416\n",
      "Iteration: 18220, Loss: -179.271850586\n",
      "Iteration: 18230, Loss: -170.026992798\n",
      "Iteration: 18240, Loss: -174.674346924\n",
      "Iteration: 18250, Loss: -172.80871582\n",
      "Iteration: 18260, Loss: -158.780426025\n",
      "Iteration: 18270, Loss: -170.655197144\n",
      "Iteration: 18280, Loss: -176.746810913\n",
      "Iteration: 18290, Loss: -172.191345215\n",
      "Iteration: 18300, Loss: -160.277191162\n",
      "Iteration: 18310, Loss: -162.792541504\n",
      "Iteration: 18320, Loss: -170.414932251\n",
      "Iteration: 18330, Loss: -156.018463135\n",
      "Iteration: 18340, Loss: -164.907958984\n",
      "Iteration: 18350, Loss: -148.676040649\n",
      "Iteration: 18360, Loss: -167.417907715\n",
      "Iteration: 18370, Loss: -189.941986084\n",
      "Iteration: 18380, Loss: -191.578018188\n",
      "Iteration: 18390, Loss: -179.055114746\n",
      "Iteration: 18400, Loss: -167.635559082\n",
      "Iteration: 18410, Loss: -185.214691162\n",
      "Iteration: 18420, Loss: -158.371765137\n",
      "Iteration: 18430, Loss: -175.451782227\n",
      "Iteration: 18440, Loss: -167.839080811\n",
      "Iteration: 18450, Loss: -170.855651855\n",
      "Iteration: 18460, Loss: -167.009613037\n",
      "Iteration: 18470, Loss: -163.4949646\n",
      "Iteration: 18480, Loss: -151.819061279\n",
      "Iteration: 18490, Loss: -174.39364624\n",
      "Iteration: 18500, Loss: -162.531707764\n",
      "Iteration: 18510, Loss: -163.120620728\n",
      "Iteration: 18520, Loss: -158.339065552\n",
      "Iteration: 18530, Loss: -177.96005249\n",
      "Iteration: 18540, Loss: -139.86656189\n",
      "Iteration: 18550, Loss: -164.966461182\n",
      "Iteration: 18560, Loss: -157.132003784\n",
      "Iteration: 18570, Loss: -163.9737854\n",
      "Iteration: 18580, Loss: -175.877502441\n",
      "Iteration: 18590, Loss: -162.763076782\n",
      "Iteration: 18600, Loss: -151.115371704\n",
      "Iteration: 18610, Loss: -154.447479248\n",
      "Iteration: 18620, Loss: -170.430633545\n",
      "Iteration: 18630, Loss: -175.629119873\n",
      "Iteration: 18640, Loss: -191.359207153\n",
      "Iteration: 18650, Loss: -160.99887085\n",
      "Iteration: 18660, Loss: -158.383148193\n",
      "Iteration: 18670, Loss: -171.728546143\n",
      "Iteration: 18680, Loss: -182.834487915\n",
      "Iteration: 18690, Loss: -175.749084473\n",
      "Iteration: 18700, Loss: -171.569168091\n",
      "Iteration: 18710, Loss: -164.416366577\n",
      "Iteration: 18720, Loss: -156.039489746\n",
      "Iteration: 18730, Loss: -157.099838257\n",
      "Iteration: 18740, Loss: -175.17918396\n",
      "Iteration: 18750, Loss: -154.227615356\n",
      "Iteration: 18760, Loss: -176.4425354\n",
      "Iteration: 18770, Loss: -165.232803345\n",
      "Iteration: 18780, Loss: -172.157745361\n",
      "Iteration: 18790, Loss: -171.152557373\n",
      "Iteration: 18800, Loss: -159.670608521\n",
      "Iteration: 18810, Loss: -167.03137207\n",
      "Iteration: 18820, Loss: -149.442550659\n",
      "Iteration: 18830, Loss: -178.323455811\n",
      "Iteration: 18840, Loss: -176.286987305\n",
      "Iteration: 18850, Loss: -175.758209229\n",
      "Iteration: 18860, Loss: -169.0753479\n",
      "Iteration: 18870, Loss: -175.919265747\n",
      "Iteration: 18880, Loss: -165.529647827\n",
      "Iteration: 18890, Loss: -162.907501221\n",
      "Iteration: 18900, Loss: -170.496765137\n",
      "Iteration: 18910, Loss: -167.105407715\n",
      "Iteration: 18920, Loss: -165.901428223\n",
      "Iteration: 18930, Loss: -191.867156982\n",
      "Iteration: 18940, Loss: -169.305145264\n",
      "Iteration: 18950, Loss: -155.387680054\n",
      "Iteration: 18960, Loss: -167.592803955\n",
      "Iteration: 18970, Loss: -164.615829468\n",
      "Iteration: 18980, Loss: -178.443054199\n",
      "Iteration: 18990, Loss: -169.957946777\n",
      "Iteration: 19000, Loss: -189.084762573\n",
      "Iteration: 19010, Loss: -145.254394531\n",
      "Iteration: 19020, Loss: -170.705047607\n",
      "Iteration: 19030, Loss: -170.7734375\n",
      "Iteration: 19040, Loss: -163.617172241\n",
      "Iteration: 19050, Loss: -143.311019897\n",
      "Iteration: 19060, Loss: -166.249160767\n",
      "Iteration: 19070, Loss: -181.963134766\n",
      "Iteration: 19080, Loss: -152.791259766\n",
      "Iteration: 19090, Loss: -164.092041016\n",
      "Iteration: 19100, Loss: -161.835998535\n",
      "Iteration: 19110, Loss: -166.73034668\n",
      "Iteration: 19120, Loss: -156.253387451\n",
      "Iteration: 19130, Loss: -164.641571045\n",
      "Iteration: 19140, Loss: -169.504974365\n",
      "Iteration: 19150, Loss: -163.129638672\n",
      "Iteration: 19160, Loss: -189.790756226\n",
      "Iteration: 19170, Loss: -155.111236572\n",
      "Iteration: 19180, Loss: -161.795181274\n",
      "Iteration: 19190, Loss: -166.936691284\n",
      "Iteration: 19200, Loss: -177.601013184\n",
      "Iteration: 19210, Loss: -167.228240967\n",
      "Iteration: 19220, Loss: -169.931854248\n",
      "Iteration: 19230, Loss: -182.354553223\n",
      "Iteration: 19240, Loss: -158.844863892\n",
      "Iteration: 19250, Loss: -178.935546875\n",
      "Iteration: 19260, Loss: -157.749343872\n",
      "Iteration: 19270, Loss: -150.721496582\n",
      "Iteration: 19280, Loss: -173.8387146\n",
      "Iteration: 19290, Loss: -170.443756104\n",
      "Iteration: 19300, Loss: -157.278213501\n",
      "Iteration: 19310, Loss: -159.853210449\n",
      "Iteration: 19320, Loss: -168.009597778\n",
      "Iteration: 19330, Loss: -169.727203369\n",
      "Iteration: 19340, Loss: -170.263015747\n",
      "Iteration: 19350, Loss: -162.733612061\n",
      "Iteration: 19360, Loss: -169.600204468\n",
      "Iteration: 19370, Loss: -175.639297485\n",
      "Iteration: 19380, Loss: -160.661560059\n",
      "Iteration: 19390, Loss: -167.704986572\n",
      "Iteration: 19400, Loss: -173.000274658\n",
      "Iteration: 19410, Loss: -162.343841553\n",
      "Iteration: 19420, Loss: -169.137451172\n",
      "Iteration: 19430, Loss: -154.483581543\n",
      "Iteration: 19440, Loss: -172.542510986\n",
      "Iteration: 19450, Loss: -171.325057983\n",
      "Iteration: 19460, Loss: -150.794281006\n",
      "Iteration: 19470, Loss: -164.917648315\n",
      "Iteration: 19480, Loss: -163.277099609\n",
      "Iteration: 19490, Loss: -153.92930603\n",
      "Iteration: 19500, Loss: -171.912963867\n",
      "Iteration: 19510, Loss: -183.253234863\n",
      "Iteration: 19520, Loss: -165.995880127\n",
      "Iteration: 19530, Loss: -159.804824829\n",
      "Iteration: 19540, Loss: -159.790969849\n",
      "Iteration: 19550, Loss: -171.802062988\n",
      "Iteration: 19560, Loss: -177.113174438\n",
      "Iteration: 19570, Loss: -192.160949707\n",
      "Iteration: 19580, Loss: -156.035949707\n",
      "Iteration: 19590, Loss: -165.767745972\n",
      "Iteration: 19600, Loss: -175.456695557\n",
      "Iteration: 19610, Loss: -169.766418457\n",
      "Iteration: 19620, Loss: -165.049423218\n",
      "Iteration: 19630, Loss: -168.856445312\n",
      "Iteration: 19640, Loss: -175.614471436\n",
      "Iteration: 19650, Loss: -162.239776611\n",
      "Iteration: 19660, Loss: -175.663879395\n",
      "Iteration: 19670, Loss: -161.616638184\n",
      "Iteration: 19680, Loss: -175.748718262\n",
      "Iteration: 19690, Loss: -157.659805298\n",
      "Iteration: 19700, Loss: -164.878692627\n",
      "Iteration: 19710, Loss: -138.013671875\n",
      "Iteration: 19720, Loss: -171.712646484\n",
      "Iteration: 19730, Loss: -170.401580811\n",
      "Iteration: 19740, Loss: -156.793548584\n",
      "Iteration: 19750, Loss: -162.79624939\n",
      "Iteration: 19760, Loss: -160.364227295\n",
      "Iteration: 19770, Loss: -156.468261719\n",
      "Iteration: 19780, Loss: -168.461288452\n",
      "Iteration: 19790, Loss: -162.882659912\n",
      "Iteration: 19800, Loss: -154.914520264\n",
      "Iteration: 19810, Loss: -165.28894043\n",
      "Iteration: 19820, Loss: -174.106613159\n",
      "Iteration: 19830, Loss: -163.538665771\n",
      "Iteration: 19840, Loss: -175.555358887\n",
      "Iteration: 19850, Loss: -179.420013428\n",
      "Iteration: 19860, Loss: -169.724731445\n",
      "Iteration: 19870, Loss: -159.460205078\n",
      "Iteration: 19880, Loss: -171.279724121\n",
      "Iteration: 19890, Loss: -176.070495605\n",
      "Iteration: 19900, Loss: -172.427978516\n",
      "Iteration: 19910, Loss: -168.0284729\n",
      "Iteration: 19920, Loss: -166.087005615\n",
      "Iteration: 19930, Loss: -167.583740234\n",
      "Iteration: 19940, Loss: -165.256072998\n",
      "Iteration: 19950, Loss: -160.689971924\n",
      "Iteration: 19960, Loss: -157.677734375\n",
      "Iteration: 19970, Loss: -162.119537354\n",
      "Iteration: 19980, Loss: -173.183349609\n",
      "Iteration: 19990, Loss: -173.615386963\n",
      "Iteration: 20000, Loss: -150.703491211\n",
      "Iteration: 20010, Loss: -174.573822021\n",
      "Iteration: 20020, Loss: -182.702545166\n",
      "Iteration: 20030, Loss: -166.220123291\n",
      "Iteration: 20040, Loss: -175.671066284\n",
      "Iteration: 20050, Loss: -163.554931641\n",
      "Iteration: 20060, Loss: -158.428619385\n",
      "Iteration: 20070, Loss: -170.070327759\n",
      "Iteration: 20080, Loss: -159.952697754\n",
      "Iteration: 20090, Loss: -170.892349243\n",
      "Iteration: 20100, Loss: -166.794082642\n",
      "Iteration: 20110, Loss: -171.248321533\n",
      "Iteration: 20120, Loss: -176.159606934\n",
      "Iteration: 20130, Loss: -173.227218628\n",
      "Iteration: 20140, Loss: -171.754928589\n",
      "Iteration: 20150, Loss: -174.609405518\n",
      "Iteration: 20160, Loss: -162.139678955\n",
      "Iteration: 20170, Loss: -161.773605347\n",
      "Iteration: 20180, Loss: -166.295379639\n",
      "Iteration: 20190, Loss: -171.194244385\n",
      "Iteration: 20200, Loss: -155.169342041\n",
      "Iteration: 20210, Loss: -146.361206055\n",
      "Iteration: 20220, Loss: -161.817596436\n",
      "Iteration: 20230, Loss: -165.300949097\n",
      "Iteration: 20240, Loss: -170.164840698\n",
      "Iteration: 20250, Loss: -147.585342407\n",
      "Iteration: 20260, Loss: -167.920288086\n",
      "Iteration: 20270, Loss: -143.711685181\n",
      "Iteration: 20280, Loss: -169.701705933\n",
      "Iteration: 20290, Loss: -155.6847229\n",
      "Iteration: 20300, Loss: -172.499176025\n",
      "Iteration: 20310, Loss: -163.58430481\n",
      "Iteration: 20320, Loss: -153.280639648\n",
      "Iteration: 20330, Loss: -173.195114136\n",
      "Iteration: 20340, Loss: -161.364273071\n",
      "Iteration: 20350, Loss: -189.559555054\n",
      "Iteration: 20360, Loss: -155.547576904\n",
      "Iteration: 20370, Loss: -180.652984619\n",
      "Iteration: 20380, Loss: -164.784545898\n",
      "Iteration: 20390, Loss: -163.791671753\n",
      "Iteration: 20400, Loss: -162.227600098\n",
      "Iteration: 20410, Loss: -162.794372559\n",
      "Iteration: 20420, Loss: -174.857421875\n",
      "Iteration: 20430, Loss: -167.739974976\n",
      "Iteration: 20440, Loss: -156.456970215\n",
      "Iteration: 20450, Loss: -178.550506592\n",
      "Iteration: 20460, Loss: -178.58883667\n",
      "Iteration: 20470, Loss: -164.642974854\n",
      "Iteration: 20480, Loss: -195.025878906\n",
      "Iteration: 20490, Loss: -181.638153076\n",
      "Iteration: 20500, Loss: -156.139648438\n",
      "Iteration: 20510, Loss: -159.675415039\n",
      "Iteration: 20520, Loss: -163.565093994\n",
      "Iteration: 20530, Loss: -164.472869873\n",
      "Iteration: 20540, Loss: -152.840209961\n",
      "Iteration: 20550, Loss: -154.972015381\n",
      "Iteration: 20560, Loss: -169.656539917\n",
      "Iteration: 20570, Loss: -157.371505737\n",
      "Iteration: 20580, Loss: -179.014511108\n",
      "Iteration: 20590, Loss: -156.090438843\n",
      "Iteration: 20600, Loss: -157.944381714\n",
      "Iteration: 20610, Loss: -159.105361938\n",
      "Iteration: 20620, Loss: -172.251068115\n",
      "Iteration: 20630, Loss: -159.447113037\n",
      "Iteration: 20640, Loss: -180.326187134\n",
      "Iteration: 20650, Loss: -170.526031494\n",
      "Iteration: 20660, Loss: -144.428863525\n",
      "Iteration: 20670, Loss: -163.286224365\n",
      "Iteration: 20680, Loss: -160.556335449\n",
      "Iteration: 20690, Loss: -156.055145264\n",
      "Iteration: 20700, Loss: -173.015167236\n",
      "Iteration: 20710, Loss: -161.038619995\n",
      "Iteration: 20720, Loss: -182.62651062\n",
      "Iteration: 20730, Loss: -158.704238892\n",
      "Iteration: 20740, Loss: -156.477325439\n",
      "Iteration: 20750, Loss: -168.139373779\n",
      "Iteration: 20760, Loss: -153.183700562\n",
      "Iteration: 20770, Loss: -162.923965454\n",
      "Iteration: 20780, Loss: -157.820037842\n",
      "Iteration: 20790, Loss: -161.84286499\n",
      "Iteration: 20800, Loss: -174.250701904\n",
      "Iteration: 20810, Loss: -170.709991455\n",
      "Iteration: 20820, Loss: -175.326477051\n",
      "Iteration: 20830, Loss: -169.313415527\n",
      "Iteration: 20840, Loss: -175.633636475\n",
      "Iteration: 20850, Loss: -173.398452759\n",
      "Iteration: 20860, Loss: -175.05015564\n",
      "Iteration: 20870, Loss: -162.730239868\n",
      "Iteration: 20880, Loss: -163.888809204\n",
      "Iteration: 20890, Loss: -153.450454712\n",
      "Iteration: 20900, Loss: -165.094024658\n",
      "Iteration: 20910, Loss: -178.32220459\n",
      "Iteration: 20920, Loss: -174.10975647\n",
      "Iteration: 20930, Loss: -163.925857544\n",
      "Iteration: 20940, Loss: -176.582733154\n",
      "Iteration: 20950, Loss: -164.722869873\n",
      "Iteration: 20960, Loss: -173.885406494\n",
      "Iteration: 20970, Loss: -149.319641113\n",
      "Iteration: 20980, Loss: -149.954666138\n",
      "Iteration: 20990, Loss: -156.28187561\n",
      "Iteration: 21000, Loss: -174.089828491\n",
      "Iteration: 21010, Loss: -174.679962158\n",
      "Iteration: 21020, Loss: -162.221069336\n",
      "Iteration: 21030, Loss: -168.196990967\n",
      "Iteration: 21040, Loss: -174.555328369\n",
      "Iteration: 21050, Loss: -171.265808105\n",
      "Iteration: 21060, Loss: -164.254974365\n",
      "Iteration: 21070, Loss: -177.082244873\n",
      "Iteration: 21080, Loss: -160.78868103\n",
      "Iteration: 21090, Loss: -168.924835205\n",
      "Iteration: 21100, Loss: -175.459060669\n",
      "Iteration: 21110, Loss: -171.122650146\n",
      "Iteration: 21120, Loss: -161.89630127\n",
      "Iteration: 21130, Loss: -168.571563721\n",
      "Iteration: 21140, Loss: -158.784301758\n",
      "Iteration: 21150, Loss: -164.27255249\n",
      "Iteration: 21160, Loss: -161.065490723\n",
      "Iteration: 21170, Loss: -169.265487671\n",
      "Iteration: 21180, Loss: -168.205673218\n",
      "Iteration: 21190, Loss: -158.895355225\n",
      "Iteration: 21200, Loss: -163.962402344\n",
      "Iteration: 21210, Loss: -176.465942383\n",
      "Iteration: 21220, Loss: -157.996749878\n",
      "Iteration: 21230, Loss: -164.932861328\n",
      "Iteration: 21240, Loss: -161.738708496\n",
      "Iteration: 21250, Loss: -157.99005127\n",
      "Iteration: 21260, Loss: -168.58430481\n",
      "Iteration: 21270, Loss: -159.223754883\n",
      "Iteration: 21280, Loss: -165.64704895\n",
      "Iteration: 21290, Loss: -170.833618164\n",
      "Iteration: 21300, Loss: -162.071411133\n",
      "Iteration: 21310, Loss: -162.667877197\n",
      "Iteration: 21320, Loss: -145.70300293\n",
      "Iteration: 21330, Loss: -160.916091919\n",
      "Iteration: 21340, Loss: -171.693069458\n",
      "Iteration: 21350, Loss: -151.450653076\n",
      "Iteration: 21360, Loss: -179.017684937\n",
      "Iteration: 21370, Loss: -164.650299072\n",
      "Iteration: 21380, Loss: -169.23828125\n",
      "Iteration: 21390, Loss: -168.294128418\n",
      "Iteration: 21400, Loss: -166.046615601\n",
      "Iteration: 21410, Loss: -174.187225342\n",
      "Iteration: 21420, Loss: -151.045288086\n",
      "Iteration: 21430, Loss: -168.750411987\n",
      "Iteration: 21440, Loss: -155.035766602\n",
      "Iteration: 21450, Loss: -164.337402344\n",
      "Iteration: 21460, Loss: -169.888336182\n",
      "Iteration: 21470, Loss: -159.246963501\n",
      "Iteration: 21480, Loss: -162.829116821\n",
      "Iteration: 21490, Loss: -186.472106934\n",
      "Iteration: 21500, Loss: -160.45892334\n",
      "Iteration: 21510, Loss: -161.099304199\n",
      "Iteration: 21520, Loss: -157.717819214\n",
      "Iteration: 21530, Loss: -143.741485596\n",
      "Iteration: 21540, Loss: -172.759048462\n",
      "Iteration: 21550, Loss: -155.072509766\n",
      "Iteration: 21560, Loss: -168.516372681\n",
      "Iteration: 21570, Loss: -159.573104858\n",
      "Iteration: 21580, Loss: -171.806991577\n",
      "Iteration: 21590, Loss: -162.636642456\n",
      "Iteration: 21600, Loss: -162.774871826\n",
      "Iteration: 21610, Loss: -181.058700562\n",
      "Iteration: 21620, Loss: -169.675430298\n",
      "Iteration: 21630, Loss: -155.211578369\n",
      "Iteration: 21640, Loss: -161.549194336\n",
      "Iteration: 21650, Loss: -167.113815308\n",
      "Iteration: 21660, Loss: -169.487548828\n",
      "Iteration: 21670, Loss: -150.606964111\n",
      "Iteration: 21680, Loss: -157.292404175\n",
      "Iteration: 21690, Loss: -158.412887573\n",
      "Iteration: 21700, Loss: -174.74508667\n",
      "Iteration: 21710, Loss: -162.895370483\n",
      "Iteration: 21720, Loss: -172.402648926\n",
      "Iteration: 21730, Loss: -177.308044434\n",
      "Iteration: 21740, Loss: -157.248535156\n",
      "Iteration: 21750, Loss: -154.410705566\n",
      "Iteration: 21760, Loss: -169.308486938\n",
      "Iteration: 21770, Loss: -163.214035034\n",
      "Iteration: 21780, Loss: -166.466247559\n",
      "Iteration: 21790, Loss: -159.113769531\n",
      "Iteration: 21800, Loss: -145.43296814\n",
      "Iteration: 21810, Loss: -157.24697876\n",
      "Iteration: 21820, Loss: -166.291366577\n",
      "Iteration: 21830, Loss: -168.779815674\n",
      "Iteration: 21840, Loss: -182.66027832\n",
      "Iteration: 21850, Loss: -164.34815979\n",
      "Iteration: 21860, Loss: -156.924285889\n",
      "Iteration: 21870, Loss: -168.661178589\n",
      "Iteration: 21880, Loss: -164.805877686\n",
      "Iteration: 21890, Loss: -168.657104492\n",
      "Iteration: 21900, Loss: -168.215942383\n",
      "Iteration: 21910, Loss: -157.75378418\n",
      "Iteration: 21920, Loss: -161.01159668\n",
      "Iteration: 21930, Loss: -159.433135986\n",
      "Iteration: 21940, Loss: -176.52734375\n",
      "Iteration: 21950, Loss: -164.013259888\n",
      "Iteration: 21960, Loss: -166.50378418\n",
      "Iteration: 21970, Loss: -151.527801514\n",
      "Iteration: 21980, Loss: -148.449584961\n",
      "Iteration: 21990, Loss: -158.561401367\n",
      "Iteration: 22000, Loss: -162.058502197\n",
      "Iteration: 22010, Loss: -152.816421509\n",
      "Iteration: 22020, Loss: -162.915985107\n",
      "Iteration: 22030, Loss: -170.363494873\n",
      "Iteration: 22040, Loss: -164.224060059\n",
      "Iteration: 22050, Loss: -175.092102051\n",
      "Iteration: 22060, Loss: -175.72277832\n",
      "Iteration: 22070, Loss: -161.063980103\n",
      "Iteration: 22080, Loss: -157.293716431\n",
      "Iteration: 22090, Loss: -176.008148193\n",
      "Iteration: 22100, Loss: -165.6199646\n",
      "Iteration: 22110, Loss: -172.477722168\n",
      "Iteration: 22120, Loss: -157.959899902\n",
      "Iteration: 22130, Loss: -160.733169556\n",
      "Iteration: 22140, Loss: -161.620300293\n",
      "Iteration: 22150, Loss: -162.958480835\n",
      "Iteration: 22160, Loss: -172.942474365\n",
      "Iteration: 22170, Loss: -169.184143066\n",
      "Iteration: 22180, Loss: -146.96963501\n",
      "Iteration: 22190, Loss: -164.815155029\n",
      "Iteration: 22200, Loss: -185.377624512\n",
      "Iteration: 22210, Loss: -157.451263428\n",
      "Iteration: 22220, Loss: -167.066375732\n",
      "Iteration: 22230, Loss: -153.613952637\n",
      "Iteration: 22240, Loss: -178.732788086\n",
      "Iteration: 22250, Loss: -181.117828369\n",
      "Iteration: 22260, Loss: -165.282089233\n",
      "Iteration: 22270, Loss: -147.971908569\n",
      "Iteration: 22280, Loss: -159.337127686\n",
      "Iteration: 22290, Loss: -152.674377441\n",
      "Iteration: 22300, Loss: -154.390457153\n",
      "Iteration: 22310, Loss: -170.686462402\n",
      "Iteration: 22320, Loss: -166.076324463\n",
      "Iteration: 22330, Loss: -186.76449585\n",
      "Iteration: 22340, Loss: -171.080551147\n",
      "Iteration: 22350, Loss: -161.597686768\n",
      "Iteration: 22360, Loss: -153.001846313\n",
      "Iteration: 22370, Loss: -161.581237793\n",
      "Iteration: 22380, Loss: -175.236190796\n",
      "Iteration: 22390, Loss: -166.946640015\n",
      "Iteration: 22400, Loss: -163.610626221\n",
      "Iteration: 22410, Loss: -158.720672607\n",
      "Iteration: 22420, Loss: -157.214019775\n",
      "Iteration: 22430, Loss: -166.021484375\n",
      "Iteration: 22440, Loss: -144.610717773\n",
      "Iteration: 22450, Loss: -152.542480469\n",
      "Iteration: 22460, Loss: -178.705123901\n",
      "Iteration: 22470, Loss: -175.471405029\n",
      "Iteration: 22480, Loss: -160.502029419\n",
      "Iteration: 22490, Loss: -158.20703125\n",
      "Iteration: 22500, Loss: -152.952682495\n",
      "Iteration: 22510, Loss: -152.601043701\n",
      "Iteration: 22520, Loss: -144.079681396\n",
      "Iteration: 22530, Loss: -169.49105835\n",
      "Iteration: 22540, Loss: -164.6769104\n",
      "Iteration: 22550, Loss: -150.128479004\n",
      "Iteration: 22560, Loss: -150.640930176\n",
      "Iteration: 22570, Loss: -156.683319092\n",
      "Iteration: 22580, Loss: -158.223434448\n",
      "Iteration: 22590, Loss: -160.377182007\n",
      "Iteration: 22600, Loss: -172.942184448\n",
      "Iteration: 22610, Loss: -162.798217773\n",
      "Iteration: 22620, Loss: -162.300750732\n",
      "Iteration: 22630, Loss: -170.356201172\n",
      "Iteration: 22640, Loss: -149.090454102\n",
      "Iteration: 22650, Loss: -154.938339233\n",
      "Iteration: 22660, Loss: -183.71762085\n",
      "Iteration: 22670, Loss: -162.585342407\n",
      "Iteration: 22680, Loss: -179.129455566\n",
      "Iteration: 22690, Loss: -177.360717773\n",
      "Iteration: 22700, Loss: -151.011657715\n",
      "Iteration: 22710, Loss: -165.014831543\n",
      "Iteration: 22720, Loss: -155.831802368\n",
      "Iteration: 22730, Loss: -166.383651733\n",
      "Iteration: 22740, Loss: -158.297393799\n",
      "Iteration: 22750, Loss: -153.134368896\n",
      "Iteration: 22760, Loss: -148.113967896\n",
      "Iteration: 22770, Loss: -152.237426758\n",
      "Iteration: 22780, Loss: -165.760314941\n",
      "Iteration: 22790, Loss: -162.545669556\n",
      "Iteration: 22800, Loss: -156.845474243\n",
      "Iteration: 22810, Loss: -169.556732178\n",
      "Iteration: 22820, Loss: -165.239624023\n",
      "Iteration: 22830, Loss: -155.264129639\n",
      "Iteration: 22840, Loss: -173.968566895\n",
      "Iteration: 22850, Loss: -165.283325195\n",
      "Iteration: 22860, Loss: -163.592590332\n",
      "Iteration: 22870, Loss: -160.872802734\n",
      "Iteration: 22880, Loss: -144.994567871\n",
      "Iteration: 22890, Loss: -173.643203735\n",
      "Iteration: 22900, Loss: -176.478149414\n",
      "Iteration: 22910, Loss: -187.146636963\n",
      "Iteration: 22920, Loss: -161.322875977\n",
      "Iteration: 22930, Loss: -163.164886475\n",
      "Iteration: 22940, Loss: -161.339050293\n",
      "Iteration: 22950, Loss: -186.057769775\n",
      "Iteration: 22960, Loss: -155.703857422\n",
      "Iteration: 22970, Loss: -152.219299316\n",
      "Iteration: 22980, Loss: -160.93031311\n",
      "Iteration: 22990, Loss: -164.563552856\n",
      "Iteration: 23000, Loss: -167.200073242\n",
      "Iteration: 23010, Loss: -155.86529541\n",
      "Iteration: 23020, Loss: -154.707550049\n",
      "Iteration: 23030, Loss: -154.103561401\n",
      "Iteration: 23040, Loss: -178.482543945\n",
      "Iteration: 23050, Loss: -159.962341309\n",
      "Iteration: 23060, Loss: -153.907104492\n",
      "Iteration: 23070, Loss: -158.234024048\n",
      "Iteration: 23080, Loss: -166.026184082\n",
      "Iteration: 23090, Loss: -187.806304932\n",
      "Iteration: 23100, Loss: -179.179748535\n",
      "Iteration: 23110, Loss: -167.334289551\n",
      "Iteration: 23120, Loss: -163.502075195\n",
      "Iteration: 23130, Loss: -152.748382568\n",
      "Iteration: 23140, Loss: -169.385543823\n",
      "Iteration: 23150, Loss: -162.429428101\n",
      "Iteration: 23160, Loss: -153.605773926\n",
      "Iteration: 23170, Loss: -161.764968872\n",
      "Iteration: 23180, Loss: -173.464126587\n",
      "Iteration: 23190, Loss: -168.95211792\n",
      "Iteration: 23200, Loss: -157.177734375\n",
      "Iteration: 23210, Loss: -156.694946289\n",
      "Iteration: 23220, Loss: -151.635131836\n",
      "Iteration: 23230, Loss: -163.875518799\n",
      "Iteration: 23240, Loss: -163.705841064\n",
      "Iteration: 23250, Loss: -152.900909424\n",
      "Iteration: 23260, Loss: -152.435424805\n",
      "Iteration: 23270, Loss: -176.345550537\n",
      "Iteration: 23280, Loss: -158.674758911\n",
      "Iteration: 23290, Loss: -146.891326904\n",
      "Iteration: 23300, Loss: -154.382904053\n",
      "Iteration: 23310, Loss: -162.567779541\n",
      "Iteration: 23320, Loss: -158.654769897\n",
      "Iteration: 23330, Loss: -166.240447998\n",
      "Iteration: 23340, Loss: -154.37008667\n",
      "Iteration: 23350, Loss: -159.688720703\n",
      "Iteration: 23360, Loss: -168.629241943\n",
      "Iteration: 23370, Loss: -173.593231201\n",
      "Iteration: 23380, Loss: -167.836303711\n",
      "Iteration: 23390, Loss: -162.868011475\n",
      "Iteration: 23400, Loss: -165.293777466\n",
      "Iteration: 23410, Loss: -159.436477661\n",
      "Iteration: 23420, Loss: -173.969680786\n",
      "Iteration: 23430, Loss: -154.761322021\n",
      "Iteration: 23440, Loss: -177.543060303\n",
      "Iteration: 23450, Loss: -166.918029785\n",
      "Iteration: 23460, Loss: -165.496063232\n",
      "Iteration: 23470, Loss: -161.539413452\n",
      "Iteration: 23480, Loss: -157.053146362\n",
      "Iteration: 23490, Loss: -155.243148804\n",
      "Iteration: 23500, Loss: -137.171508789\n",
      "Iteration: 23510, Loss: -147.502319336\n",
      "Iteration: 23520, Loss: -170.694076538\n",
      "Iteration: 23530, Loss: -151.900939941\n",
      "Iteration: 23540, Loss: -154.510528564\n",
      "Iteration: 23550, Loss: -154.68347168\n",
      "Iteration: 23560, Loss: -172.554748535\n",
      "Iteration: 23570, Loss: -154.678619385\n",
      "Iteration: 23580, Loss: -149.065628052\n",
      "Iteration: 23590, Loss: -164.458053589\n",
      "Iteration: 23600, Loss: -164.073303223\n",
      "Iteration: 23610, Loss: -177.444610596\n",
      "Iteration: 23620, Loss: -166.369003296\n",
      "Iteration: 23630, Loss: -170.286605835\n",
      "Iteration: 23640, Loss: -154.521331787\n",
      "Iteration: 23650, Loss: -150.424041748\n",
      "Iteration: 23660, Loss: -165.090835571\n",
      "Iteration: 23670, Loss: -153.38269043\n",
      "Iteration: 23680, Loss: -155.740814209\n",
      "Iteration: 23690, Loss: -166.852554321\n",
      "Iteration: 23700, Loss: -159.323059082\n",
      "Iteration: 23710, Loss: -178.110900879\n",
      "Iteration: 23720, Loss: -159.147674561\n",
      "Iteration: 23730, Loss: -168.658538818\n",
      "Iteration: 23740, Loss: -159.726074219\n",
      "Iteration: 23750, Loss: -156.229248047\n",
      "Iteration: 23760, Loss: -150.374679565\n",
      "Iteration: 23770, Loss: -143.239471436\n",
      "Iteration: 23780, Loss: -159.234954834\n",
      "Iteration: 23790, Loss: -160.602539062\n",
      "Iteration: 23800, Loss: -163.654418945\n",
      "Iteration: 23810, Loss: -168.038116455\n",
      "Iteration: 23820, Loss: -160.048858643\n",
      "Iteration: 23830, Loss: -159.342773438\n",
      "Iteration: 23840, Loss: -159.248001099\n",
      "Iteration: 23850, Loss: -166.183746338\n",
      "Iteration: 23860, Loss: -158.676879883\n",
      "Iteration: 23870, Loss: -156.38269043\n",
      "Iteration: 23880, Loss: -170.961746216\n",
      "Iteration: 23890, Loss: -163.530639648\n",
      "Iteration: 23900, Loss: -162.609741211\n",
      "Iteration: 23910, Loss: -160.848861694\n",
      "Iteration: 23920, Loss: -177.650756836\n",
      "Iteration: 23930, Loss: -175.064239502\n",
      "Iteration: 23940, Loss: -161.993652344\n",
      "Iteration: 23950, Loss: -152.160079956\n",
      "Iteration: 23960, Loss: -161.538848877\n",
      "Iteration: 23970, Loss: -153.38848877\n",
      "Iteration: 23980, Loss: -162.742599487\n",
      "Iteration: 23990, Loss: -164.758651733\n",
      "Iteration: 24000, Loss: -161.805114746\n",
      "Iteration: 24010, Loss: -163.128662109\n",
      "Iteration: 24020, Loss: -149.285858154\n",
      "Iteration: 24030, Loss: -156.326538086\n",
      "Iteration: 24040, Loss: -159.869491577\n",
      "Iteration: 24050, Loss: -154.53024292\n",
      "Iteration: 24060, Loss: -157.157821655\n",
      "Iteration: 24070, Loss: -164.207748413\n",
      "Iteration: 24080, Loss: -171.341110229\n",
      "Iteration: 24090, Loss: -169.477508545\n",
      "Iteration: 24100, Loss: -158.680419922\n",
      "Iteration: 24110, Loss: -153.195907593\n",
      "Iteration: 24120, Loss: -178.093231201\n",
      "Iteration: 24130, Loss: -168.966659546\n",
      "Iteration: 24140, Loss: -185.830825806\n",
      "Iteration: 24150, Loss: -161.651611328\n",
      "Iteration: 24160, Loss: -174.937652588\n",
      "Iteration: 24170, Loss: -177.796844482\n",
      "Iteration: 24180, Loss: -157.818389893\n",
      "Iteration: 24190, Loss: -153.454437256\n",
      "Iteration: 24200, Loss: -153.385223389\n",
      "Iteration: 24210, Loss: -154.172912598\n",
      "Iteration: 24220, Loss: -159.49609375\n",
      "Iteration: 24230, Loss: -166.27961731\n",
      "Iteration: 24240, Loss: -172.298187256\n",
      "Iteration: 24250, Loss: -164.32989502\n",
      "Iteration: 24260, Loss: -174.901153564\n",
      "Iteration: 24270, Loss: -156.311126709\n",
      "Iteration: 24280, Loss: -168.804443359\n",
      "Iteration: 24290, Loss: -160.103393555\n",
      "Iteration: 24300, Loss: -160.803833008\n",
      "Iteration: 24310, Loss: -162.482284546\n",
      "Iteration: 24320, Loss: -156.853271484\n",
      "Iteration: 24330, Loss: -157.549880981\n",
      "Iteration: 24340, Loss: -167.001922607\n",
      "Iteration: 24350, Loss: -152.733154297\n",
      "Iteration: 24360, Loss: -155.233520508\n",
      "Iteration: 24370, Loss: -174.40461731\n",
      "Iteration: 24380, Loss: -159.17288208\n",
      "Iteration: 24390, Loss: -157.311218262\n",
      "Iteration: 24400, Loss: -159.897689819\n",
      "Iteration: 24410, Loss: -169.104125977\n",
      "Iteration: 24420, Loss: -161.255187988\n",
      "Iteration: 24430, Loss: -175.37588501\n",
      "Iteration: 24440, Loss: -154.688949585\n",
      "Iteration: 24450, Loss: -164.685455322\n",
      "Iteration: 24460, Loss: -186.793457031\n",
      "Iteration: 24470, Loss: -161.792449951\n",
      "Iteration: 24480, Loss: -155.248199463\n",
      "Iteration: 24490, Loss: -155.352386475\n",
      "Iteration: 24500, Loss: -155.647735596\n",
      "Iteration: 24510, Loss: -159.755661011\n",
      "Iteration: 24520, Loss: -146.553283691\n",
      "Iteration: 24530, Loss: -146.233520508\n",
      "Iteration: 24540, Loss: -167.067138672\n",
      "Iteration: 24550, Loss: -169.212493896\n",
      "Iteration: 24560, Loss: -162.383163452\n",
      "Iteration: 24570, Loss: -159.271118164\n",
      "Iteration: 24580, Loss: -154.904022217\n",
      "Iteration: 24590, Loss: -184.723937988\n",
      "Iteration: 24600, Loss: -156.137252808\n",
      "Iteration: 24610, Loss: -155.125610352\n",
      "Iteration: 24620, Loss: -171.797164917\n",
      "Iteration: 24630, Loss: -158.317092896\n",
      "Iteration: 24640, Loss: -155.14642334\n",
      "Iteration: 24650, Loss: -157.288330078\n",
      "Iteration: 24660, Loss: -168.209274292\n",
      "Iteration: 24670, Loss: -164.912200928\n",
      "Iteration: 24680, Loss: -166.078369141\n",
      "Iteration: 24690, Loss: -149.275848389\n",
      "Iteration: 24700, Loss: -162.658630371\n",
      "Iteration: 24710, Loss: -154.442367554\n",
      "Iteration: 24720, Loss: -157.761154175\n",
      "Iteration: 24730, Loss: -167.499771118\n",
      "Iteration: 24740, Loss: -178.641937256\n",
      "Iteration: 24750, Loss: -154.167892456\n",
      "Iteration: 24760, Loss: -158.644226074\n",
      "Iteration: 24770, Loss: -177.212738037\n",
      "Iteration: 24780, Loss: -152.18157959\n",
      "Iteration: 24790, Loss: -152.262741089\n",
      "Iteration: 24800, Loss: -169.565093994\n",
      "Iteration: 24810, Loss: -150.314559937\n",
      "Iteration: 24820, Loss: -157.86050415\n",
      "Iteration: 24830, Loss: -146.966156006\n",
      "Iteration: 24840, Loss: -155.009277344\n",
      "Iteration: 24850, Loss: -154.7865448\n",
      "Iteration: 24860, Loss: -140.527816772\n",
      "Iteration: 24870, Loss: -177.495391846\n",
      "Iteration: 24880, Loss: -184.482635498\n",
      "Iteration: 24890, Loss: -170.391723633\n",
      "Iteration: 24900, Loss: -152.770141602\n",
      "Iteration: 24910, Loss: -158.010314941\n",
      "Iteration: 24920, Loss: -160.207275391\n",
      "Iteration: 24930, Loss: -149.025375366\n",
      "Iteration: 24940, Loss: -148.702667236\n",
      "Iteration: 24950, Loss: -174.571304321\n",
      "Iteration: 24960, Loss: -171.179779053\n",
      "Iteration: 24970, Loss: -150.918212891\n",
      "Iteration: 24980, Loss: -162.54876709\n",
      "Iteration: 24990, Loss: -145.816772461\n",
      "Iteration: 25000, Loss: -159.477844238\n",
      "Iteration: 25010, Loss: -167.915390015\n",
      "Iteration: 25020, Loss: -153.552581787\n",
      "Iteration: 25030, Loss: -160.330108643\n",
      "Iteration: 25040, Loss: -177.958358765\n",
      "Iteration: 25050, Loss: -173.738754272\n",
      "Iteration: 25060, Loss: -160.920715332\n",
      "Iteration: 25070, Loss: -155.678985596\n",
      "Iteration: 25080, Loss: -159.862640381\n",
      "Iteration: 25090, Loss: -145.172454834\n",
      "Iteration: 25100, Loss: -151.560699463\n",
      "Iteration: 25110, Loss: -150.116455078\n",
      "Iteration: 25120, Loss: -163.48210144\n",
      "Iteration: 25130, Loss: -154.979919434\n",
      "Iteration: 25140, Loss: -160.955123901\n",
      "Iteration: 25150, Loss: -154.299560547\n",
      "Iteration: 25160, Loss: -150.077911377\n",
      "Iteration: 25170, Loss: -171.568817139\n",
      "Iteration: 25180, Loss: -154.279724121\n",
      "Iteration: 25190, Loss: -162.390350342\n",
      "Iteration: 25200, Loss: -171.137512207\n",
      "Iteration: 25210, Loss: -165.468505859\n",
      "Iteration: 25220, Loss: -145.499389648\n",
      "Iteration: 25230, Loss: -172.321365356\n",
      "Iteration: 25240, Loss: -166.294036865\n",
      "Iteration: 25250, Loss: -179.132324219\n",
      "Iteration: 25260, Loss: -163.807739258\n",
      "Iteration: 25270, Loss: -173.723617554\n",
      "Iteration: 25280, Loss: -174.590301514\n",
      "Iteration: 25290, Loss: -152.926528931\n",
      "Iteration: 25300, Loss: -184.566467285\n",
      "Iteration: 25310, Loss: -158.968551636\n",
      "Iteration: 25320, Loss: -158.078384399\n",
      "Iteration: 25330, Loss: -145.257217407\n",
      "Iteration: 25340, Loss: -167.08241272\n",
      "Iteration: 25350, Loss: -155.260192871\n",
      "Iteration: 25360, Loss: -173.868301392\n",
      "Iteration: 25370, Loss: -160.750961304\n",
      "Iteration: 25380, Loss: -145.900787354\n",
      "Iteration: 25390, Loss: -150.702133179\n",
      "Iteration: 25400, Loss: -163.33833313\n",
      "Iteration: 25410, Loss: -149.406280518\n",
      "Iteration: 25420, Loss: -170.940444946\n",
      "Iteration: 25430, Loss: -154.537689209\n",
      "Iteration: 25440, Loss: -166.485458374\n",
      "Iteration: 25450, Loss: -170.093841553\n",
      "Iteration: 25460, Loss: -144.56539917\n",
      "Iteration: 25470, Loss: -160.133239746\n",
      "Iteration: 25480, Loss: -156.158599854\n",
      "Iteration: 25490, Loss: -158.943130493\n",
      "Iteration: 25500, Loss: -147.436706543\n",
      "Iteration: 25510, Loss: -163.917785645\n",
      "Iteration: 25520, Loss: -162.477844238\n",
      "Iteration: 25530, Loss: -183.818023682\n",
      "Iteration: 25540, Loss: -146.43737793\n",
      "Iteration: 25550, Loss: -164.372589111\n",
      "Iteration: 25560, Loss: -162.598327637\n",
      "Iteration: 25570, Loss: -162.131866455\n",
      "Iteration: 25580, Loss: -143.763824463\n",
      "Iteration: 25590, Loss: -156.693054199\n",
      "Iteration: 25600, Loss: -152.014541626\n",
      "Iteration: 25610, Loss: -179.196548462\n",
      "Iteration: 25620, Loss: -173.414642334\n",
      "Iteration: 25630, Loss: -168.020294189\n",
      "Iteration: 25640, Loss: -167.179702759\n",
      "Iteration: 25650, Loss: -167.223632812\n",
      "Iteration: 25660, Loss: -165.111129761\n",
      "Iteration: 25670, Loss: -152.956787109\n",
      "Iteration: 25680, Loss: -160.769805908\n",
      "Iteration: 25690, Loss: -165.947357178\n",
      "Iteration: 25700, Loss: -143.221191406\n",
      "Iteration: 25710, Loss: -159.729217529\n",
      "Iteration: 25720, Loss: -163.990905762\n",
      "Iteration: 25730, Loss: -157.85256958\n",
      "Iteration: 25740, Loss: -155.822631836\n",
      "Iteration: 25750, Loss: -165.477996826\n",
      "Iteration: 25760, Loss: -165.568649292\n",
      "Iteration: 25770, Loss: -164.266815186\n",
      "Iteration: 25780, Loss: -142.12310791\n",
      "Iteration: 25790, Loss: -151.269958496\n",
      "Iteration: 25800, Loss: -147.612960815\n",
      "Iteration: 25810, Loss: -160.114837646\n",
      "Iteration: 25820, Loss: -159.013122559\n",
      "Iteration: 25830, Loss: -171.244293213\n",
      "Iteration: 25840, Loss: -171.677490234\n",
      "Iteration: 25850, Loss: -148.054107666\n",
      "Iteration: 25860, Loss: -165.640808105\n",
      "Iteration: 25870, Loss: -164.430450439\n",
      "Iteration: 25880, Loss: -166.022521973\n",
      "Iteration: 25890, Loss: -145.057861328\n",
      "Iteration: 25900, Loss: -146.880401611\n",
      "Iteration: 25910, Loss: -163.677734375\n",
      "Iteration: 25920, Loss: -149.620239258\n",
      "Iteration: 25930, Loss: -160.229919434\n",
      "Iteration: 25940, Loss: -148.587310791\n",
      "Iteration: 25950, Loss: -151.219802856\n",
      "Iteration: 25960, Loss: -155.307373047\n",
      "Iteration: 25970, Loss: -155.219573975\n",
      "Iteration: 25980, Loss: -186.818725586\n",
      "Iteration: 25990, Loss: -152.507354736\n",
      "Iteration: 26000, Loss: -162.98223877\n",
      "Iteration: 26010, Loss: -147.066162109\n",
      "Iteration: 26020, Loss: -158.942108154\n",
      "Iteration: 26030, Loss: -167.922912598\n",
      "Iteration: 26040, Loss: -175.983154297\n",
      "Iteration: 26050, Loss: -163.753448486\n",
      "Iteration: 26060, Loss: -154.015426636\n",
      "Iteration: 26070, Loss: -175.294616699\n",
      "Iteration: 26080, Loss: -155.71585083\n",
      "Iteration: 26090, Loss: -151.987548828\n",
      "Iteration: 26100, Loss: -168.970336914\n",
      "Iteration: 26110, Loss: -151.973999023\n",
      "Iteration: 26120, Loss: -167.231246948\n",
      "Iteration: 26130, Loss: -163.492431641\n",
      "Iteration: 26140, Loss: -147.353637695\n",
      "Iteration: 26150, Loss: -142.426895142\n",
      "Iteration: 26160, Loss: -155.887863159\n",
      "Iteration: 26170, Loss: -155.120178223\n",
      "Iteration: 26180, Loss: -161.86618042\n",
      "Iteration: 26190, Loss: -152.254669189\n",
      "Iteration: 26200, Loss: -161.243682861\n",
      "Iteration: 26210, Loss: -151.96685791\n",
      "Iteration: 26220, Loss: -151.947738647\n",
      "Iteration: 26230, Loss: -175.9765625\n",
      "Iteration: 26240, Loss: -150.581054688\n",
      "Iteration: 26250, Loss: -156.269073486\n",
      "Iteration: 26260, Loss: -167.84664917\n",
      "Iteration: 26270, Loss: -158.657485962\n",
      "Iteration: 26280, Loss: -155.033172607\n",
      "Iteration: 26290, Loss: -160.855148315\n",
      "Iteration: 26300, Loss: -153.239242554\n",
      "Iteration: 26310, Loss: -159.533004761\n",
      "Iteration: 26320, Loss: -148.332580566\n",
      "Iteration: 26330, Loss: -156.250061035\n",
      "Iteration: 26340, Loss: -156.259552002\n",
      "Iteration: 26350, Loss: -147.371551514\n",
      "Iteration: 26360, Loss: -158.634307861\n",
      "Iteration: 26370, Loss: -162.456268311\n",
      "Iteration: 26380, Loss: -162.125457764\n",
      "Iteration: 26390, Loss: -155.345916748\n",
      "Iteration: 26400, Loss: -161.287780762\n",
      "Iteration: 26410, Loss: -165.698852539\n",
      "Iteration: 26420, Loss: -164.487091064\n",
      "Iteration: 26430, Loss: -168.367004395\n",
      "Iteration: 26440, Loss: -167.419845581\n",
      "Iteration: 26450, Loss: -181.1847229\n",
      "Iteration: 26460, Loss: -154.217880249\n",
      "Iteration: 26470, Loss: -159.922943115\n",
      "Iteration: 26480, Loss: -157.954269409\n",
      "Iteration: 26490, Loss: -158.71472168\n",
      "Iteration: 26500, Loss: -160.201766968\n",
      "Iteration: 26510, Loss: -164.028076172\n",
      "Iteration: 26520, Loss: -167.39654541\n",
      "Iteration: 26530, Loss: -153.7940979\n",
      "Iteration: 26540, Loss: -151.581359863\n",
      "Iteration: 26550, Loss: -167.230758667\n",
      "Iteration: 26560, Loss: -143.902526855\n",
      "Iteration: 26570, Loss: -140.249237061\n",
      "Iteration: 26580, Loss: -180.693023682\n",
      "Iteration: 26590, Loss: -163.058547974\n",
      "Iteration: 26600, Loss: -166.465087891\n",
      "Iteration: 26610, Loss: -174.15322876\n",
      "Iteration: 26620, Loss: -166.779937744\n",
      "Iteration: 26630, Loss: -161.156768799\n",
      "Iteration: 26640, Loss: -164.145080566\n",
      "Iteration: 26650, Loss: -160.143234253\n",
      "Iteration: 26660, Loss: -174.590789795\n",
      "Iteration: 26670, Loss: -160.311508179\n",
      "Iteration: 26680, Loss: -172.187011719\n",
      "Iteration: 26690, Loss: -157.864364624\n",
      "Iteration: 26700, Loss: -161.013427734\n",
      "Iteration: 26710, Loss: -151.332061768\n",
      "Iteration: 26720, Loss: -163.539215088\n",
      "Iteration: 26730, Loss: -156.550598145\n",
      "Iteration: 26740, Loss: -159.203308105\n",
      "Iteration: 26750, Loss: -156.330795288\n",
      "Iteration: 26760, Loss: -151.82585144\n",
      "Iteration: 26770, Loss: -168.389419556\n",
      "Iteration: 26780, Loss: -146.977127075\n",
      "Iteration: 26790, Loss: -150.791595459\n",
      "Iteration: 26800, Loss: -168.939666748\n",
      "Iteration: 26810, Loss: -156.643829346\n",
      "Iteration: 26820, Loss: -151.227508545\n",
      "Iteration: 26830, Loss: -161.642578125\n",
      "Iteration: 26840, Loss: -153.376434326\n",
      "Iteration: 26850, Loss: -145.430557251\n",
      "Iteration: 26860, Loss: -155.107513428\n",
      "Iteration: 26870, Loss: -182.464157104\n",
      "Iteration: 26880, Loss: -149.771621704\n",
      "Iteration: 26890, Loss: -181.428878784\n",
      "Iteration: 26900, Loss: -148.977355957\n",
      "Iteration: 26910, Loss: -156.119812012\n",
      "Iteration: 26920, Loss: -154.380203247\n",
      "Iteration: 26930, Loss: -167.880279541\n",
      "Iteration: 26940, Loss: -169.661315918\n",
      "Iteration: 26950, Loss: -164.951873779\n",
      "Iteration: 26960, Loss: -144.62538147\n",
      "Iteration: 26970, Loss: -157.293838501\n",
      "Iteration: 26980, Loss: -159.479705811\n",
      "Iteration: 26990, Loss: -137.465377808\n",
      "Iteration: 27000, Loss: -168.207962036\n",
      "Iteration: 27010, Loss: -167.227935791\n",
      "Iteration: 27020, Loss: -141.105117798\n",
      "Iteration: 27030, Loss: -153.817016602\n",
      "Iteration: 27040, Loss: -155.704986572\n",
      "Iteration: 27050, Loss: -158.807525635\n",
      "Iteration: 27060, Loss: -150.128601074\n",
      "Iteration: 27070, Loss: -161.670883179\n",
      "Iteration: 27080, Loss: -152.900253296\n",
      "Iteration: 27090, Loss: -141.838607788\n",
      "Iteration: 27100, Loss: -158.159759521\n",
      "Iteration: 27110, Loss: -143.939117432\n",
      "Iteration: 27120, Loss: -143.34703064\n",
      "Iteration: 27130, Loss: -144.481506348\n",
      "Iteration: 27140, Loss: -158.120849609\n",
      "Iteration: 27150, Loss: -142.997909546\n",
      "Iteration: 27160, Loss: -171.835159302\n",
      "Iteration: 27170, Loss: -168.331420898\n",
      "Iteration: 27180, Loss: -164.08442688\n",
      "Iteration: 27190, Loss: -152.854309082\n",
      "Iteration: 27200, Loss: -155.855743408\n",
      "Iteration: 27210, Loss: -158.231506348\n",
      "Iteration: 27220, Loss: -158.124786377\n",
      "Iteration: 27230, Loss: -141.744033813\n",
      "Iteration: 27240, Loss: -153.053649902\n",
      "Iteration: 27250, Loss: -154.424468994\n",
      "Iteration: 27260, Loss: -152.500595093\n",
      "Iteration: 27270, Loss: -152.343261719\n",
      "Iteration: 27280, Loss: -150.519180298\n",
      "Iteration: 27290, Loss: -147.612915039\n",
      "Iteration: 27300, Loss: -151.708587646\n",
      "Iteration: 27310, Loss: -136.494506836\n",
      "Iteration: 27320, Loss: -161.360229492\n",
      "Iteration: 27330, Loss: -159.218383789\n",
      "Iteration: 27340, Loss: -143.863555908\n",
      "Iteration: 27350, Loss: -162.335159302\n",
      "Iteration: 27360, Loss: -152.268264771\n",
      "Iteration: 27370, Loss: -162.805038452\n",
      "Iteration: 27380, Loss: -163.815750122\n",
      "Iteration: 27390, Loss: -157.950424194\n",
      "Iteration: 27400, Loss: -155.945007324\n",
      "Iteration: 27410, Loss: -162.814453125\n",
      "Iteration: 27420, Loss: -156.226074219\n",
      "Iteration: 27430, Loss: -154.885757446\n",
      "Iteration: 27440, Loss: -178.266906738\n",
      "Iteration: 27450, Loss: -142.290939331\n",
      "Iteration: 27460, Loss: -154.676757812\n",
      "Iteration: 27470, Loss: -170.444717407\n",
      "Iteration: 27480, Loss: -158.425720215\n",
      "Iteration: 27490, Loss: -163.803924561\n",
      "Iteration: 27500, Loss: -153.828521729\n",
      "Iteration: 27510, Loss: -154.417785645\n",
      "Iteration: 27520, Loss: -166.566604614\n",
      "Iteration: 27530, Loss: -173.974761963\n",
      "Iteration: 27540, Loss: -155.891967773\n",
      "Iteration: 27550, Loss: -144.145385742\n",
      "Iteration: 27560, Loss: -174.210723877\n",
      "Iteration: 27570, Loss: -182.364944458\n",
      "Iteration: 27580, Loss: -154.338867188\n",
      "Iteration: 27590, Loss: -162.836349487\n",
      "Iteration: 27600, Loss: -165.533630371\n",
      "Iteration: 27610, Loss: -169.543365479\n",
      "Iteration: 27620, Loss: -141.359558105\n",
      "Iteration: 27630, Loss: -161.044296265\n",
      "Iteration: 27640, Loss: -165.860778809\n",
      "Iteration: 27650, Loss: -148.158538818\n",
      "Iteration: 27660, Loss: -160.196182251\n",
      "Iteration: 27670, Loss: -144.404327393\n",
      "Iteration: 27680, Loss: -156.673950195\n",
      "Iteration: 27690, Loss: -148.192520142\n",
      "Iteration: 27700, Loss: -153.017272949\n",
      "Iteration: 27710, Loss: -167.138183594\n",
      "Iteration: 27720, Loss: -160.004272461\n",
      "Iteration: 27730, Loss: -153.217468262\n",
      "Iteration: 27740, Loss: -153.77935791\n",
      "Iteration: 27750, Loss: -165.250549316\n",
      "Iteration: 27760, Loss: -158.085540771\n",
      "Iteration: 27770, Loss: -159.019439697\n",
      "Iteration: 27780, Loss: -159.623123169\n",
      "Iteration: 27790, Loss: -168.565093994\n",
      "Iteration: 27800, Loss: -180.460021973\n",
      "Iteration: 27810, Loss: -145.768371582\n",
      "Iteration: 27820, Loss: -158.294708252\n",
      "Iteration: 27830, Loss: -163.796127319\n",
      "Iteration: 27840, Loss: -158.539611816\n",
      "Iteration: 27850, Loss: -155.997634888\n",
      "Iteration: 27860, Loss: -154.869293213\n",
      "Iteration: 27870, Loss: -177.12953186\n",
      "Iteration: 27880, Loss: -156.857666016\n",
      "Iteration: 27890, Loss: -150.291717529\n",
      "Iteration: 27900, Loss: -161.996856689\n",
      "Iteration: 27910, Loss: -148.452224731\n",
      "Iteration: 27920, Loss: -166.721160889\n",
      "Iteration: 27930, Loss: -183.196014404\n",
      "Iteration: 27940, Loss: -163.767028809\n",
      "Iteration: 27950, Loss: -166.420913696\n",
      "Iteration: 27960, Loss: -162.586380005\n",
      "Iteration: 27970, Loss: -161.681533813\n",
      "Iteration: 27980, Loss: -158.502258301\n",
      "Iteration: 27990, Loss: -160.197296143\n",
      "Iteration: 28000, Loss: -166.693740845\n",
      "Iteration: 28010, Loss: -157.330596924\n",
      "Iteration: 28020, Loss: -153.879821777\n",
      "Iteration: 28030, Loss: -170.566070557\n",
      "Iteration: 28040, Loss: -156.66986084\n",
      "Iteration: 28050, Loss: -157.835830688\n",
      "Iteration: 28060, Loss: -155.747161865\n",
      "Iteration: 28070, Loss: -170.461593628\n",
      "Iteration: 28080, Loss: -153.61315918\n",
      "Iteration: 28090, Loss: -162.502716064\n",
      "Iteration: 28100, Loss: -156.747528076\n",
      "Iteration: 28110, Loss: -161.556762695\n",
      "Iteration: 28120, Loss: -157.483093262\n",
      "Iteration: 28130, Loss: -165.461303711\n",
      "Iteration: 28140, Loss: -160.31439209\n",
      "Iteration: 28150, Loss: -157.248458862\n",
      "Iteration: 28160, Loss: -148.544204712\n",
      "Iteration: 28170, Loss: -162.177490234\n",
      "Iteration: 28180, Loss: -148.097473145\n",
      "Iteration: 28190, Loss: -147.310791016\n",
      "Iteration: 28200, Loss: -154.836151123\n",
      "Iteration: 28210, Loss: -148.282012939\n",
      "Iteration: 28220, Loss: -158.551361084\n",
      "Iteration: 28230, Loss: -162.936157227\n",
      "Iteration: 28240, Loss: -149.44720459\n",
      "Iteration: 28250, Loss: -166.112762451\n",
      "Iteration: 28260, Loss: -161.332397461\n",
      "Iteration: 28270, Loss: -147.407958984\n",
      "Iteration: 28280, Loss: -149.012084961\n",
      "Iteration: 28290, Loss: -179.166625977\n",
      "Iteration: 28300, Loss: -150.748184204\n",
      "Iteration: 28310, Loss: -154.326507568\n",
      "Iteration: 28320, Loss: -158.141296387\n",
      "Iteration: 28330, Loss: -153.554718018\n",
      "Iteration: 28340, Loss: -179.72442627\n",
      "Iteration: 28350, Loss: -149.380310059\n",
      "Iteration: 28360, Loss: -155.230834961\n",
      "Iteration: 28370, Loss: -153.712020874\n",
      "Iteration: 28380, Loss: -163.317886353\n",
      "Iteration: 28390, Loss: -161.726867676\n",
      "Iteration: 28400, Loss: -151.490432739\n",
      "Iteration: 28410, Loss: -166.551116943\n",
      "Iteration: 28420, Loss: -163.750656128\n",
      "Iteration: 28430, Loss: -150.047531128\n",
      "Iteration: 28440, Loss: -142.447418213\n",
      "Iteration: 28450, Loss: -157.388641357\n",
      "Iteration: 28460, Loss: -165.504974365\n",
      "Iteration: 28470, Loss: -173.087493896\n",
      "Iteration: 28480, Loss: -145.939361572\n",
      "Iteration: 28490, Loss: -158.350891113\n",
      "Iteration: 28500, Loss: -153.604309082\n",
      "Iteration: 28510, Loss: -168.227294922\n",
      "Iteration: 28520, Loss: -148.126464844\n",
      "Iteration: 28530, Loss: -162.666046143\n",
      "Iteration: 28540, Loss: -152.986679077\n",
      "Iteration: 28550, Loss: -132.975662231\n",
      "Iteration: 28560, Loss: -141.839096069\n",
      "Iteration: 28570, Loss: -153.683486938\n",
      "Iteration: 28580, Loss: -149.962615967\n",
      "Iteration: 28590, Loss: -158.122680664\n",
      "Iteration: 28600, Loss: -158.709228516\n",
      "Iteration: 28610, Loss: -164.780929565\n",
      "Iteration: 28620, Loss: -150.402008057\n",
      "Iteration: 28630, Loss: -160.804412842\n",
      "Iteration: 28640, Loss: -146.451812744\n",
      "Iteration: 28650, Loss: -152.403320312\n",
      "Iteration: 28660, Loss: -151.15965271\n",
      "Iteration: 28670, Loss: -160.682647705\n",
      "Iteration: 28680, Loss: -153.757781982\n",
      "Iteration: 28690, Loss: -150.019958496\n",
      "Iteration: 28700, Loss: -150.444488525\n",
      "Iteration: 28710, Loss: -163.847351074\n",
      "Iteration: 28720, Loss: -147.766159058\n",
      "Iteration: 28730, Loss: -166.456558228\n",
      "Iteration: 28740, Loss: -144.601867676\n",
      "Iteration: 28750, Loss: -158.437591553\n",
      "Iteration: 28760, Loss: -166.96824646\n",
      "Iteration: 28770, Loss: -170.091674805\n",
      "Iteration: 28780, Loss: -166.210083008\n",
      "Iteration: 28790, Loss: -156.505554199\n",
      "Iteration: 28800, Loss: -151.13104248\n",
      "Iteration: 28810, Loss: -154.496795654\n",
      "Iteration: 28820, Loss: -161.261993408\n",
      "Iteration: 28830, Loss: -177.74156189\n",
      "Iteration: 28840, Loss: -158.268707275\n",
      "Iteration: 28850, Loss: -146.033752441\n",
      "Iteration: 28860, Loss: -156.118347168\n",
      "Iteration: 28870, Loss: -174.056854248\n",
      "Iteration: 28880, Loss: -157.167892456\n",
      "Iteration: 28890, Loss: -143.267150879\n",
      "Iteration: 28900, Loss: -170.327392578\n",
      "Iteration: 28910, Loss: -161.101608276\n",
      "Iteration: 28920, Loss: -163.064346313\n",
      "Iteration: 28930, Loss: -156.365905762\n",
      "Iteration: 28940, Loss: -167.514007568\n",
      "Iteration: 28950, Loss: -158.472442627\n",
      "Iteration: 28960, Loss: -156.196517944\n",
      "Iteration: 28970, Loss: -166.488174438\n",
      "Iteration: 28980, Loss: -169.457702637\n",
      "Iteration: 28990, Loss: -156.674957275\n",
      "Iteration: 29000, Loss: -147.981109619\n",
      "Iteration: 29010, Loss: -154.396270752\n",
      "Iteration: 29020, Loss: -153.534790039\n",
      "Iteration: 29030, Loss: -161.164978027\n",
      "Iteration: 29040, Loss: -151.843933105\n",
      "Iteration: 29050, Loss: -148.854919434\n",
      "Iteration: 29060, Loss: -162.655639648\n",
      "Iteration: 29070, Loss: -171.652297974\n",
      "Iteration: 29080, Loss: -152.447402954\n",
      "Iteration: 29090, Loss: -154.034210205\n",
      "Iteration: 29100, Loss: -155.173980713\n",
      "Iteration: 29110, Loss: -155.441162109\n",
      "Iteration: 29120, Loss: -149.1146698\n",
      "Iteration: 29130, Loss: -148.708175659\n",
      "Iteration: 29140, Loss: -166.690658569\n",
      "Iteration: 29150, Loss: -149.969696045\n",
      "Iteration: 29160, Loss: -184.571014404\n",
      "Iteration: 29170, Loss: -159.091949463\n",
      "Iteration: 29180, Loss: -141.646789551\n",
      "Iteration: 29190, Loss: -159.548400879\n",
      "Iteration: 29200, Loss: -144.007598877\n",
      "Iteration: 29210, Loss: -145.368988037\n",
      "Iteration: 29220, Loss: -163.151443481\n",
      "Iteration: 29230, Loss: -152.620361328\n",
      "Iteration: 29240, Loss: -156.105987549\n",
      "Iteration: 29250, Loss: -155.674865723\n",
      "Iteration: 29260, Loss: -154.565231323\n",
      "Iteration: 29270, Loss: -161.336517334\n",
      "Iteration: 29280, Loss: -163.067321777\n",
      "Iteration: 29290, Loss: -157.466522217\n",
      "Iteration: 29300, Loss: -181.600799561\n",
      "Iteration: 29310, Loss: -151.254730225\n",
      "Iteration: 29320, Loss: -156.826934814\n",
      "Iteration: 29330, Loss: -157.338684082\n",
      "Iteration: 29340, Loss: -172.46812439\n",
      "Iteration: 29350, Loss: -164.885269165\n",
      "Iteration: 29360, Loss: -161.249984741\n",
      "Iteration: 29370, Loss: -142.724090576\n",
      "Iteration: 29380, Loss: -137.204040527\n",
      "Iteration: 29390, Loss: -166.624282837\n",
      "Iteration: 29400, Loss: -138.858032227\n",
      "Iteration: 29410, Loss: -163.136138916\n",
      "Iteration: 29420, Loss: -160.207504272\n",
      "Iteration: 29430, Loss: -169.097839355\n",
      "Iteration: 29440, Loss: -157.978591919\n",
      "Iteration: 29450, Loss: -158.320343018\n",
      "Iteration: 29460, Loss: -155.586303711\n",
      "Iteration: 29470, Loss: -154.330322266\n",
      "Iteration: 29480, Loss: -169.964569092\n",
      "Iteration: 29490, Loss: -159.101715088\n",
      "Iteration: 29500, Loss: -158.328781128\n",
      "Iteration: 29510, Loss: -149.858474731\n",
      "Iteration: 29520, Loss: -150.638839722\n",
      "Iteration: 29530, Loss: -168.656723022\n",
      "Iteration: 29540, Loss: -155.852661133\n",
      "Iteration: 29550, Loss: -156.485824585\n",
      "Iteration: 29560, Loss: -143.45993042\n",
      "Iteration: 29570, Loss: -160.345581055\n",
      "Iteration: 29580, Loss: -161.613555908\n",
      "Iteration: 29590, Loss: -172.30255127\n",
      "Iteration: 29600, Loss: -164.168869019\n",
      "Iteration: 29610, Loss: -153.151733398\n",
      "Iteration: 29620, Loss: -154.812347412\n",
      "Iteration: 29630, Loss: -151.311508179\n",
      "Iteration: 29640, Loss: -167.489868164\n",
      "Iteration: 29650, Loss: -154.108047485\n",
      "Iteration: 29660, Loss: -166.285430908\n",
      "Iteration: 29670, Loss: -166.883987427\n",
      "Iteration: 29680, Loss: -159.11618042\n",
      "Iteration: 29690, Loss: -172.270950317\n",
      "Iteration: 29700, Loss: -165.242843628\n",
      "Iteration: 29710, Loss: -155.974304199\n",
      "Iteration: 29720, Loss: -157.192138672\n",
      "Iteration: 29730, Loss: -153.002197266\n",
      "Iteration: 29740, Loss: -181.805541992\n",
      "Iteration: 29750, Loss: -154.196655273\n",
      "Iteration: 29760, Loss: -135.440750122\n",
      "Iteration: 29770, Loss: -154.096878052\n",
      "Iteration: 29780, Loss: -189.460037231\n",
      "Iteration: 29790, Loss: -146.284606934\n",
      "Iteration: 29800, Loss: -160.744979858\n",
      "Iteration: 29810, Loss: -140.268920898\n",
      "Iteration: 29820, Loss: -148.995391846\n",
      "Iteration: 29830, Loss: -149.089935303\n",
      "Iteration: 29840, Loss: -162.156677246\n",
      "Iteration: 29850, Loss: -161.470794678\n",
      "Iteration: 29860, Loss: -144.80947876\n",
      "Iteration: 29870, Loss: -158.026489258\n",
      "Iteration: 29880, Loss: -153.845321655\n",
      "Iteration: 29890, Loss: -153.624359131\n",
      "Iteration: 29900, Loss: -156.855224609\n",
      "Iteration: 29910, Loss: -158.21572876\n",
      "Iteration: 29920, Loss: -161.750701904\n",
      "Iteration: 29930, Loss: -156.524047852\n",
      "Iteration: 29940, Loss: -143.521713257\n",
      "Iteration: 29950, Loss: -160.038009644\n",
      "Iteration: 29960, Loss: -171.737915039\n",
      "Iteration: 29970, Loss: -156.205413818\n",
      "Iteration: 29980, Loss: -162.338378906\n",
      "Iteration: 29990, Loss: -155.229293823\n",
      "Iteration: 30000, Loss: -147.255615234\n",
      "Iteration: 30010, Loss: -156.690124512\n",
      "Iteration: 30020, Loss: -164.553009033\n",
      "Iteration: 30030, Loss: -159.502304077\n",
      "Iteration: 30040, Loss: -161.988616943\n",
      "Iteration: 30050, Loss: -155.539337158\n",
      "Iteration: 30060, Loss: -147.281494141\n",
      "Iteration: 30070, Loss: -152.022674561\n",
      "Iteration: 30080, Loss: -165.415649414\n",
      "Iteration: 30090, Loss: -159.700073242\n",
      "Iteration: 30100, Loss: -156.288406372\n",
      "Iteration: 30110, Loss: -167.585479736\n",
      "Iteration: 30120, Loss: -159.119857788\n",
      "Iteration: 30130, Loss: -169.674865723\n",
      "Iteration: 30140, Loss: -152.225128174\n",
      "Iteration: 30150, Loss: -151.278778076\n",
      "Iteration: 30160, Loss: -165.30670166\n",
      "Iteration: 30170, Loss: -152.651153564\n",
      "Iteration: 30180, Loss: -146.180053711\n",
      "Iteration: 30190, Loss: -153.160858154\n",
      "Iteration: 30200, Loss: -156.541152954\n",
      "Iteration: 30210, Loss: -179.569335938\n",
      "Iteration: 30220, Loss: -168.169692993\n",
      "Iteration: 30230, Loss: -162.136474609\n",
      "Iteration: 30240, Loss: -158.255966187\n",
      "Iteration: 30250, Loss: -163.136993408\n",
      "Iteration: 30260, Loss: -174.496124268\n",
      "Iteration: 30270, Loss: -154.783569336\n",
      "Iteration: 30280, Loss: -158.772766113\n",
      "Iteration: 30290, Loss: -140.690292358\n",
      "Iteration: 30300, Loss: -165.800552368\n",
      "Iteration: 30310, Loss: -170.101226807\n",
      "Iteration: 30320, Loss: -163.819290161\n",
      "Iteration: 30330, Loss: -166.759155273\n",
      "Iteration: 30340, Loss: -156.779708862\n",
      "Iteration: 30350, Loss: -151.752990723\n",
      "Iteration: 30360, Loss: -150.423736572\n",
      "Iteration: 30370, Loss: -159.460083008\n",
      "Iteration: 30380, Loss: -153.798065186\n",
      "Iteration: 30390, Loss: -148.595474243\n",
      "Iteration: 30400, Loss: -159.433120728\n",
      "Iteration: 30410, Loss: -152.036514282\n",
      "Iteration: 30420, Loss: -159.529418945\n",
      "Iteration: 30430, Loss: -166.494674683\n",
      "Iteration: 30440, Loss: -142.97076416\n",
      "Iteration: 30450, Loss: -135.752624512\n",
      "Iteration: 30460, Loss: -155.655258179\n",
      "Iteration: 30470, Loss: -165.991836548\n",
      "Iteration: 30480, Loss: -160.614120483\n",
      "Iteration: 30490, Loss: -152.883560181\n",
      "Iteration: 30500, Loss: -153.83644104\n",
      "Iteration: 30510, Loss: -178.756072998\n",
      "Iteration: 30520, Loss: -139.116729736\n",
      "Iteration: 30530, Loss: -159.653015137\n",
      "Iteration: 30540, Loss: -155.784896851\n",
      "Iteration: 30550, Loss: -149.924087524\n",
      "Iteration: 30560, Loss: -157.849853516\n",
      "Iteration: 30570, Loss: -157.173583984\n",
      "Iteration: 30580, Loss: -136.277297974\n",
      "Iteration: 30590, Loss: -160.146377563\n",
      "Iteration: 30600, Loss: -166.411087036\n",
      "Iteration: 30610, Loss: -156.970733643\n",
      "Iteration: 30620, Loss: -153.632369995\n",
      "Iteration: 30630, Loss: -145.935012817\n",
      "Iteration: 30640, Loss: -153.481414795\n",
      "Iteration: 30650, Loss: -153.792480469\n",
      "Iteration: 30660, Loss: -152.336654663\n",
      "Iteration: 30670, Loss: -159.134613037\n",
      "Iteration: 30680, Loss: -157.879211426\n",
      "Iteration: 30690, Loss: -164.644989014\n",
      "Iteration: 30700, Loss: -166.589172363\n",
      "Iteration: 30710, Loss: -155.033752441\n",
      "Iteration: 30720, Loss: -166.873733521\n",
      "Iteration: 30730, Loss: -154.454421997\n",
      "Iteration: 30740, Loss: -162.473571777\n",
      "Iteration: 30750, Loss: -151.560592651\n",
      "Iteration: 30760, Loss: -159.585418701\n",
      "Iteration: 30770, Loss: -164.028045654\n",
      "Iteration: 30780, Loss: -146.024368286\n",
      "Iteration: 30790, Loss: -163.231170654\n",
      "Iteration: 30800, Loss: -138.678848267\n",
      "Iteration: 30810, Loss: -150.305770874\n",
      "Iteration: 30820, Loss: -149.925537109\n",
      "Iteration: 30830, Loss: -149.930999756\n",
      "Iteration: 30840, Loss: -166.960845947\n",
      "Iteration: 30850, Loss: -153.868804932\n",
      "Iteration: 30860, Loss: -147.053970337\n",
      "Iteration: 30870, Loss: -155.41293335\n",
      "Iteration: 30880, Loss: -169.146072388\n",
      "Iteration: 30890, Loss: -151.882064819\n",
      "Iteration: 30900, Loss: -140.251159668\n",
      "Iteration: 30910, Loss: -150.097625732\n",
      "Iteration: 30920, Loss: -149.422088623\n",
      "Iteration: 30930, Loss: -153.875701904\n",
      "Iteration: 30940, Loss: -146.281997681\n",
      "Iteration: 30950, Loss: -179.61138916\n",
      "Iteration: 30960, Loss: -159.216445923\n",
      "Iteration: 30970, Loss: -148.381652832\n",
      "Iteration: 30980, Loss: -155.639480591\n",
      "Iteration: 30990, Loss: -149.4584198\n",
      "Iteration: 31000, Loss: -153.586273193\n",
      "Iteration: 31010, Loss: -154.781829834\n",
      "Iteration: 31020, Loss: -160.324615479\n",
      "Iteration: 31030, Loss: -169.427017212\n",
      "Iteration: 31040, Loss: -165.308441162\n",
      "Iteration: 31050, Loss: -142.795623779\n",
      "Iteration: 31060, Loss: -156.122741699\n",
      "Iteration: 31070, Loss: -145.730224609\n",
      "Iteration: 31080, Loss: -154.595611572\n",
      "Iteration: 31090, Loss: -152.217468262\n",
      "Iteration: 31100, Loss: -155.331878662\n",
      "Iteration: 31110, Loss: -154.162033081\n",
      "Iteration: 31120, Loss: -147.106445312\n",
      "Iteration: 31130, Loss: -143.487106323\n",
      "Iteration: 31140, Loss: -154.581359863\n",
      "Iteration: 31150, Loss: -154.530731201\n",
      "Iteration: 31160, Loss: -164.237106323\n",
      "Iteration: 31170, Loss: -156.858673096\n",
      "Iteration: 31180, Loss: -152.721939087\n",
      "Iteration: 31190, Loss: -147.689697266\n",
      "Iteration: 31200, Loss: -146.574142456\n",
      "Iteration: 31210, Loss: -156.045791626\n",
      "Iteration: 31220, Loss: -155.651062012\n",
      "Iteration: 31230, Loss: -150.994384766\n",
      "Iteration: 31240, Loss: -155.913543701\n",
      "Iteration: 31250, Loss: -179.372299194\n",
      "Iteration: 31260, Loss: -163.320480347\n",
      "Iteration: 31270, Loss: -152.490783691\n",
      "Iteration: 31280, Loss: -141.572113037\n",
      "Iteration: 31290, Loss: -162.840270996\n",
      "Iteration: 31300, Loss: -169.562362671\n",
      "Iteration: 31310, Loss: -134.937728882\n",
      "Iteration: 31320, Loss: -141.864715576\n",
      "Iteration: 31330, Loss: -156.203262329\n",
      "Iteration: 31340, Loss: -155.944549561\n",
      "Iteration: 31350, Loss: -158.794708252\n",
      "Iteration: 31360, Loss: -159.458526611\n",
      "Iteration: 31370, Loss: -155.57661438\n",
      "Iteration: 31380, Loss: -144.180267334\n",
      "Iteration: 31390, Loss: -156.542419434\n",
      "Iteration: 31400, Loss: -147.291748047\n",
      "Iteration: 31410, Loss: -145.262878418\n",
      "Iteration: 31420, Loss: -164.241439819\n",
      "Iteration: 31430, Loss: -169.629257202\n",
      "Iteration: 31440, Loss: -150.522827148\n",
      "Iteration: 31450, Loss: -162.732177734\n",
      "Iteration: 31460, Loss: -139.99382019\n",
      "Iteration: 31470, Loss: -146.163269043\n",
      "Iteration: 31480, Loss: -145.962875366\n",
      "Iteration: 31490, Loss: -172.64906311\n",
      "Iteration: 31500, Loss: -148.247528076\n",
      "Iteration: 31510, Loss: -162.796615601\n",
      "Iteration: 31520, Loss: -138.60043335\n",
      "Iteration: 31530, Loss: -156.569152832\n",
      "Iteration: 31540, Loss: -138.040374756\n",
      "Iteration: 31550, Loss: -161.40776062\n",
      "Iteration: 31560, Loss: -148.885482788\n",
      "Iteration: 31570, Loss: -143.916229248\n",
      "Iteration: 31580, Loss: -161.636917114\n",
      "Iteration: 31590, Loss: -158.111160278\n",
      "Iteration: 31600, Loss: -159.73487854\n",
      "Iteration: 31610, Loss: -166.451904297\n",
      "Iteration: 31620, Loss: -180.464782715\n",
      "Iteration: 31630, Loss: -155.908966064\n",
      "Iteration: 31640, Loss: -150.233459473\n",
      "Iteration: 31650, Loss: -158.200805664\n",
      "Iteration: 31660, Loss: -161.212738037\n",
      "Iteration: 31670, Loss: -153.815338135\n",
      "Iteration: 31680, Loss: -144.671340942\n",
      "Iteration: 31690, Loss: -148.038879395\n",
      "Iteration: 31700, Loss: -148.169219971\n",
      "Iteration: 31710, Loss: -156.869018555\n",
      "Iteration: 31720, Loss: -160.484863281\n",
      "Iteration: 31730, Loss: -158.567871094\n",
      "Iteration: 31740, Loss: -144.957992554\n",
      "Iteration: 31750, Loss: -177.993408203\n",
      "Iteration: 31760, Loss: -156.509857178\n",
      "Iteration: 31770, Loss: -158.420913696\n",
      "Iteration: 31780, Loss: -160.879257202\n",
      "Iteration: 31790, Loss: -144.528320312\n",
      "Iteration: 31800, Loss: -155.376495361\n",
      "Iteration: 31810, Loss: -168.943862915\n",
      "Iteration: 31820, Loss: -154.648681641\n",
      "Iteration: 31830, Loss: -142.233093262\n",
      "Iteration: 31840, Loss: -157.834442139\n",
      "Iteration: 31850, Loss: -158.549942017\n",
      "Iteration: 31860, Loss: -145.116638184\n",
      "Iteration: 31870, Loss: -159.033370972\n",
      "Iteration: 31880, Loss: -158.626800537\n",
      "Iteration: 31890, Loss: -166.448013306\n",
      "Iteration: 31900, Loss: -157.804748535\n",
      "Iteration: 31910, Loss: -159.992599487\n",
      "Iteration: 31920, Loss: -145.28918457\n",
      "Iteration: 31930, Loss: -166.64730835\n",
      "Iteration: 31940, Loss: -168.600418091\n",
      "Iteration: 31950, Loss: -144.195327759\n",
      "Iteration: 31960, Loss: -149.8490448\n",
      "Iteration: 31970, Loss: -158.768463135\n",
      "Iteration: 31980, Loss: -155.130310059\n",
      "Iteration: 31990, Loss: -159.698776245\n",
      "Iteration: 32000, Loss: -147.165283203\n",
      "Iteration: 32010, Loss: -151.737564087\n",
      "Iteration: 32020, Loss: -157.98526001\n",
      "Iteration: 32030, Loss: -140.263504028\n",
      "Iteration: 32040, Loss: -159.170654297\n",
      "Iteration: 32050, Loss: -156.84312439\n",
      "Iteration: 32060, Loss: -166.698699951\n",
      "Iteration: 32070, Loss: -153.564987183\n",
      "Iteration: 32080, Loss: -152.117736816\n",
      "Iteration: 32090, Loss: -167.010040283\n",
      "Iteration: 32100, Loss: -142.412231445\n",
      "Iteration: 32110, Loss: -150.927520752\n",
      "Iteration: 32120, Loss: -140.77961731\n",
      "Iteration: 32130, Loss: -148.356292725\n",
      "Iteration: 32140, Loss: -149.990631104\n",
      "Iteration: 32150, Loss: -150.741043091\n",
      "Iteration: 32160, Loss: -161.678100586\n",
      "Iteration: 32170, Loss: -157.263458252\n",
      "Iteration: 32180, Loss: -147.936721802\n",
      "Iteration: 32190, Loss: -147.824951172\n",
      "Iteration: 32200, Loss: -147.845809937\n",
      "Iteration: 32210, Loss: -152.481964111\n",
      "Iteration: 32220, Loss: -150.23286438\n",
      "Iteration: 32230, Loss: -139.478729248\n",
      "Iteration: 32240, Loss: -133.331237793\n",
      "Iteration: 32250, Loss: -169.878570557\n",
      "Iteration: 32260, Loss: -168.876495361\n",
      "Iteration: 32270, Loss: -147.680084229\n",
      "Iteration: 32280, Loss: -157.714950562\n",
      "Iteration: 32290, Loss: -142.079910278\n",
      "Iteration: 32300, Loss: -158.113143921\n",
      "Iteration: 32310, Loss: -131.954803467\n",
      "Iteration: 32320, Loss: -161.814376831\n",
      "Iteration: 32330, Loss: -148.710388184\n",
      "Iteration: 32340, Loss: -147.699951172\n",
      "Iteration: 32350, Loss: -146.484558105\n",
      "Iteration: 32360, Loss: -160.646789551\n",
      "Iteration: 32370, Loss: -148.318130493\n",
      "Iteration: 32380, Loss: -152.330444336\n",
      "Iteration: 32390, Loss: -165.29006958\n",
      "Iteration: 32400, Loss: -140.191009521\n",
      "Iteration: 32410, Loss: -139.70866394\n",
      "Iteration: 32420, Loss: -154.183868408\n",
      "Iteration: 32430, Loss: -162.77583313\n",
      "Iteration: 32440, Loss: -144.064285278\n",
      "Iteration: 32450, Loss: -154.320419312\n",
      "Iteration: 32460, Loss: -151.189147949\n",
      "Iteration: 32470, Loss: -163.289733887\n",
      "Iteration: 32480, Loss: -147.61920166\n",
      "Iteration: 32490, Loss: -150.152114868\n",
      "Iteration: 32500, Loss: -149.536972046\n",
      "Iteration: 32510, Loss: -146.649139404\n",
      "Iteration: 32520, Loss: -163.035980225\n",
      "Iteration: 32530, Loss: -159.065979004\n",
      "Iteration: 32540, Loss: -150.720367432\n",
      "Iteration: 32550, Loss: -150.97857666\n",
      "Iteration: 32560, Loss: -149.259918213\n",
      "Iteration: 32570, Loss: -152.446334839\n",
      "Iteration: 32580, Loss: -161.34185791\n",
      "Iteration: 32590, Loss: -140.581573486\n",
      "Iteration: 32600, Loss: -167.230163574\n",
      "Iteration: 32610, Loss: -152.382858276\n",
      "Iteration: 32620, Loss: -158.20123291\n",
      "Iteration: 32630, Loss: -160.978363037\n",
      "Iteration: 32640, Loss: -158.011886597\n",
      "Iteration: 32650, Loss: -163.930801392\n",
      "Iteration: 32660, Loss: -148.940536499\n",
      "Iteration: 32670, Loss: -137.213806152\n",
      "Iteration: 32680, Loss: -155.078460693\n",
      "Iteration: 32690, Loss: -160.491668701\n",
      "Iteration: 32700, Loss: -151.415512085\n",
      "Iteration: 32710, Loss: -138.73739624\n",
      "Iteration: 32720, Loss: -151.811462402\n",
      "Iteration: 32730, Loss: -152.35369873\n",
      "Iteration: 32740, Loss: -171.05871582\n",
      "Iteration: 32750, Loss: -140.671447754\n",
      "Iteration: 32760, Loss: -157.378799438\n",
      "Iteration: 32770, Loss: -145.291244507\n",
      "Iteration: 32780, Loss: -152.873321533\n",
      "Iteration: 32790, Loss: -149.290786743\n",
      "Iteration: 32800, Loss: -156.457702637\n",
      "Iteration: 32810, Loss: -166.868286133\n",
      "Iteration: 32820, Loss: -170.787887573\n",
      "Iteration: 32830, Loss: -154.294143677\n",
      "Iteration: 32840, Loss: -143.548950195\n",
      "Iteration: 32850, Loss: -158.504882812\n",
      "Iteration: 32860, Loss: -147.873321533\n",
      "Iteration: 32870, Loss: -151.410919189\n",
      "Iteration: 32880, Loss: -144.900634766\n",
      "Iteration: 32890, Loss: -149.573699951\n",
      "Iteration: 32900, Loss: -156.666442871\n",
      "Iteration: 32910, Loss: -174.677383423\n",
      "Iteration: 32920, Loss: -151.191970825\n",
      "Iteration: 32930, Loss: -148.580093384\n",
      "Iteration: 32940, Loss: -146.259887695\n",
      "Iteration: 32950, Loss: -146.141021729\n",
      "Iteration: 32960, Loss: -171.879364014\n",
      "Iteration: 32970, Loss: -174.06338501\n",
      "Iteration: 32980, Loss: -169.767028809\n",
      "Iteration: 32990, Loss: -150.29800415\n",
      "Iteration: 33000, Loss: -154.419525146\n",
      "Iteration: 33010, Loss: -147.856307983\n",
      "Iteration: 33020, Loss: -157.237701416\n",
      "Iteration: 33030, Loss: -153.813186646\n",
      "Iteration: 33040, Loss: -150.250213623\n",
      "Iteration: 33050, Loss: -154.173782349\n",
      "Iteration: 33060, Loss: -150.865234375\n",
      "Iteration: 33070, Loss: -155.095596313\n",
      "Iteration: 33080, Loss: -145.199768066\n",
      "Iteration: 33090, Loss: -147.517974854\n",
      "Iteration: 33100, Loss: -156.262268066\n",
      "Iteration: 33110, Loss: -140.16104126\n",
      "Iteration: 33120, Loss: -156.144454956\n",
      "Iteration: 33130, Loss: -137.023925781\n",
      "Iteration: 33140, Loss: -146.999755859\n",
      "Iteration: 33150, Loss: -139.503326416\n",
      "Iteration: 33160, Loss: -155.893188477\n",
      "Iteration: 33170, Loss: -156.203582764\n",
      "Iteration: 33180, Loss: -155.965866089\n",
      "Iteration: 33190, Loss: -159.706237793\n",
      "Iteration: 33200, Loss: -141.133850098\n",
      "Iteration: 33210, Loss: -155.074020386\n",
      "Iteration: 33220, Loss: -162.942169189\n",
      "Iteration: 33230, Loss: -162.131195068\n",
      "Iteration: 33240, Loss: -144.514556885\n",
      "Iteration: 33250, Loss: -159.245727539\n",
      "Iteration: 33260, Loss: -135.792175293\n",
      "Iteration: 33270, Loss: -140.834640503\n",
      "Iteration: 33280, Loss: -140.999603271\n",
      "Iteration: 33290, Loss: -154.446533203\n",
      "Iteration: 33300, Loss: -164.216400146\n",
      "Iteration: 33310, Loss: -149.41619873\n",
      "Iteration: 33320, Loss: -159.079437256\n",
      "Iteration: 33330, Loss: -165.733520508\n",
      "Iteration: 33340, Loss: -165.971481323\n",
      "Iteration: 33350, Loss: -155.044372559\n",
      "Iteration: 33360, Loss: -148.804641724\n",
      "Iteration: 33370, Loss: -141.320983887\n",
      "Iteration: 33380, Loss: -150.498840332\n",
      "Iteration: 33390, Loss: -165.117706299\n",
      "Iteration: 33400, Loss: -155.52935791\n",
      "Iteration: 33410, Loss: -155.941696167\n",
      "Iteration: 33420, Loss: -154.800506592\n",
      "Iteration: 33430, Loss: -162.966125488\n",
      "Iteration: 33440, Loss: -161.631271362\n",
      "Iteration: 33450, Loss: -151.901016235\n",
      "Iteration: 33460, Loss: -152.130126953\n",
      "Iteration: 33470, Loss: -151.404998779\n",
      "Iteration: 33480, Loss: -147.814422607\n",
      "Iteration: 33490, Loss: -157.5519104\n",
      "Iteration: 33500, Loss: -143.954818726\n",
      "Iteration: 33510, Loss: -175.57661438\n",
      "Iteration: 33520, Loss: -144.318893433\n",
      "Iteration: 33530, Loss: -156.883773804\n",
      "Iteration: 33540, Loss: -153.460357666\n",
      "Iteration: 33550, Loss: -155.350616455\n",
      "Iteration: 33560, Loss: -156.464416504\n",
      "Iteration: 33570, Loss: -157.707565308\n",
      "Iteration: 33580, Loss: -153.289398193\n",
      "Iteration: 33590, Loss: -158.517578125\n",
      "Iteration: 33600, Loss: -154.522903442\n",
      "Iteration: 33610, Loss: -153.912994385\n",
      "Iteration: 33620, Loss: -165.651580811\n",
      "Iteration: 33630, Loss: -167.640762329\n",
      "Iteration: 33640, Loss: -151.059631348\n",
      "Iteration: 33650, Loss: -143.769958496\n",
      "Iteration: 33660, Loss: -156.647659302\n",
      "Iteration: 33670, Loss: -153.351867676\n",
      "Iteration: 33680, Loss: -163.694534302\n",
      "Iteration: 33690, Loss: -166.535751343\n",
      "Iteration: 33700, Loss: -145.024887085\n",
      "Iteration: 33710, Loss: -167.586303711\n",
      "Iteration: 33720, Loss: -141.437896729\n",
      "Iteration: 33730, Loss: -140.029052734\n",
      "Iteration: 33740, Loss: -149.55960083\n",
      "Iteration: 33750, Loss: -158.828948975\n",
      "Iteration: 33760, Loss: -153.998962402\n",
      "Iteration: 33770, Loss: -151.539642334\n",
      "Iteration: 33780, Loss: -163.304626465\n",
      "Iteration: 33790, Loss: -153.807815552\n",
      "Iteration: 33800, Loss: -144.304229736\n",
      "Iteration: 33810, Loss: -134.324127197\n",
      "Iteration: 33820, Loss: -131.521759033\n",
      "Iteration: 33830, Loss: -150.651977539\n",
      "Iteration: 33840, Loss: -148.813690186\n",
      "Iteration: 33850, Loss: -135.818145752\n",
      "Iteration: 33860, Loss: -137.486206055\n",
      "Iteration: 33870, Loss: -141.704101562\n",
      "Iteration: 33880, Loss: -149.594833374\n",
      "Iteration: 33890, Loss: -161.321548462\n",
      "Iteration: 33900, Loss: -155.172698975\n",
      "Iteration: 33910, Loss: -140.968383789\n",
      "Iteration: 33920, Loss: -163.483947754\n",
      "Iteration: 33930, Loss: -166.892410278\n",
      "Iteration: 33940, Loss: -152.159408569\n",
      "Iteration: 33950, Loss: -161.40423584\n",
      "Iteration: 33960, Loss: -151.530792236\n",
      "Iteration: 33970, Loss: -149.897720337\n",
      "Iteration: 33980, Loss: -166.810562134\n",
      "Iteration: 33990, Loss: -157.650054932\n",
      "Iteration: 34000, Loss: -152.083618164\n",
      "Iteration: 34010, Loss: -160.339401245\n",
      "Iteration: 34020, Loss: -157.215698242\n",
      "Iteration: 34030, Loss: -145.223480225\n",
      "Iteration: 34040, Loss: -151.772338867\n",
      "Iteration: 34050, Loss: -149.835525513\n",
      "Iteration: 34060, Loss: -150.26171875\n",
      "Iteration: 34070, Loss: -173.692138672\n",
      "Iteration: 34080, Loss: -153.031433105\n",
      "Iteration: 34090, Loss: -140.773345947\n",
      "Iteration: 34100, Loss: -156.427398682\n",
      "Iteration: 34110, Loss: -149.618438721\n",
      "Iteration: 34120, Loss: -140.933837891\n",
      "Iteration: 34130, Loss: -166.958068848\n",
      "Iteration: 34140, Loss: -157.116210938\n",
      "Iteration: 34150, Loss: -146.094238281\n",
      "Iteration: 34160, Loss: -137.462524414\n",
      "Iteration: 34170, Loss: -150.718063354\n",
      "Iteration: 34180, Loss: -155.084259033\n",
      "Iteration: 34190, Loss: -144.041900635\n",
      "Iteration: 34200, Loss: -140.225753784\n",
      "Iteration: 34210, Loss: -149.960784912\n",
      "Iteration: 34220, Loss: -156.385635376\n",
      "Iteration: 34230, Loss: -139.07043457\n",
      "Iteration: 34240, Loss: -154.865142822\n",
      "Iteration: 34250, Loss: -152.216415405\n",
      "Iteration: 34260, Loss: -156.335083008\n",
      "Iteration: 34270, Loss: -161.331924438\n",
      "Iteration: 34280, Loss: -151.040664673\n",
      "Iteration: 34290, Loss: -139.954193115\n",
      "Iteration: 34300, Loss: -157.954345703\n",
      "Iteration: 34310, Loss: -155.887298584\n",
      "Iteration: 34320, Loss: -152.037994385\n",
      "Iteration: 34330, Loss: -145.278594971\n",
      "Iteration: 34340, Loss: -161.320907593\n",
      "Iteration: 34350, Loss: -148.693695068\n",
      "Iteration: 34360, Loss: -166.297958374\n",
      "Iteration: 34370, Loss: -165.315246582\n",
      "Iteration: 34380, Loss: -152.122955322\n",
      "Iteration: 34390, Loss: -143.945007324\n",
      "Iteration: 34400, Loss: -154.875335693\n",
      "Iteration: 34410, Loss: -158.530929565\n",
      "Iteration: 34420, Loss: -154.838684082\n",
      "Iteration: 34430, Loss: -160.897384644\n",
      "Iteration: 34440, Loss: -153.217971802\n",
      "Iteration: 34450, Loss: -148.360488892\n",
      "Iteration: 34460, Loss: -165.559890747\n",
      "Iteration: 34470, Loss: -152.754333496\n",
      "Iteration: 34480, Loss: -156.90802002\n",
      "Iteration: 34490, Loss: -168.610107422\n",
      "Iteration: 34500, Loss: -166.414825439\n",
      "Iteration: 34510, Loss: -161.541442871\n",
      "Iteration: 34520, Loss: -140.554946899\n",
      "Iteration: 34530, Loss: -142.914154053\n",
      "Iteration: 34540, Loss: -163.623733521\n",
      "Iteration: 34550, Loss: -143.263137817\n",
      "Iteration: 34560, Loss: -149.909179688\n",
      "Iteration: 34570, Loss: -172.356231689\n",
      "Iteration: 34580, Loss: -157.840576172\n",
      "Iteration: 34590, Loss: -147.542205811\n",
      "Iteration: 34600, Loss: -154.113586426\n",
      "Iteration: 34610, Loss: -144.424530029\n",
      "Iteration: 34620, Loss: -153.862243652\n",
      "Iteration: 34630, Loss: -137.385482788\n",
      "Iteration: 34640, Loss: -143.790893555\n",
      "Iteration: 34650, Loss: -150.809677124\n",
      "Iteration: 34660, Loss: -168.365997314\n",
      "Iteration: 34670, Loss: -151.533874512\n",
      "Iteration: 34680, Loss: -150.417388916\n",
      "Iteration: 34690, Loss: -158.08581543\n",
      "Iteration: 34700, Loss: -162.117584229\n",
      "Iteration: 34710, Loss: -148.254898071\n",
      "Iteration: 34720, Loss: -154.910354614\n",
      "Iteration: 34730, Loss: -164.888122559\n",
      "Iteration: 34740, Loss: -151.258026123\n",
      "Iteration: 34750, Loss: -149.856964111\n",
      "Iteration: 34760, Loss: -145.300750732\n",
      "Iteration: 34770, Loss: -141.802536011\n",
      "Iteration: 34780, Loss: -155.621856689\n",
      "Iteration: 34790, Loss: -155.152648926\n",
      "Iteration: 34800, Loss: -174.139282227\n",
      "Iteration: 34810, Loss: -154.343078613\n",
      "Iteration: 34820, Loss: -152.639846802\n",
      "Iteration: 34830, Loss: -165.890289307\n",
      "Iteration: 34840, Loss: -147.311309814\n",
      "Iteration: 34850, Loss: -158.289077759\n",
      "Iteration: 34860, Loss: -148.885940552\n",
      "Iteration: 34870, Loss: -151.992919922\n",
      "Iteration: 34880, Loss: -157.068557739\n",
      "Iteration: 34890, Loss: -140.705612183\n",
      "Iteration: 34900, Loss: -158.966583252\n",
      "Iteration: 34910, Loss: -150.293930054\n",
      "Iteration: 34920, Loss: -131.638671875\n",
      "Iteration: 34930, Loss: -150.492797852\n",
      "Iteration: 34940, Loss: -142.865936279\n",
      "Iteration: 34950, Loss: -150.439956665\n",
      "Iteration: 34960, Loss: -145.975494385\n",
      "Iteration: 34970, Loss: -147.717269897\n",
      "Iteration: 34980, Loss: -150.75302124\n",
      "Iteration: 34990, Loss: -150.50491333\n",
      "Iteration: 35000, Loss: -140.211288452\n",
      "Iteration: 35010, Loss: -142.536956787\n",
      "Iteration: 35020, Loss: -145.839630127\n",
      "Iteration: 35030, Loss: -147.080993652\n",
      "Iteration: 35040, Loss: -150.315826416\n",
      "Iteration: 35050, Loss: -161.815917969\n",
      "Iteration: 35060, Loss: -152.559921265\n",
      "Iteration: 35070, Loss: -155.145629883\n",
      "Iteration: 35080, Loss: -167.555526733\n",
      "Iteration: 35090, Loss: -141.911254883\n",
      "Iteration: 35100, Loss: -146.696990967\n",
      "Iteration: 35110, Loss: -135.590393066\n",
      "Iteration: 35120, Loss: -147.294708252\n",
      "Iteration: 35130, Loss: -141.126785278\n",
      "Iteration: 35140, Loss: -145.328216553\n",
      "Iteration: 35150, Loss: -149.885070801\n",
      "Iteration: 35160, Loss: -155.028015137\n",
      "Iteration: 35170, Loss: -149.553070068\n",
      "Iteration: 35180, Loss: -147.075408936\n",
      "Iteration: 35190, Loss: -132.890548706\n",
      "Iteration: 35200, Loss: -163.981658936\n",
      "Iteration: 35210, Loss: -163.168579102\n",
      "Iteration: 35220, Loss: -151.134094238\n",
      "Iteration: 35230, Loss: -141.459259033\n",
      "Iteration: 35240, Loss: -178.061035156\n",
      "Iteration: 35250, Loss: -173.272216797\n",
      "Iteration: 35260, Loss: -161.603515625\n",
      "Iteration: 35270, Loss: -157.040100098\n",
      "Iteration: 35280, Loss: -154.270263672\n",
      "Iteration: 35290, Loss: -153.184539795\n",
      "Iteration: 35300, Loss: -164.424865723\n",
      "Iteration: 35310, Loss: -152.080993652\n",
      "Iteration: 35320, Loss: -160.326812744\n",
      "Iteration: 35330, Loss: -166.061264038\n",
      "Iteration: 35340, Loss: -149.878387451\n",
      "Iteration: 35350, Loss: -148.379943848\n",
      "Iteration: 35360, Loss: -144.939819336\n",
      "Iteration: 35370, Loss: -140.799697876\n",
      "Iteration: 35380, Loss: -149.528762817\n",
      "Iteration: 35390, Loss: -150.258087158\n",
      "Iteration: 35400, Loss: -168.73928833\n",
      "Iteration: 35410, Loss: -161.512329102\n",
      "Iteration: 35420, Loss: -162.103286743\n",
      "Iteration: 35430, Loss: -149.584625244\n",
      "Iteration: 35440, Loss: -156.116790771\n",
      "Iteration: 35450, Loss: -157.345932007\n",
      "Iteration: 35460, Loss: -141.340911865\n",
      "Iteration: 35470, Loss: -148.14390564\n",
      "Iteration: 35480, Loss: -151.785919189\n",
      "Iteration: 35490, Loss: -157.169036865\n",
      "Iteration: 35500, Loss: -151.184509277\n",
      "Iteration: 35510, Loss: -159.574798584\n",
      "Iteration: 35520, Loss: -151.516738892\n",
      "Iteration: 35530, Loss: -153.829681396\n",
      "Iteration: 35540, Loss: -152.03817749\n",
      "Iteration: 35550, Loss: -143.271026611\n",
      "Iteration: 35560, Loss: -177.229675293\n",
      "Iteration: 35570, Loss: -173.893463135\n",
      "Iteration: 35580, Loss: -157.168624878\n",
      "Iteration: 35590, Loss: -163.669067383\n",
      "Iteration: 35600, Loss: -141.309585571\n",
      "Iteration: 35610, Loss: -153.999053955\n",
      "Iteration: 35620, Loss: -154.458724976\n",
      "Iteration: 35630, Loss: -154.616439819\n",
      "Iteration: 35640, Loss: -133.68347168\n",
      "Iteration: 35650, Loss: -146.275085449\n",
      "Iteration: 35660, Loss: -138.522583008\n",
      "Iteration: 35670, Loss: -158.589996338\n",
      "Iteration: 35680, Loss: -165.748657227\n",
      "Iteration: 35690, Loss: -141.321807861\n",
      "Iteration: 35700, Loss: -155.166564941\n",
      "Iteration: 35710, Loss: -168.401443481\n",
      "Iteration: 35720, Loss: -141.301971436\n",
      "Iteration: 35730, Loss: -170.80267334\n",
      "Iteration: 35740, Loss: -145.794708252\n",
      "Iteration: 35750, Loss: -142.910354614\n",
      "Iteration: 35760, Loss: -149.531524658\n",
      "Iteration: 35770, Loss: -156.244949341\n",
      "Iteration: 35780, Loss: -150.683578491\n",
      "Iteration: 35790, Loss: -145.671630859\n",
      "Iteration: 35800, Loss: -154.321746826\n",
      "Iteration: 35810, Loss: -157.217315674\n",
      "Iteration: 35820, Loss: -152.240386963\n",
      "Iteration: 35830, Loss: -146.464996338\n",
      "Iteration: 35840, Loss: -154.618499756\n",
      "Iteration: 35850, Loss: -144.382110596\n",
      "Iteration: 35860, Loss: -164.553131104\n",
      "Iteration: 35870, Loss: -139.579864502\n",
      "Iteration: 35880, Loss: -160.189804077\n",
      "Iteration: 35890, Loss: -146.0909729\n",
      "Iteration: 35900, Loss: -148.511932373\n",
      "Iteration: 35910, Loss: -148.753616333\n",
      "Iteration: 35920, Loss: -153.179931641\n",
      "Iteration: 35930, Loss: -164.274734497\n",
      "Iteration: 35940, Loss: -149.993225098\n",
      "Iteration: 35950, Loss: -149.828430176\n",
      "Iteration: 35960, Loss: -177.787597656\n",
      "Iteration: 35970, Loss: -152.860595703\n",
      "Iteration: 35980, Loss: -151.554504395\n",
      "Iteration: 35990, Loss: -155.823394775\n",
      "Iteration: 36000, Loss: -158.978057861\n",
      "Iteration: 36010, Loss: -154.716796875\n",
      "Iteration: 36020, Loss: -139.577255249\n",
      "Iteration: 36030, Loss: -140.242553711\n",
      "Iteration: 36040, Loss: -155.17401123\n",
      "Iteration: 36050, Loss: -151.055419922\n",
      "Iteration: 36060, Loss: -161.466918945\n",
      "Iteration: 36070, Loss: -139.736953735\n",
      "Iteration: 36080, Loss: -157.543060303\n",
      "Iteration: 36090, Loss: -146.531066895\n",
      "Iteration: 36100, Loss: -151.842407227\n",
      "Iteration: 36110, Loss: -146.337188721\n",
      "Iteration: 36120, Loss: -149.019699097\n",
      "Iteration: 36130, Loss: -159.419189453\n",
      "Iteration: 36140, Loss: -158.499679565\n",
      "Iteration: 36150, Loss: -159.565551758\n",
      "Iteration: 36160, Loss: -159.706924438\n",
      "Iteration: 36170, Loss: -151.309066772\n",
      "Iteration: 36180, Loss: -153.117401123\n",
      "Iteration: 36190, Loss: -144.334594727\n",
      "Iteration: 36200, Loss: -156.149429321\n",
      "Iteration: 36210, Loss: -151.166381836\n",
      "Iteration: 36220, Loss: -143.884567261\n",
      "Iteration: 36230, Loss: -143.875747681\n",
      "Iteration: 36240, Loss: -150.210922241\n",
      "Iteration: 36250, Loss: -157.451431274\n",
      "Iteration: 36260, Loss: -149.313720703\n",
      "Iteration: 36270, Loss: -151.125213623\n",
      "Iteration: 36280, Loss: -158.269592285\n",
      "Iteration: 36290, Loss: -157.820556641\n",
      "Iteration: 36300, Loss: -162.664398193\n",
      "Iteration: 36310, Loss: -161.144592285\n",
      "Iteration: 36320, Loss: -149.591049194\n",
      "Iteration: 36330, Loss: -156.530776978\n",
      "Iteration: 36340, Loss: -149.202301025\n",
      "Iteration: 36350, Loss: -160.276443481\n",
      "Iteration: 36360, Loss: -150.869766235\n",
      "Iteration: 36370, Loss: -149.29989624\n",
      "Iteration: 36380, Loss: -149.019180298\n",
      "Iteration: 36390, Loss: -149.00340271\n",
      "Iteration: 36400, Loss: -165.031616211\n",
      "Iteration: 36410, Loss: -131.044921875\n",
      "Iteration: 36420, Loss: -161.787628174\n",
      "Iteration: 36430, Loss: -149.6065979\n",
      "Iteration: 36440, Loss: -149.408004761\n",
      "Iteration: 36450, Loss: -152.386703491\n",
      "Iteration: 36460, Loss: -134.351516724\n",
      "Iteration: 36470, Loss: -157.234832764\n",
      "Iteration: 36480, Loss: -162.40536499\n",
      "Iteration: 36490, Loss: -163.175842285\n",
      "Iteration: 36500, Loss: -155.573944092\n",
      "Iteration: 36510, Loss: -155.420471191\n",
      "Iteration: 36520, Loss: -161.529052734\n",
      "Iteration: 36530, Loss: -163.509017944\n",
      "Iteration: 36540, Loss: -144.537124634\n",
      "Iteration: 36550, Loss: -134.524597168\n",
      "Iteration: 36560, Loss: -167.210968018\n",
      "Iteration: 36570, Loss: -164.360275269\n",
      "Iteration: 36580, Loss: -142.99621582\n",
      "Iteration: 36590, Loss: -157.200378418\n",
      "Iteration: 36600, Loss: -147.312591553\n",
      "Iteration: 36610, Loss: -159.828735352\n",
      "Iteration: 36620, Loss: -152.677246094\n",
      "Iteration: 36630, Loss: -159.041641235\n",
      "Iteration: 36640, Loss: -146.598419189\n",
      "Iteration: 36650, Loss: -169.65663147\n",
      "Iteration: 36660, Loss: -154.081878662\n",
      "Iteration: 36670, Loss: -148.461090088\n",
      "Iteration: 36680, Loss: -155.533325195\n",
      "Iteration: 36690, Loss: -147.740631104\n",
      "Iteration: 36700, Loss: -157.910369873\n",
      "Iteration: 36710, Loss: -147.708984375\n",
      "Iteration: 36720, Loss: -153.67640686\n",
      "Iteration: 36730, Loss: -163.64440918\n",
      "Iteration: 36740, Loss: -160.914474487\n",
      "Iteration: 36750, Loss: -160.250274658\n",
      "Iteration: 36760, Loss: -145.369216919\n",
      "Iteration: 36770, Loss: -162.912582397\n",
      "Iteration: 36780, Loss: -163.112625122\n",
      "Iteration: 36790, Loss: -130.714401245\n",
      "Iteration: 36800, Loss: -148.312408447\n",
      "Iteration: 36810, Loss: -153.460983276\n",
      "Iteration: 36820, Loss: -151.480987549\n",
      "Iteration: 36830, Loss: -142.931121826\n",
      "Iteration: 36840, Loss: -140.73600769\n",
      "Iteration: 36850, Loss: -160.824295044\n",
      "Iteration: 36860, Loss: -148.080673218\n",
      "Iteration: 36870, Loss: -150.542007446\n",
      "Iteration: 36880, Loss: -158.490615845\n",
      "Iteration: 36890, Loss: -157.572891235\n",
      "Iteration: 36900, Loss: -154.845535278\n",
      "Iteration: 36910, Loss: -160.472167969\n",
      "Iteration: 36920, Loss: -151.462356567\n",
      "Iteration: 36930, Loss: -152.649978638\n",
      "Iteration: 36940, Loss: -166.399902344\n",
      "Iteration: 36950, Loss: -151.345123291\n",
      "Iteration: 36960, Loss: -163.130477905\n",
      "Iteration: 36970, Loss: -139.97769165\n",
      "Iteration: 36980, Loss: -133.98526001\n",
      "Iteration: 36990, Loss: -170.270095825\n",
      "Iteration: 37000, Loss: -162.244934082\n",
      "Iteration: 37010, Loss: -150.5184021\n",
      "Iteration: 37020, Loss: -145.348358154\n",
      "Iteration: 37030, Loss: -155.254425049\n",
      "Iteration: 37040, Loss: -165.060317993\n",
      "Iteration: 37050, Loss: -156.695083618\n",
      "Iteration: 37060, Loss: -154.110336304\n",
      "Iteration: 37070, Loss: -150.304901123\n",
      "Iteration: 37080, Loss: -152.696716309\n",
      "Iteration: 37090, Loss: -147.309448242\n",
      "Iteration: 37100, Loss: -156.566711426\n",
      "Iteration: 37110, Loss: -141.35786438\n",
      "Iteration: 37120, Loss: -147.144378662\n",
      "Iteration: 37130, Loss: -139.952941895\n",
      "Iteration: 37140, Loss: -174.519058228\n",
      "Iteration: 37150, Loss: -157.482940674\n",
      "Iteration: 37160, Loss: -140.925994873\n",
      "Iteration: 37170, Loss: -152.857208252\n",
      "Iteration: 37180, Loss: -144.884216309\n",
      "Iteration: 37190, Loss: -145.692108154\n",
      "Iteration: 37200, Loss: -146.46295166\n",
      "Iteration: 37210, Loss: -162.269226074\n",
      "Iteration: 37220, Loss: -166.476272583\n",
      "Iteration: 37230, Loss: -145.481048584\n",
      "Iteration: 37240, Loss: -168.825439453\n",
      "Iteration: 37250, Loss: -170.540405273\n",
      "Iteration: 37260, Loss: -156.196777344\n",
      "Iteration: 37270, Loss: -160.790710449\n",
      "Iteration: 37280, Loss: -156.921676636\n",
      "Iteration: 37290, Loss: -148.510009766\n",
      "Iteration: 37300, Loss: -176.383148193\n",
      "Iteration: 37310, Loss: -146.525665283\n",
      "Iteration: 37320, Loss: -167.549484253\n",
      "Iteration: 37330, Loss: -162.673202515\n",
      "Iteration: 37340, Loss: -150.229492188\n",
      "Iteration: 37350, Loss: -151.41885376\n",
      "Iteration: 37360, Loss: -155.985137939\n",
      "Iteration: 37370, Loss: -129.171173096\n",
      "Iteration: 37380, Loss: -155.088989258\n",
      "Iteration: 37390, Loss: -150.507904053\n",
      "Iteration: 37400, Loss: -147.453125\n",
      "Iteration: 37410, Loss: -152.99671936\n",
      "Iteration: 37420, Loss: -147.183349609\n",
      "Iteration: 37430, Loss: -157.377624512\n",
      "Iteration: 37440, Loss: -152.197784424\n",
      "Iteration: 37450, Loss: -162.925354004\n",
      "Iteration: 37460, Loss: -154.811309814\n",
      "Iteration: 37470, Loss: -153.396697998\n",
      "Iteration: 37480, Loss: -140.538482666\n",
      "Iteration: 37490, Loss: -150.884658813\n",
      "Iteration: 37500, Loss: -154.307098389\n",
      "Iteration: 37510, Loss: -144.207168579\n",
      "Iteration: 37520, Loss: -158.015960693\n",
      "Iteration: 37530, Loss: -154.648254395\n",
      "Iteration: 37540, Loss: -152.942184448\n",
      "Iteration: 37550, Loss: -147.903869629\n",
      "Iteration: 37560, Loss: -163.469497681\n",
      "Iteration: 37570, Loss: -143.444763184\n",
      "Iteration: 37580, Loss: -143.33921814\n",
      "Iteration: 37590, Loss: -149.460998535\n",
      "Iteration: 37600, Loss: -151.38243103\n",
      "Iteration: 37610, Loss: -145.568115234\n",
      "Iteration: 37620, Loss: -174.082641602\n",
      "Iteration: 37630, Loss: -138.844558716\n",
      "Iteration: 37640, Loss: -142.828353882\n",
      "Iteration: 37650, Loss: -172.969787598\n",
      "Iteration: 37660, Loss: -146.451034546\n",
      "Iteration: 37670, Loss: -152.970565796\n",
      "Iteration: 37680, Loss: -128.987915039\n",
      "Iteration: 37690, Loss: -140.568634033\n",
      "Iteration: 37700, Loss: -151.863952637\n",
      "Iteration: 37710, Loss: -146.414001465\n",
      "Iteration: 37720, Loss: -146.708374023\n",
      "Iteration: 37730, Loss: -132.776626587\n",
      "Iteration: 37740, Loss: -153.095092773\n",
      "Iteration: 37750, Loss: -135.310806274\n",
      "Iteration: 37760, Loss: -147.505828857\n",
      "Iteration: 37770, Loss: -148.442840576\n",
      "Iteration: 37780, Loss: -151.470123291\n",
      "Iteration: 37790, Loss: -145.43687439\n",
      "Iteration: 37800, Loss: -152.32963562\n",
      "Iteration: 37810, Loss: -152.65524292\n",
      "Iteration: 37820, Loss: -141.014801025\n",
      "Iteration: 37830, Loss: -148.13394165\n",
      "Iteration: 37840, Loss: -141.176376343\n",
      "Iteration: 37850, Loss: -142.759033203\n",
      "Iteration: 37860, Loss: -142.84147644\n",
      "Iteration: 37870, Loss: -153.899017334\n",
      "Iteration: 37880, Loss: -156.932327271\n",
      "Iteration: 37890, Loss: -144.592193604\n",
      "Iteration: 37900, Loss: -136.473434448\n",
      "Iteration: 37910, Loss: -145.096893311\n",
      "Iteration: 37920, Loss: -159.268981934\n",
      "Iteration: 37930, Loss: -159.093658447\n",
      "Iteration: 37940, Loss: -151.415512085\n",
      "Iteration: 37950, Loss: -153.549453735\n",
      "Iteration: 37960, Loss: -153.780715942\n",
      "Iteration: 37970, Loss: -143.311340332\n",
      "Iteration: 37980, Loss: -136.529632568\n",
      "Iteration: 37990, Loss: -146.901229858\n",
      "Iteration: 38000, Loss: -135.661224365\n",
      "Iteration: 38010, Loss: -162.796813965\n",
      "Iteration: 38020, Loss: -148.053604126\n",
      "Iteration: 38030, Loss: -159.741470337\n",
      "Iteration: 38040, Loss: -164.753067017\n",
      "Iteration: 38050, Loss: -140.382110596\n",
      "Iteration: 38060, Loss: -138.703613281\n",
      "Iteration: 38070, Loss: -136.82572937\n",
      "Iteration: 38080, Loss: -159.929397583\n",
      "Iteration: 38090, Loss: -149.262786865\n",
      "Iteration: 38100, Loss: -145.716049194\n",
      "Iteration: 38110, Loss: -147.590484619\n",
      "Iteration: 38120, Loss: -145.246124268\n",
      "Iteration: 38130, Loss: -170.92868042\n",
      "Iteration: 38140, Loss: -158.808563232\n",
      "Iteration: 38150, Loss: -149.359832764\n",
      "Iteration: 38160, Loss: -161.630752563\n",
      "Iteration: 38170, Loss: -148.116455078\n",
      "Iteration: 38180, Loss: -142.974456787\n",
      "Iteration: 38190, Loss: -151.863815308\n",
      "Iteration: 38200, Loss: -146.250320435\n",
      "Iteration: 38210, Loss: -146.945861816\n",
      "Iteration: 38220, Loss: -158.82220459\n",
      "Iteration: 38230, Loss: -126.547454834\n",
      "Iteration: 38240, Loss: -157.35760498\n",
      "Iteration: 38250, Loss: -132.49281311\n",
      "Iteration: 38260, Loss: -146.408966064\n",
      "Iteration: 38270, Loss: -146.025787354\n",
      "Iteration: 38280, Loss: -143.179870605\n",
      "Iteration: 38290, Loss: -155.577728271\n",
      "Iteration: 38300, Loss: -152.485336304\n",
      "Iteration: 38310, Loss: -151.537475586\n",
      "Iteration: 38320, Loss: -138.839035034\n",
      "Iteration: 38330, Loss: -154.575775146\n",
      "Iteration: 38340, Loss: -161.239837646\n",
      "Iteration: 38350, Loss: -152.039871216\n",
      "Iteration: 38360, Loss: -143.330932617\n",
      "Iteration: 38370, Loss: -143.595474243\n",
      "Iteration: 38380, Loss: -152.858810425\n",
      "Iteration: 38390, Loss: -142.087188721\n",
      "Iteration: 38400, Loss: -168.541046143\n",
      "Iteration: 38410, Loss: -165.487045288\n",
      "Iteration: 38420, Loss: -150.347564697\n",
      "Iteration: 38430, Loss: -149.805541992\n",
      "Iteration: 38440, Loss: -154.290802002\n",
      "Iteration: 38450, Loss: -157.838043213\n",
      "Iteration: 38460, Loss: -150.693511963\n",
      "Iteration: 38470, Loss: -179.078125\n",
      "Iteration: 38480, Loss: -140.786132812\n",
      "Iteration: 38490, Loss: -163.014312744\n",
      "Iteration: 38500, Loss: -154.060714722\n",
      "Iteration: 38510, Loss: -142.857971191\n",
      "Iteration: 38520, Loss: -159.362960815\n",
      "Iteration: 38530, Loss: -135.975402832\n",
      "Iteration: 38540, Loss: -142.717269897\n",
      "Iteration: 38550, Loss: -151.350204468\n",
      "Iteration: 38560, Loss: -140.587402344\n",
      "Iteration: 38570, Loss: -163.697021484\n",
      "Iteration: 38580, Loss: -156.636383057\n",
      "Iteration: 38590, Loss: -154.598464966\n",
      "Iteration: 38600, Loss: -151.327346802\n",
      "Iteration: 38610, Loss: -154.281829834\n",
      "Iteration: 38620, Loss: -155.016708374\n",
      "Iteration: 38630, Loss: -150.064971924\n",
      "Iteration: 38640, Loss: -156.867614746\n",
      "Iteration: 38650, Loss: -168.365036011\n",
      "Iteration: 38660, Loss: -141.855743408\n",
      "Iteration: 38670, Loss: -139.706436157\n",
      "Iteration: 38680, Loss: -158.645599365\n",
      "Iteration: 38690, Loss: -159.043792725\n",
      "Iteration: 38700, Loss: -144.059173584\n",
      "Iteration: 38710, Loss: -149.060836792\n",
      "Iteration: 38720, Loss: -144.444274902\n",
      "Iteration: 38730, Loss: -140.335067749\n",
      "Iteration: 38740, Loss: -150.703826904\n",
      "Iteration: 38750, Loss: -148.389511108\n",
      "Iteration: 38760, Loss: -152.362686157\n",
      "Iteration: 38770, Loss: -146.571502686\n",
      "Iteration: 38780, Loss: -155.250961304\n",
      "Iteration: 38790, Loss: -161.01739502\n",
      "Iteration: 38800, Loss: -135.810913086\n",
      "Iteration: 38810, Loss: -159.368743896\n",
      "Iteration: 38820, Loss: -143.317764282\n",
      "Iteration: 38830, Loss: -142.887359619\n",
      "Iteration: 38840, Loss: -149.202880859\n",
      "Iteration: 38850, Loss: -149.86605835\n",
      "Iteration: 38860, Loss: -153.186279297\n",
      "Iteration: 38870, Loss: -149.053161621\n",
      "Iteration: 38880, Loss: -157.698760986\n",
      "Iteration: 38890, Loss: -149.805984497\n",
      "Iteration: 38900, Loss: -148.930358887\n",
      "Iteration: 38910, Loss: -154.55166626\n",
      "Iteration: 38920, Loss: -144.254425049\n",
      "Iteration: 38930, Loss: -155.067901611\n",
      "Iteration: 38940, Loss: -145.206512451\n",
      "Iteration: 38950, Loss: -150.535583496\n",
      "Iteration: 38960, Loss: -146.081100464\n",
      "Iteration: 38970, Loss: -148.364440918\n",
      "Iteration: 38980, Loss: -146.94921875\n",
      "Iteration: 38990, Loss: -156.070007324\n",
      "Iteration: 39000, Loss: -152.264251709\n",
      "Iteration: 39010, Loss: -172.997467041\n",
      "Iteration: 39020, Loss: -154.294555664\n",
      "Iteration: 39030, Loss: -148.444122314\n",
      "Iteration: 39040, Loss: -140.533584595\n",
      "Iteration: 39050, Loss: -130.919006348\n",
      "Iteration: 39060, Loss: -160.552627563\n",
      "Iteration: 39070, Loss: -155.022155762\n",
      "Iteration: 39080, Loss: -154.171844482\n",
      "Iteration: 39090, Loss: -146.582962036\n",
      "Iteration: 39100, Loss: -140.161193848\n",
      "Iteration: 39110, Loss: -156.326324463\n",
      "Iteration: 39120, Loss: -166.413528442\n",
      "Iteration: 39130, Loss: -157.014663696\n",
      "Iteration: 39140, Loss: -152.241928101\n",
      "Iteration: 39150, Loss: -141.185745239\n",
      "Iteration: 39160, Loss: -163.486877441\n",
      "Iteration: 39170, Loss: -143.166046143\n",
      "Iteration: 39180, Loss: -149.118103027\n",
      "Iteration: 39190, Loss: -164.131958008\n",
      "Iteration: 39200, Loss: -151.052185059\n",
      "Iteration: 39210, Loss: -153.347137451\n",
      "Iteration: 39220, Loss: -137.118133545\n",
      "Iteration: 39230, Loss: -153.633575439\n",
      "Iteration: 39240, Loss: -158.415496826\n",
      "Iteration: 39250, Loss: -157.384918213\n",
      "Iteration: 39260, Loss: -152.744064331\n",
      "Iteration: 39270, Loss: -143.010391235\n",
      "Iteration: 39280, Loss: -144.750213623\n",
      "Iteration: 39290, Loss: -163.001525879\n",
      "Iteration: 39300, Loss: -165.261810303\n",
      "Iteration: 39310, Loss: -168.901947021\n",
      "Iteration: 39320, Loss: -152.775100708\n",
      "Iteration: 39330, Loss: -140.28314209\n",
      "Iteration: 39340, Loss: -140.376739502\n",
      "Iteration: 39350, Loss: -153.115539551\n",
      "Iteration: 39360, Loss: -161.895401001\n",
      "Iteration: 39370, Loss: -152.667160034\n",
      "Iteration: 39380, Loss: -147.410949707\n",
      "Iteration: 39390, Loss: -154.52255249\n",
      "Iteration: 39400, Loss: -143.017120361\n",
      "Iteration: 39410, Loss: -148.922775269\n",
      "Iteration: 39420, Loss: -159.777984619\n",
      "Iteration: 39430, Loss: -161.343215942\n",
      "Iteration: 39440, Loss: -142.82623291\n",
      "Iteration: 39450, Loss: -155.478622437\n",
      "Iteration: 39460, Loss: -155.928451538\n",
      "Iteration: 39470, Loss: -150.548782349\n",
      "Iteration: 39480, Loss: -153.530883789\n",
      "Iteration: 39490, Loss: -157.119186401\n",
      "Iteration: 39500, Loss: -149.159881592\n",
      "Iteration: 39510, Loss: -156.190124512\n",
      "Iteration: 39520, Loss: -150.343933105\n",
      "Iteration: 39530, Loss: -154.801330566\n",
      "Iteration: 39540, Loss: -155.652908325\n",
      "Iteration: 39550, Loss: -144.65411377\n",
      "Iteration: 39560, Loss: -162.166824341\n",
      "Iteration: 39570, Loss: -147.488677979\n",
      "Iteration: 39580, Loss: -142.261245728\n",
      "Iteration: 39590, Loss: -152.067626953\n",
      "Iteration: 39600, Loss: -143.19078064\n",
      "Iteration: 39610, Loss: -142.298629761\n",
      "Iteration: 39620, Loss: -146.820129395\n",
      "Iteration: 39630, Loss: -138.327957153\n",
      "Iteration: 39640, Loss: -169.151748657\n",
      "Iteration: 39650, Loss: -133.577377319\n",
      "Iteration: 39660, Loss: -134.901611328\n",
      "Iteration: 39670, Loss: -145.41229248\n",
      "Iteration: 39680, Loss: -153.751754761\n",
      "Iteration: 39690, Loss: -133.938400269\n",
      "Iteration: 39700, Loss: -149.427566528\n",
      "Iteration: 39710, Loss: -145.179595947\n",
      "Iteration: 39720, Loss: -158.055786133\n",
      "Iteration: 39730, Loss: -143.03692627\n",
      "Iteration: 39740, Loss: -129.121688843\n",
      "Iteration: 39750, Loss: -141.688262939\n",
      "Iteration: 39760, Loss: -136.863555908\n",
      "Iteration: 39770, Loss: -165.757705688\n",
      "Iteration: 39780, Loss: -139.055664062\n",
      "Iteration: 39790, Loss: -150.807983398\n",
      "Iteration: 39800, Loss: -144.248062134\n",
      "Iteration: 39810, Loss: -138.011550903\n",
      "Iteration: 39820, Loss: -164.955551147\n",
      "Iteration: 39830, Loss: -165.250488281\n",
      "Iteration: 39840, Loss: -145.230529785\n",
      "Iteration: 39850, Loss: -147.788208008\n",
      "Iteration: 39860, Loss: -155.474502563\n",
      "Iteration: 39870, Loss: -172.397949219\n",
      "Iteration: 39880, Loss: -140.131103516\n",
      "Iteration: 39890, Loss: -151.968444824\n",
      "Iteration: 39900, Loss: -149.003295898\n",
      "Iteration: 39910, Loss: -158.271484375\n",
      "Iteration: 39920, Loss: -161.469909668\n",
      "Iteration: 39930, Loss: -155.240142822\n",
      "Iteration: 39940, Loss: -138.045028687\n",
      "Iteration: 39950, Loss: -146.507705688\n",
      "Iteration: 39960, Loss: -147.378295898\n",
      "Iteration: 39970, Loss: -140.14553833\n",
      "Iteration: 39980, Loss: -155.507293701\n",
      "Iteration: 39990, Loss: -131.628112793\n",
      "Iteration: 40000, Loss: -155.471786499\n",
      "Iteration: 40010, Loss: -159.10144043\n",
      "Iteration: 40020, Loss: -151.44909668\n",
      "Iteration: 40030, Loss: -138.764709473\n",
      "Iteration: 40040, Loss: -142.020782471\n",
      "Iteration: 40050, Loss: -147.524124146\n",
      "Iteration: 40060, Loss: -145.100906372\n",
      "Iteration: 40070, Loss: -157.374267578\n",
      "Iteration: 40080, Loss: -163.553207397\n",
      "Iteration: 40090, Loss: -144.142364502\n",
      "Iteration: 40100, Loss: -169.221054077\n",
      "Iteration: 40110, Loss: -153.093414307\n",
      "Iteration: 40120, Loss: -131.73324585\n",
      "Iteration: 40130, Loss: -155.053970337\n",
      "Iteration: 40140, Loss: -151.851104736\n",
      "Iteration: 40150, Loss: -157.142364502\n",
      "Iteration: 40160, Loss: -151.188491821\n",
      "Iteration: 40170, Loss: -157.694061279\n",
      "Iteration: 40180, Loss: -137.237838745\n",
      "Iteration: 40190, Loss: -143.767883301\n",
      "Iteration: 40200, Loss: -157.785400391\n",
      "Iteration: 40210, Loss: -148.717041016\n",
      "Iteration: 40220, Loss: -151.820953369\n",
      "Iteration: 40230, Loss: -156.680877686\n",
      "Iteration: 40240, Loss: -142.903137207\n",
      "Iteration: 40250, Loss: -150.45501709\n",
      "Iteration: 40260, Loss: -137.65447998\n",
      "Iteration: 40270, Loss: -145.860992432\n",
      "Iteration: 40280, Loss: -181.018005371\n",
      "Iteration: 40290, Loss: -151.934020996\n",
      "Iteration: 40300, Loss: -154.78364563\n",
      "Iteration: 40310, Loss: -151.786468506\n",
      "Iteration: 40320, Loss: -151.427978516\n",
      "Iteration: 40330, Loss: -149.725357056\n",
      "Iteration: 40340, Loss: -137.402435303\n",
      "Iteration: 40350, Loss: -166.515090942\n",
      "Iteration: 40360, Loss: -147.761199951\n",
      "Iteration: 40370, Loss: -166.557571411\n",
      "Iteration: 40380, Loss: -156.051300049\n",
      "Iteration: 40390, Loss: -141.383514404\n",
      "Iteration: 40400, Loss: -157.607391357\n",
      "Iteration: 40410, Loss: -162.047271729\n",
      "Iteration: 40420, Loss: -168.664733887\n",
      "Iteration: 40430, Loss: -161.836975098\n",
      "Iteration: 40440, Loss: -151.701171875\n",
      "Iteration: 40450, Loss: -146.984390259\n",
      "Iteration: 40460, Loss: -149.386810303\n",
      "Iteration: 40470, Loss: -162.980010986\n",
      "Iteration: 40480, Loss: -137.752700806\n",
      "Iteration: 40490, Loss: -140.820419312\n",
      "Iteration: 40500, Loss: -159.237136841\n",
      "Iteration: 40510, Loss: -138.697906494\n",
      "Iteration: 40520, Loss: -133.595245361\n",
      "Iteration: 40530, Loss: -158.831237793\n",
      "Iteration: 40540, Loss: -156.262039185\n",
      "Iteration: 40550, Loss: -160.100021362\n",
      "Iteration: 40560, Loss: -148.879699707\n",
      "Iteration: 40570, Loss: -166.894134521\n",
      "Iteration: 40580, Loss: -150.183761597\n",
      "Iteration: 40590, Loss: -142.878677368\n",
      "Iteration: 40600, Loss: -144.931503296\n",
      "Iteration: 40610, Loss: -163.899658203\n",
      "Iteration: 40620, Loss: -145.697540283\n",
      "Iteration: 40630, Loss: -136.458862305\n",
      "Iteration: 40640, Loss: -149.465835571\n",
      "Iteration: 40650, Loss: -147.257598877\n",
      "Iteration: 40660, Loss: -141.806671143\n",
      "Iteration: 40670, Loss: -158.128692627\n",
      "Iteration: 40680, Loss: -156.92678833\n",
      "Iteration: 40690, Loss: -155.130950928\n",
      "Iteration: 40700, Loss: -152.772766113\n",
      "Iteration: 40710, Loss: -156.48600769\n",
      "Iteration: 40720, Loss: -143.218078613\n",
      "Iteration: 40730, Loss: -144.102905273\n",
      "Iteration: 40740, Loss: -145.812469482\n",
      "Iteration: 40750, Loss: -164.095977783\n",
      "Iteration: 40760, Loss: -149.172485352\n",
      "Iteration: 40770, Loss: -152.23034668\n",
      "Iteration: 40780, Loss: -155.65524292\n",
      "Iteration: 40790, Loss: -152.239532471\n",
      "Iteration: 40800, Loss: -137.855438232\n",
      "Iteration: 40810, Loss: -153.457672119\n",
      "Iteration: 40820, Loss: -147.30569458\n",
      "Iteration: 40830, Loss: -165.136108398\n",
      "Iteration: 40840, Loss: -146.362197876\n",
      "Iteration: 40850, Loss: -144.585296631\n",
      "Iteration: 40860, Loss: -153.352111816\n",
      "Iteration: 40870, Loss: -152.00227356\n",
      "Iteration: 40880, Loss: -151.186096191\n",
      "Iteration: 40890, Loss: -139.271347046\n",
      "Iteration: 40900, Loss: -142.563659668\n",
      "Iteration: 40910, Loss: -132.350891113\n",
      "Iteration: 40920, Loss: -150.598495483\n",
      "Iteration: 40930, Loss: -146.14453125\n",
      "Iteration: 40940, Loss: -149.119247437\n",
      "Iteration: 40950, Loss: -160.032531738\n",
      "Iteration: 40960, Loss: -154.363800049\n",
      "Iteration: 40970, Loss: -143.803009033\n",
      "Iteration: 40980, Loss: -161.74420166\n",
      "Iteration: 40990, Loss: -143.088500977\n",
      "Iteration: 41000, Loss: -148.288467407\n",
      "Iteration: 41010, Loss: -147.254394531\n",
      "Iteration: 41020, Loss: -150.851501465\n",
      "Iteration: 41030, Loss: -156.804473877\n",
      "Iteration: 41040, Loss: -133.153152466\n",
      "Iteration: 41050, Loss: -145.871063232\n",
      "Iteration: 41060, Loss: -155.345352173\n",
      "Iteration: 41070, Loss: -148.405517578\n",
      "Iteration: 41080, Loss: -153.492218018\n",
      "Iteration: 41090, Loss: -149.101913452\n",
      "Iteration: 41100, Loss: -146.393661499\n",
      "Iteration: 41110, Loss: -150.860610962\n",
      "Iteration: 41120, Loss: -134.658355713\n",
      "Iteration: 41130, Loss: -139.96824646\n",
      "Iteration: 41140, Loss: -148.527008057\n",
      "Iteration: 41150, Loss: -147.597747803\n",
      "Iteration: 41160, Loss: -142.474395752\n",
      "Iteration: 41170, Loss: -166.580963135\n",
      "Iteration: 41180, Loss: -148.00378418\n",
      "Iteration: 41190, Loss: -148.048599243\n",
      "Iteration: 41200, Loss: -144.597198486\n",
      "Iteration: 41210, Loss: -129.826293945\n",
      "Iteration: 41220, Loss: -162.236816406\n",
      "Iteration: 41230, Loss: -141.318115234\n",
      "Iteration: 41240, Loss: -151.601226807\n",
      "Iteration: 41250, Loss: -142.746459961\n",
      "Iteration: 41260, Loss: -159.232269287\n",
      "Iteration: 41270, Loss: -150.326431274\n",
      "Iteration: 41280, Loss: -157.153625488\n",
      "Iteration: 41290, Loss: -151.441101074\n",
      "Iteration: 41300, Loss: -161.767318726\n",
      "Iteration: 41310, Loss: -156.448944092\n",
      "Iteration: 41320, Loss: -139.232727051\n",
      "Iteration: 41330, Loss: -148.437789917\n",
      "Iteration: 41340, Loss: -163.497924805\n",
      "Iteration: 41350, Loss: -153.964385986\n",
      "Iteration: 41360, Loss: -164.145370483\n",
      "Iteration: 41370, Loss: -147.578948975\n",
      "Iteration: 41380, Loss: -137.730682373\n",
      "Iteration: 41390, Loss: -151.97253418\n",
      "Iteration: 41400, Loss: -143.384216309\n",
      "Iteration: 41410, Loss: -161.227462769\n",
      "Iteration: 41420, Loss: -161.419662476\n",
      "Iteration: 41430, Loss: -150.27746582\n",
      "Iteration: 41440, Loss: -136.536132812\n",
      "Iteration: 41450, Loss: -162.554931641\n",
      "Iteration: 41460, Loss: -158.531066895\n",
      "Iteration: 41470, Loss: -137.025665283\n",
      "Iteration: 41480, Loss: -141.945495605\n",
      "Iteration: 41490, Loss: -160.720947266\n",
      "Iteration: 41500, Loss: -155.97505188\n",
      "Iteration: 41510, Loss: -150.883453369\n",
      "Iteration: 41520, Loss: -152.566345215\n",
      "Iteration: 41530, Loss: -143.730438232\n",
      "Iteration: 41540, Loss: -145.88973999\n",
      "Iteration: 41550, Loss: -150.001159668\n",
      "Iteration: 41560, Loss: -143.294876099\n",
      "Iteration: 41570, Loss: -143.716217041\n",
      "Iteration: 41580, Loss: -149.420013428\n",
      "Iteration: 41590, Loss: -150.477416992\n",
      "Iteration: 41600, Loss: -147.234558105\n",
      "Iteration: 41610, Loss: -164.799530029\n",
      "Iteration: 41620, Loss: -142.898010254\n",
      "Iteration: 41630, Loss: -145.551971436\n",
      "Iteration: 41640, Loss: -152.22164917\n",
      "Iteration: 41650, Loss: -149.226989746\n",
      "Iteration: 41660, Loss: -152.556503296\n",
      "Iteration: 41670, Loss: -146.698699951\n",
      "Iteration: 41680, Loss: -143.041809082\n",
      "Iteration: 41690, Loss: -148.409454346\n",
      "Iteration: 41700, Loss: -152.725769043\n",
      "Iteration: 41710, Loss: -171.84425354\n",
      "Iteration: 41720, Loss: -145.636932373\n",
      "Iteration: 41730, Loss: -155.501785278\n",
      "Iteration: 41740, Loss: -170.080352783\n",
      "Iteration: 41750, Loss: -145.721160889\n",
      "Iteration: 41760, Loss: -154.244369507\n",
      "Iteration: 41770, Loss: -147.389312744\n",
      "Iteration: 41780, Loss: -156.67010498\n",
      "Iteration: 41790, Loss: -144.977111816\n",
      "Iteration: 41800, Loss: -134.121780396\n",
      "Iteration: 41810, Loss: -166.435943604\n",
      "Iteration: 41820, Loss: -160.410110474\n",
      "Iteration: 41830, Loss: -163.918121338\n",
      "Iteration: 41840, Loss: -164.970031738\n",
      "Iteration: 41850, Loss: -163.580825806\n",
      "Iteration: 41860, Loss: -136.396499634\n",
      "Iteration: 41870, Loss: -150.577087402\n",
      "Iteration: 41880, Loss: -134.657592773\n",
      "Iteration: 41890, Loss: -134.892700195\n",
      "Iteration: 41900, Loss: -157.513183594\n",
      "Iteration: 41910, Loss: -159.651916504\n",
      "Iteration: 41920, Loss: -144.90020752\n",
      "Iteration: 41930, Loss: -155.496612549\n",
      "Iteration: 41940, Loss: -151.038925171\n",
      "Iteration: 41950, Loss: -140.172454834\n",
      "Iteration: 41960, Loss: -148.625793457\n",
      "Iteration: 41970, Loss: -159.920074463\n",
      "Iteration: 41980, Loss: -148.260681152\n",
      "Iteration: 41990, Loss: -155.532958984\n",
      "Iteration: 42000, Loss: -145.183944702\n",
      "Iteration: 42010, Loss: -149.94442749\n",
      "Iteration: 42020, Loss: -149.903366089\n",
      "Iteration: 42030, Loss: -175.558532715\n",
      "Iteration: 42040, Loss: -152.430023193\n",
      "Iteration: 42050, Loss: -146.647903442\n",
      "Iteration: 42060, Loss: -160.778289795\n",
      "Iteration: 42070, Loss: -154.531860352\n",
      "Iteration: 42080, Loss: -140.106964111\n",
      "Iteration: 42090, Loss: -144.65133667\n",
      "Iteration: 42100, Loss: -157.787490845\n",
      "Iteration: 42110, Loss: -159.473968506\n",
      "Iteration: 42120, Loss: -141.574401855\n",
      "Iteration: 42130, Loss: -133.168228149\n",
      "Iteration: 42140, Loss: -134.461242676\n",
      "Iteration: 42150, Loss: -155.829040527\n",
      "Iteration: 42160, Loss: -137.171539307\n",
      "Iteration: 42170, Loss: -136.412414551\n",
      "Iteration: 42180, Loss: -154.937713623\n",
      "Iteration: 42190, Loss: -154.245422363\n",
      "Iteration: 42200, Loss: -153.730224609\n",
      "Iteration: 42210, Loss: -145.866333008\n",
      "Iteration: 42220, Loss: -153.339508057\n",
      "Iteration: 42230, Loss: -153.465820312\n",
      "Iteration: 42240, Loss: -157.252227783\n",
      "Iteration: 42250, Loss: -151.793487549\n",
      "Iteration: 42260, Loss: -141.397186279\n",
      "Iteration: 42270, Loss: -145.112228394\n",
      "Iteration: 42280, Loss: -134.539611816\n",
      "Iteration: 42290, Loss: -152.842666626\n",
      "Iteration: 42300, Loss: -139.221557617\n",
      "Iteration: 42310, Loss: -150.127685547\n",
      "Iteration: 42320, Loss: -146.57699585\n",
      "Iteration: 42330, Loss: -140.581207275\n",
      "Iteration: 42340, Loss: -144.218322754\n",
      "Iteration: 42350, Loss: -153.283599854\n",
      "Iteration: 42360, Loss: -152.898071289\n",
      "Iteration: 42370, Loss: -146.512237549\n",
      "Iteration: 42380, Loss: -151.093307495\n",
      "Iteration: 42390, Loss: -139.582763672\n",
      "Iteration: 42400, Loss: -155.019989014\n",
      "Iteration: 42410, Loss: -153.003112793\n",
      "Iteration: 42420, Loss: -156.627990723\n",
      "Iteration: 42430, Loss: -148.819763184\n",
      "Iteration: 42440, Loss: -149.108856201\n",
      "Iteration: 42450, Loss: -144.060211182\n",
      "Iteration: 42460, Loss: -145.593841553\n",
      "Iteration: 42470, Loss: -142.000366211\n",
      "Iteration: 42480, Loss: -165.265014648\n",
      "Iteration: 42490, Loss: -151.397399902\n",
      "Iteration: 42500, Loss: -141.754150391\n",
      "Iteration: 42510, Loss: -141.331314087\n",
      "Iteration: 42520, Loss: -163.866744995\n",
      "Iteration: 42530, Loss: -147.036819458\n",
      "Iteration: 42540, Loss: -150.135559082\n",
      "Iteration: 42550, Loss: -153.940795898\n",
      "Iteration: 42560, Loss: -170.440582275\n",
      "Iteration: 42570, Loss: -140.847213745\n",
      "Iteration: 42580, Loss: -156.604705811\n",
      "Iteration: 42590, Loss: -166.158325195\n",
      "Iteration: 42600, Loss: -149.564666748\n",
      "Iteration: 42610, Loss: -144.313568115\n",
      "Iteration: 42620, Loss: -138.907958984\n",
      "Iteration: 42630, Loss: -156.35949707\n",
      "Iteration: 42640, Loss: -156.290771484\n",
      "Iteration: 42650, Loss: -151.532592773\n",
      "Iteration: 42660, Loss: -142.413452148\n",
      "Iteration: 42670, Loss: -147.316467285\n",
      "Iteration: 42680, Loss: -164.725448608\n",
      "Iteration: 42690, Loss: -147.373779297\n",
      "Iteration: 42700, Loss: -137.218078613\n",
      "Iteration: 42710, Loss: -145.012649536\n",
      "Iteration: 42720, Loss: -142.495422363\n",
      "Iteration: 42730, Loss: -156.373184204\n",
      "Iteration: 42740, Loss: -143.14050293\n",
      "Iteration: 42750, Loss: -144.074432373\n",
      "Iteration: 42760, Loss: -149.652389526\n",
      "Iteration: 42770, Loss: -154.049407959\n",
      "Iteration: 42780, Loss: -153.903747559\n",
      "Iteration: 42790, Loss: -154.482620239\n",
      "Iteration: 42800, Loss: -155.903045654\n",
      "Iteration: 42810, Loss: -156.023468018\n",
      "Iteration: 42820, Loss: -144.609039307\n",
      "Iteration: 42830, Loss: -145.880813599\n",
      "Iteration: 42840, Loss: -137.65562439\n",
      "Iteration: 42850, Loss: -152.634674072\n",
      "Iteration: 42860, Loss: -153.665496826\n",
      "Iteration: 42870, Loss: -147.218765259\n",
      "Iteration: 42880, Loss: -139.714309692\n",
      "Iteration: 42890, Loss: -143.83631897\n",
      "Iteration: 42900, Loss: -166.981842041\n",
      "Iteration: 42910, Loss: -136.863296509\n",
      "Iteration: 42920, Loss: -143.58505249\n",
      "Iteration: 42930, Loss: -143.301376343\n",
      "Iteration: 42940, Loss: -161.528305054\n",
      "Iteration: 42950, Loss: -152.935592651\n",
      "Iteration: 42960, Loss: -155.548294067\n",
      "Iteration: 42970, Loss: -144.695037842\n",
      "Iteration: 42980, Loss: -150.571838379\n",
      "Iteration: 42990, Loss: -159.795654297\n",
      "Iteration: 43000, Loss: -159.834289551\n",
      "Iteration: 43010, Loss: -159.721832275\n",
      "Iteration: 43020, Loss: -139.362823486\n",
      "Iteration: 43030, Loss: -149.072937012\n",
      "Iteration: 43040, Loss: -145.098419189\n",
      "Iteration: 43050, Loss: -159.943130493\n",
      "Iteration: 43060, Loss: -157.215759277\n",
      "Iteration: 43070, Loss: -157.255340576\n",
      "Iteration: 43080, Loss: -139.202697754\n",
      "Iteration: 43090, Loss: -147.078964233\n",
      "Iteration: 43100, Loss: -152.364654541\n",
      "Iteration: 43110, Loss: -149.647842407\n",
      "Iteration: 43120, Loss: -150.625061035\n",
      "Iteration: 43130, Loss: -147.806365967\n",
      "Iteration: 43140, Loss: -138.722686768\n",
      "Iteration: 43150, Loss: -145.463226318\n",
      "Iteration: 43160, Loss: -142.017944336\n",
      "Iteration: 43170, Loss: -152.701171875\n",
      "Iteration: 43180, Loss: -135.069519043\n",
      "Iteration: 43190, Loss: -170.217956543\n",
      "Iteration: 43200, Loss: -141.02822876\n",
      "Iteration: 43210, Loss: -144.939712524\n",
      "Iteration: 43220, Loss: -158.506118774\n",
      "Iteration: 43230, Loss: -143.089508057\n",
      "Iteration: 43240, Loss: -157.316680908\n",
      "Iteration: 43250, Loss: -142.891433716\n",
      "Iteration: 43260, Loss: -159.510284424\n",
      "Iteration: 43270, Loss: -143.091186523\n",
      "Iteration: 43280, Loss: -142.405853271\n",
      "Iteration: 43290, Loss: -138.910705566\n",
      "Iteration: 43300, Loss: -150.082275391\n",
      "Iteration: 43310, Loss: -154.40927124\n",
      "Iteration: 43320, Loss: -148.200164795\n",
      "Iteration: 43330, Loss: -147.28894043\n",
      "Iteration: 43340, Loss: -150.789520264\n",
      "Iteration: 43350, Loss: -169.172149658\n",
      "Iteration: 43360, Loss: -155.094177246\n",
      "Iteration: 43370, Loss: -154.522979736\n",
      "Iteration: 43380, Loss: -151.801147461\n",
      "Iteration: 43390, Loss: -149.575866699\n",
      "Iteration: 43400, Loss: -131.236526489\n",
      "Iteration: 43410, Loss: -147.826675415\n",
      "Iteration: 43420, Loss: -150.297790527\n",
      "Iteration: 43430, Loss: -150.271484375\n",
      "Iteration: 43440, Loss: -142.240570068\n",
      "Iteration: 43450, Loss: -146.030700684\n",
      "Iteration: 43460, Loss: -145.652145386\n",
      "Iteration: 43470, Loss: -135.479415894\n",
      "Iteration: 43480, Loss: -156.067520142\n",
      "Iteration: 43490, Loss: -143.345458984\n",
      "Iteration: 43500, Loss: -139.452941895\n",
      "Iteration: 43510, Loss: -136.085174561\n",
      "Iteration: 43520, Loss: -140.412139893\n",
      "Iteration: 43530, Loss: -155.368377686\n",
      "Iteration: 43540, Loss: -150.188232422\n",
      "Iteration: 43550, Loss: -151.120941162\n",
      "Iteration: 43560, Loss: -151.519073486\n",
      "Iteration: 43570, Loss: -154.799423218\n",
      "Iteration: 43580, Loss: -150.535812378\n",
      "Iteration: 43590, Loss: -159.620788574\n",
      "Iteration: 43600, Loss: -157.867156982\n",
      "Iteration: 43610, Loss: -144.662994385\n",
      "Iteration: 43620, Loss: -145.433044434\n",
      "Iteration: 43630, Loss: -139.428039551\n",
      "Iteration: 43640, Loss: -145.801696777\n",
      "Iteration: 43650, Loss: -152.729263306\n",
      "Iteration: 43660, Loss: -164.541992188\n",
      "Iteration: 43670, Loss: -156.346755981\n",
      "Iteration: 43680, Loss: -145.549819946\n",
      "Iteration: 43690, Loss: -137.206298828\n",
      "Iteration: 43700, Loss: -161.074508667\n",
      "Iteration: 43710, Loss: -158.68371582\n",
      "Iteration: 43720, Loss: -141.019195557\n",
      "Iteration: 43730, Loss: -165.183532715\n",
      "Iteration: 43740, Loss: -152.984405518\n",
      "Iteration: 43750, Loss: -144.83807373\n",
      "Iteration: 43760, Loss: -150.283508301\n",
      "Iteration: 43770, Loss: -139.32019043\n",
      "Iteration: 43780, Loss: -146.711196899\n",
      "Iteration: 43790, Loss: -147.839752197\n",
      "Iteration: 43800, Loss: -145.059127808\n",
      "Iteration: 43810, Loss: -157.273986816\n",
      "Iteration: 43820, Loss: -145.282028198\n",
      "Iteration: 43830, Loss: -136.259109497\n",
      "Iteration: 43840, Loss: -146.530639648\n",
      "Iteration: 43850, Loss: -146.540298462\n",
      "Iteration: 43860, Loss: -148.336242676\n",
      "Iteration: 43870, Loss: -132.732055664\n",
      "Iteration: 43880, Loss: -145.775177002\n",
      "Iteration: 43890, Loss: -162.305450439\n",
      "Iteration: 43900, Loss: -151.515258789\n",
      "Iteration: 43910, Loss: -147.259765625\n",
      "Iteration: 43920, Loss: -153.079101562\n",
      "Iteration: 43930, Loss: -141.438491821\n",
      "Iteration: 43940, Loss: -146.263793945\n",
      "Iteration: 43950, Loss: -141.27784729\n",
      "Iteration: 43960, Loss: -141.255065918\n",
      "Iteration: 43970, Loss: -154.868164062\n",
      "Iteration: 43980, Loss: -145.992889404\n",
      "Iteration: 43990, Loss: -140.289703369\n",
      "Iteration: 44000, Loss: -138.647094727\n",
      "Iteration: 44010, Loss: -140.185256958\n",
      "Iteration: 44020, Loss: -142.398864746\n",
      "Iteration: 44030, Loss: -152.419677734\n",
      "Iteration: 44040, Loss: -151.858551025\n",
      "Iteration: 44050, Loss: -158.496109009\n",
      "Iteration: 44060, Loss: -147.825164795\n",
      "Iteration: 44070, Loss: -142.540374756\n",
      "Iteration: 44080, Loss: -159.193252563\n",
      "Iteration: 44090, Loss: -159.910217285\n",
      "Iteration: 44100, Loss: -149.828369141\n",
      "Iteration: 44110, Loss: -151.273468018\n",
      "Iteration: 44120, Loss: -153.771759033\n",
      "Iteration: 44130, Loss: -147.606079102\n",
      "Iteration: 44140, Loss: -152.653182983\n",
      "Iteration: 44150, Loss: -146.375488281\n",
      "Iteration: 44160, Loss: -141.364807129\n",
      "Iteration: 44170, Loss: -156.129135132\n",
      "Iteration: 44180, Loss: -152.153213501\n",
      "Iteration: 44190, Loss: -136.905166626\n",
      "Iteration: 44200, Loss: -157.640106201\n",
      "Iteration: 44210, Loss: -161.783355713\n",
      "Iteration: 44220, Loss: -144.7003479\n",
      "Iteration: 44230, Loss: -142.481994629\n",
      "Iteration: 44240, Loss: -146.334686279\n",
      "Iteration: 44250, Loss: -151.792358398\n",
      "Iteration: 44260, Loss: -152.633071899\n",
      "Iteration: 44270, Loss: -154.602493286\n",
      "Iteration: 44280, Loss: -164.485031128\n",
      "Iteration: 44290, Loss: -149.056488037\n",
      "Iteration: 44300, Loss: -142.664031982\n",
      "Iteration: 44310, Loss: -160.178619385\n",
      "Iteration: 44320, Loss: -153.591949463\n",
      "Iteration: 44330, Loss: -150.514678955\n",
      "Iteration: 44340, Loss: -151.475204468\n",
      "Iteration: 44350, Loss: -151.921020508\n",
      "Iteration: 44360, Loss: -153.973983765\n",
      "Iteration: 44370, Loss: -150.903167725\n",
      "Iteration: 44380, Loss: -147.778839111\n",
      "Iteration: 44390, Loss: -158.138519287\n",
      "Iteration: 44400, Loss: -136.815582275\n",
      "Iteration: 44410, Loss: -154.598602295\n",
      "Iteration: 44420, Loss: -144.015930176\n",
      "Iteration: 44430, Loss: -151.837219238\n",
      "Iteration: 44440, Loss: -150.345733643\n",
      "Iteration: 44450, Loss: -123.473419189\n",
      "Iteration: 44460, Loss: -138.989593506\n",
      "Iteration: 44470, Loss: -160.500839233\n",
      "Iteration: 44480, Loss: -160.448196411\n",
      "Iteration: 44490, Loss: -145.753540039\n",
      "Iteration: 44500, Loss: -143.049560547\n",
      "Iteration: 44510, Loss: -159.579620361\n",
      "Iteration: 44520, Loss: -141.525344849\n",
      "Iteration: 44530, Loss: -153.661621094\n",
      "Iteration: 44540, Loss: -138.013214111\n",
      "Iteration: 44550, Loss: -151.753387451\n",
      "Iteration: 44560, Loss: -159.290740967\n",
      "Iteration: 44570, Loss: -153.788589478\n",
      "Iteration: 44580, Loss: -136.058837891\n",
      "Iteration: 44590, Loss: -147.95425415\n",
      "Iteration: 44600, Loss: -163.448059082\n",
      "Iteration: 44610, Loss: -147.648803711\n",
      "Iteration: 44620, Loss: -158.393249512\n",
      "Iteration: 44630, Loss: -158.204040527\n",
      "Iteration: 44640, Loss: -149.408050537\n",
      "Iteration: 44650, Loss: -144.951660156\n",
      "Iteration: 44660, Loss: -150.635848999\n",
      "Iteration: 44670, Loss: -150.629943848\n",
      "Iteration: 44680, Loss: -139.092681885\n",
      "Iteration: 44690, Loss: -155.265167236\n",
      "Iteration: 44700, Loss: -144.215591431\n",
      "Iteration: 44710, Loss: -138.11038208\n",
      "Iteration: 44720, Loss: -161.651885986\n",
      "Iteration: 44730, Loss: -151.281951904\n",
      "Iteration: 44740, Loss: -151.645889282\n",
      "Iteration: 44750, Loss: -147.734985352\n",
      "Iteration: 44760, Loss: -150.684539795\n",
      "Iteration: 44770, Loss: -148.416656494\n",
      "Iteration: 44780, Loss: -157.22064209\n",
      "Iteration: 44790, Loss: -137.854995728\n",
      "Iteration: 44800, Loss: -139.210021973\n",
      "Iteration: 44810, Loss: -133.296417236\n",
      "Iteration: 44820, Loss: -146.405944824\n",
      "Iteration: 44830, Loss: -153.022964478\n",
      "Iteration: 44840, Loss: -140.739257812\n",
      "Iteration: 44850, Loss: -141.944152832\n",
      "Iteration: 44860, Loss: -143.649078369\n",
      "Iteration: 44870, Loss: -148.351959229\n",
      "Iteration: 44880, Loss: -144.374603271\n",
      "Iteration: 44890, Loss: -149.898681641\n",
      "Iteration: 44900, Loss: -162.296691895\n",
      "Iteration: 44910, Loss: -163.164337158\n",
      "Iteration: 44920, Loss: -153.184265137\n",
      "Iteration: 44930, Loss: -146.181488037\n",
      "Iteration: 44940, Loss: -136.119476318\n",
      "Iteration: 44950, Loss: -156.798980713\n",
      "Iteration: 44960, Loss: -139.704040527\n",
      "Iteration: 44970, Loss: -153.571182251\n",
      "Iteration: 44980, Loss: -136.538848877\n",
      "Iteration: 44990, Loss: -152.960998535\n",
      "Iteration: 45000, Loss: -164.460174561\n",
      "Iteration: 45010, Loss: -135.641052246\n",
      "Iteration: 45020, Loss: -137.287872314\n",
      "Iteration: 45030, Loss: -133.096405029\n",
      "Iteration: 45040, Loss: -160.893569946\n",
      "Iteration: 45050, Loss: -157.588195801\n",
      "Iteration: 45060, Loss: -146.740386963\n",
      "Iteration: 45070, Loss: -155.740509033\n",
      "Iteration: 45080, Loss: -154.265640259\n",
      "Iteration: 45090, Loss: -143.557952881\n",
      "Iteration: 45100, Loss: -145.999206543\n",
      "Iteration: 45110, Loss: -160.93522644\n",
      "Iteration: 45120, Loss: -156.037200928\n",
      "Iteration: 45130, Loss: -138.960632324\n",
      "Iteration: 45140, Loss: -141.902282715\n",
      "Iteration: 45150, Loss: -157.908630371\n",
      "Iteration: 45160, Loss: -140.75189209\n",
      "Iteration: 45170, Loss: -143.281524658\n",
      "Iteration: 45180, Loss: -145.044311523\n",
      "Iteration: 45190, Loss: -154.995605469\n",
      "Iteration: 45200, Loss: -161.620178223\n",
      "Iteration: 45210, Loss: -148.466751099\n",
      "Iteration: 45220, Loss: -138.034484863\n",
      "Iteration: 45230, Loss: -146.980407715\n",
      "Iteration: 45240, Loss: -156.25201416\n",
      "Iteration: 45250, Loss: -150.487594604\n",
      "Iteration: 45260, Loss: -150.039733887\n",
      "Iteration: 45270, Loss: -152.977508545\n",
      "Iteration: 45280, Loss: -142.182281494\n",
      "Iteration: 45290, Loss: -150.155883789\n",
      "Iteration: 45300, Loss: -148.5756073\n",
      "Iteration: 45310, Loss: -126.156265259\n",
      "Iteration: 45320, Loss: -156.27456665\n",
      "Iteration: 45330, Loss: -147.200500488\n",
      "Iteration: 45340, Loss: -152.196685791\n",
      "Iteration: 45350, Loss: -144.900390625\n",
      "Iteration: 45360, Loss: -144.203399658\n",
      "Iteration: 45370, Loss: -124.572052002\n",
      "Iteration: 45380, Loss: -154.38494873\n",
      "Iteration: 45390, Loss: -155.177124023\n",
      "Iteration: 45400, Loss: -153.23600769\n",
      "Iteration: 45410, Loss: -148.692657471\n",
      "Iteration: 45420, Loss: -151.800674438\n",
      "Iteration: 45430, Loss: -137.323059082\n",
      "Iteration: 45440, Loss: -158.068359375\n",
      "Iteration: 45450, Loss: -156.767684937\n",
      "Iteration: 45460, Loss: -149.950805664\n",
      "Iteration: 45470, Loss: -134.095413208\n",
      "Iteration: 45480, Loss: -146.539031982\n",
      "Iteration: 45490, Loss: -153.674133301\n",
      "Iteration: 45500, Loss: -145.234741211\n",
      "Iteration: 45510, Loss: -159.722717285\n",
      "Iteration: 45520, Loss: -152.219360352\n",
      "Iteration: 45530, Loss: -150.888381958\n",
      "Iteration: 45540, Loss: -152.199111938\n",
      "Iteration: 45550, Loss: -143.426101685\n",
      "Iteration: 45560, Loss: -156.092819214\n",
      "Iteration: 45570, Loss: -139.19102478\n",
      "Iteration: 45580, Loss: -142.009918213\n",
      "Iteration: 45590, Loss: -141.46484375\n",
      "Iteration: 45600, Loss: -148.956497192\n",
      "Iteration: 45610, Loss: -141.207672119\n",
      "Iteration: 45620, Loss: -154.610916138\n",
      "Iteration: 45630, Loss: -151.538116455\n",
      "Iteration: 45640, Loss: -150.962966919\n",
      "Iteration: 45650, Loss: -150.841156006\n",
      "Iteration: 45660, Loss: -136.231689453\n",
      "Iteration: 45670, Loss: -150.494781494\n",
      "Iteration: 45680, Loss: -140.026702881\n",
      "Iteration: 45690, Loss: -153.402709961\n",
      "Iteration: 45700, Loss: -151.895599365\n",
      "Iteration: 45710, Loss: -145.555786133\n",
      "Iteration: 45720, Loss: -149.97467041\n",
      "Iteration: 45730, Loss: -145.083969116\n",
      "Iteration: 45740, Loss: -142.12461853\n",
      "Iteration: 45750, Loss: -142.364639282\n",
      "Iteration: 45760, Loss: -148.923782349\n",
      "Iteration: 45770, Loss: -140.994232178\n",
      "Iteration: 45780, Loss: -155.583984375\n",
      "Iteration: 45790, Loss: -141.399307251\n",
      "Iteration: 45800, Loss: -145.625335693\n",
      "Iteration: 45810, Loss: -166.847442627\n",
      "Iteration: 45820, Loss: -149.306564331\n",
      "Iteration: 45830, Loss: -145.579193115\n",
      "Iteration: 45840, Loss: -162.701599121\n",
      "Iteration: 45850, Loss: -162.078765869\n",
      "Iteration: 45860, Loss: -140.382217407\n",
      "Iteration: 45870, Loss: -143.063751221\n",
      "Iteration: 45880, Loss: -129.61114502\n",
      "Iteration: 45890, Loss: -139.710494995\n",
      "Iteration: 45900, Loss: -141.575714111\n",
      "Iteration: 45910, Loss: -155.36618042\n",
      "Iteration: 45920, Loss: -144.641296387\n",
      "Iteration: 45930, Loss: -141.290390015\n",
      "Iteration: 45940, Loss: -137.879821777\n",
      "Iteration: 45950, Loss: -137.665664673\n",
      "Iteration: 45960, Loss: -134.727264404\n",
      "Iteration: 45970, Loss: -138.964569092\n",
      "Iteration: 45980, Loss: -140.2840271\n",
      "Iteration: 45990, Loss: -136.551055908\n",
      "Iteration: 46000, Loss: -134.234161377\n",
      "Iteration: 46010, Loss: -158.749298096\n",
      "Iteration: 46020, Loss: -152.042129517\n",
      "Iteration: 46030, Loss: -146.389312744\n",
      "Iteration: 46040, Loss: -143.139175415\n",
      "Iteration: 46050, Loss: -147.690948486\n",
      "Iteration: 46060, Loss: -142.634918213\n",
      "Iteration: 46070, Loss: -135.471725464\n",
      "Iteration: 46080, Loss: -140.099075317\n",
      "Iteration: 46090, Loss: -154.539001465\n",
      "Iteration: 46100, Loss: -143.6224823\n",
      "Iteration: 46110, Loss: -164.949676514\n",
      "Iteration: 46120, Loss: -129.158096313\n",
      "Iteration: 46130, Loss: -149.917526245\n",
      "Iteration: 46140, Loss: -153.483886719\n",
      "Iteration: 46150, Loss: -133.564605713\n",
      "Iteration: 46160, Loss: -153.494674683\n",
      "Iteration: 46170, Loss: -161.796264648\n",
      "Iteration: 46180, Loss: -138.530212402\n",
      "Iteration: 46190, Loss: -156.249557495\n",
      "Iteration: 46200, Loss: -141.632507324\n",
      "Iteration: 46210, Loss: -147.469924927\n",
      "Iteration: 46220, Loss: -148.188980103\n",
      "Iteration: 46230, Loss: -140.008132935\n",
      "Iteration: 46240, Loss: -140.699920654\n",
      "Iteration: 46250, Loss: -139.465179443\n",
      "Iteration: 46260, Loss: -153.670150757\n",
      "Iteration: 46270, Loss: -143.286422729\n",
      "Iteration: 46280, Loss: -159.016265869\n",
      "Iteration: 46290, Loss: -144.18951416\n",
      "Iteration: 46300, Loss: -146.181976318\n",
      "Iteration: 46310, Loss: -149.36807251\n",
      "Iteration: 46320, Loss: -172.632675171\n",
      "Iteration: 46330, Loss: -178.254180908\n",
      "Iteration: 46340, Loss: -161.678497314\n",
      "Iteration: 46350, Loss: -148.439361572\n",
      "Iteration: 46360, Loss: -152.255264282\n",
      "Iteration: 46370, Loss: -147.102111816\n",
      "Iteration: 46380, Loss: -152.678909302\n",
      "Iteration: 46390, Loss: -145.79548645\n",
      "Iteration: 46400, Loss: -150.195404053\n",
      "Iteration: 46410, Loss: -143.199127197\n",
      "Iteration: 46420, Loss: -145.83833313\n",
      "Iteration: 46430, Loss: -146.331466675\n",
      "Iteration: 46440, Loss: -140.372680664\n",
      "Iteration: 46450, Loss: -150.005737305\n",
      "Iteration: 46460, Loss: -135.335784912\n",
      "Iteration: 46470, Loss: -136.967559814\n",
      "Iteration: 46480, Loss: -151.1043396\n",
      "Iteration: 46490, Loss: -157.244171143\n",
      "Iteration: 46500, Loss: -156.951522827\n",
      "Iteration: 46510, Loss: -146.451431274\n",
      "Iteration: 46520, Loss: -155.228393555\n",
      "Iteration: 46530, Loss: -148.267791748\n",
      "Iteration: 46540, Loss: -141.551239014\n",
      "Iteration: 46550, Loss: -138.469421387\n",
      "Iteration: 46560, Loss: -155.837234497\n",
      "Iteration: 46570, Loss: -150.071044922\n",
      "Iteration: 46580, Loss: -157.035247803\n",
      "Iteration: 46590, Loss: -147.466674805\n",
      "Iteration: 46600, Loss: -153.937774658\n",
      "Iteration: 46610, Loss: -154.696548462\n",
      "Iteration: 46620, Loss: -159.764160156\n",
      "Iteration: 46630, Loss: -153.693634033\n",
      "Iteration: 46640, Loss: -145.916809082\n",
      "Iteration: 46650, Loss: -158.568283081\n",
      "Iteration: 46660, Loss: -159.281616211\n",
      "Iteration: 46670, Loss: -159.041503906\n",
      "Iteration: 46680, Loss: -146.262313843\n",
      "Iteration: 46690, Loss: -136.002075195\n",
      "Iteration: 46700, Loss: -155.678863525\n",
      "Iteration: 46710, Loss: -144.863586426\n",
      "Iteration: 46720, Loss: -151.858535767\n",
      "Iteration: 46730, Loss: -151.711730957\n",
      "Iteration: 46740, Loss: -139.16847229\n",
      "Iteration: 46750, Loss: -160.921905518\n",
      "Iteration: 46760, Loss: -160.23487854\n",
      "Iteration: 46770, Loss: -150.432617188\n",
      "Iteration: 46780, Loss: -153.054718018\n",
      "Iteration: 46790, Loss: -134.574981689\n",
      "Iteration: 46800, Loss: -141.257644653\n",
      "Iteration: 46810, Loss: -145.817901611\n",
      "Iteration: 46820, Loss: -155.67074585\n",
      "Iteration: 46830, Loss: -155.048309326\n",
      "Iteration: 46840, Loss: -150.407501221\n",
      "Iteration: 46850, Loss: -156.243011475\n",
      "Iteration: 46860, Loss: -155.974273682\n",
      "Iteration: 46870, Loss: -123.72631073\n",
      "Iteration: 46880, Loss: -128.968078613\n",
      "Iteration: 46890, Loss: -148.486175537\n",
      "Iteration: 46900, Loss: -153.615753174\n",
      "Iteration: 46910, Loss: -146.404296875\n",
      "Iteration: 46920, Loss: -152.313491821\n",
      "Iteration: 46930, Loss: -136.298461914\n",
      "Iteration: 46940, Loss: -149.56439209\n",
      "Iteration: 46950, Loss: -153.532272339\n",
      "Iteration: 46960, Loss: -140.1587677\n",
      "Iteration: 46970, Loss: -150.127365112\n",
      "Iteration: 46980, Loss: -157.497711182\n",
      "Iteration: 46990, Loss: -164.802764893\n",
      "Iteration: 47000, Loss: -133.173980713\n",
      "Iteration: 47010, Loss: -145.943389893\n",
      "Iteration: 47020, Loss: -151.794219971\n",
      "Iteration: 47030, Loss: -142.32699585\n",
      "Iteration: 47040, Loss: -144.369033813\n",
      "Iteration: 47050, Loss: -134.483520508\n",
      "Iteration: 47060, Loss: -161.766693115\n",
      "Iteration: 47070, Loss: -149.213989258\n",
      "Iteration: 47080, Loss: -149.910705566\n",
      "Iteration: 47090, Loss: -150.197463989\n",
      "Iteration: 47100, Loss: -162.068145752\n",
      "Iteration: 47110, Loss: -136.93913269\n",
      "Iteration: 47120, Loss: -146.297912598\n",
      "Iteration: 47130, Loss: -143.299560547\n",
      "Iteration: 47140, Loss: -156.331634521\n",
      "Iteration: 47150, Loss: -165.119766235\n",
      "Iteration: 47160, Loss: -141.398345947\n",
      "Iteration: 47170, Loss: -159.686248779\n",
      "Iteration: 47180, Loss: -144.356262207\n",
      "Iteration: 47190, Loss: -143.564239502\n",
      "Iteration: 47200, Loss: -143.865142822\n",
      "Iteration: 47210, Loss: -147.25970459\n",
      "Iteration: 47220, Loss: -151.420852661\n",
      "Iteration: 47230, Loss: -143.4740448\n",
      "Iteration: 47240, Loss: -150.046600342\n",
      "Iteration: 47250, Loss: -135.030700684\n",
      "Iteration: 47260, Loss: -141.172546387\n",
      "Iteration: 47270, Loss: -150.597595215\n",
      "Iteration: 47280, Loss: -146.451629639\n",
      "Iteration: 47290, Loss: -148.662796021\n",
      "Iteration: 47300, Loss: -154.454788208\n",
      "Iteration: 47310, Loss: -148.004013062\n",
      "Iteration: 47320, Loss: -147.49105835\n",
      "Iteration: 47330, Loss: -154.479736328\n",
      "Iteration: 47340, Loss: -160.313934326\n",
      "Iteration: 47350, Loss: -140.004547119\n",
      "Iteration: 47360, Loss: -150.166229248\n",
      "Iteration: 47370, Loss: -153.810852051\n",
      "Iteration: 47380, Loss: -138.534637451\n",
      "Iteration: 47390, Loss: -159.752868652\n",
      "Iteration: 47400, Loss: -143.037017822\n",
      "Iteration: 47410, Loss: -148.651245117\n",
      "Iteration: 47420, Loss: -154.666671753\n",
      "Iteration: 47430, Loss: -150.12940979\n",
      "Iteration: 47440, Loss: -158.473083496\n",
      "Iteration: 47450, Loss: -134.14642334\n",
      "Iteration: 47460, Loss: -156.551422119\n",
      "Iteration: 47470, Loss: -148.114959717\n",
      "Iteration: 47480, Loss: -154.952423096\n",
      "Iteration: 47490, Loss: -146.587127686\n",
      "Iteration: 47500, Loss: -148.399459839\n",
      "Iteration: 47510, Loss: -147.221466064\n",
      "Iteration: 47520, Loss: -154.653442383\n",
      "Iteration: 47530, Loss: -147.234344482\n",
      "Iteration: 47540, Loss: -143.369277954\n",
      "Iteration: 47550, Loss: -164.226318359\n",
      "Iteration: 47560, Loss: -143.760467529\n",
      "Iteration: 47570, Loss: -147.253845215\n",
      "Iteration: 47580, Loss: -144.85395813\n",
      "Iteration: 47590, Loss: -136.628814697\n",
      "Iteration: 47600, Loss: -140.687255859\n",
      "Iteration: 47610, Loss: -128.580673218\n",
      "Iteration: 47620, Loss: -146.115386963\n",
      "Iteration: 47630, Loss: -146.72064209\n",
      "Iteration: 47640, Loss: -145.439697266\n",
      "Iteration: 47650, Loss: -136.362976074\n",
      "Iteration: 47660, Loss: -139.378723145\n",
      "Iteration: 47670, Loss: -165.187072754\n",
      "Iteration: 47680, Loss: -140.533538818\n",
      "Iteration: 47690, Loss: -155.871871948\n",
      "Iteration: 47700, Loss: -158.40145874\n",
      "Iteration: 47710, Loss: -147.701019287\n",
      "Iteration: 47720, Loss: -158.027099609\n",
      "Iteration: 47730, Loss: -151.493927002\n",
      "Iteration: 47740, Loss: -150.54498291\n",
      "Iteration: 47750, Loss: -131.912231445\n",
      "Iteration: 47760, Loss: -153.695785522\n",
      "Iteration: 47770, Loss: -144.492858887\n",
      "Iteration: 47780, Loss: -149.627441406\n",
      "Iteration: 47790, Loss: -158.494308472\n",
      "Iteration: 47800, Loss: -148.615539551\n",
      "Iteration: 47810, Loss: -154.66595459\n",
      "Iteration: 47820, Loss: -133.098922729\n",
      "Iteration: 47830, Loss: -129.095947266\n",
      "Iteration: 47840, Loss: -134.487228394\n",
      "Iteration: 47850, Loss: -139.434936523\n",
      "Iteration: 47860, Loss: -148.725097656\n",
      "Iteration: 47870, Loss: -148.436767578\n",
      "Iteration: 47880, Loss: -150.239471436\n",
      "Iteration: 47890, Loss: -149.38470459\n",
      "Iteration: 47900, Loss: -144.909851074\n",
      "Iteration: 47910, Loss: -142.202377319\n",
      "Iteration: 47920, Loss: -130.213684082\n",
      "Iteration: 47930, Loss: -139.405700684\n",
      "Iteration: 47940, Loss: -148.418670654\n",
      "Iteration: 47950, Loss: -144.164413452\n",
      "Iteration: 47960, Loss: -148.111480713\n",
      "Iteration: 47970, Loss: -154.782577515\n",
      "Iteration: 47980, Loss: -135.672821045\n",
      "Iteration: 47990, Loss: -144.14163208\n",
      "Iteration: 48000, Loss: -143.129959106\n",
      "Iteration: 48010, Loss: -136.204528809\n",
      "Iteration: 48020, Loss: -135.251068115\n",
      "Iteration: 48030, Loss: -153.855041504\n",
      "Iteration: 48040, Loss: -160.53288269\n",
      "Iteration: 48050, Loss: -150.995422363\n",
      "Iteration: 48060, Loss: -135.657958984\n",
      "Iteration: 48070, Loss: -149.413208008\n",
      "Iteration: 48080, Loss: -147.111297607\n",
      "Iteration: 48090, Loss: -144.447540283\n",
      "Iteration: 48100, Loss: -150.52734375\n",
      "Iteration: 48110, Loss: -168.459823608\n",
      "Iteration: 48120, Loss: -152.341415405\n",
      "Iteration: 48130, Loss: -149.285980225\n",
      "Iteration: 48140, Loss: -144.280075073\n",
      "Iteration: 48150, Loss: -142.693603516\n",
      "Iteration: 48160, Loss: -144.364501953\n",
      "Iteration: 48170, Loss: -141.277954102\n",
      "Iteration: 48180, Loss: -148.685882568\n",
      "Iteration: 48190, Loss: -148.149749756\n",
      "Iteration: 48200, Loss: -152.858795166\n",
      "Iteration: 48210, Loss: -142.439529419\n",
      "Iteration: 48220, Loss: -140.550643921\n",
      "Iteration: 48230, Loss: -135.73928833\n",
      "Iteration: 48240, Loss: -132.874359131\n",
      "Iteration: 48250, Loss: -151.058578491\n",
      "Iteration: 48260, Loss: -134.117675781\n",
      "Iteration: 48270, Loss: -164.836395264\n",
      "Iteration: 48280, Loss: -150.02331543\n",
      "Iteration: 48290, Loss: -150.441604614\n",
      "Iteration: 48300, Loss: -149.555389404\n",
      "Iteration: 48310, Loss: -132.973266602\n",
      "Iteration: 48320, Loss: -129.034118652\n",
      "Iteration: 48330, Loss: -158.1824646\n",
      "Iteration: 48340, Loss: -163.725448608\n",
      "Iteration: 48350, Loss: -158.85710144\n",
      "Iteration: 48360, Loss: -150.851745605\n",
      "Iteration: 48370, Loss: -137.869354248\n",
      "Iteration: 48380, Loss: -138.925445557\n",
      "Iteration: 48390, Loss: -150.43548584\n",
      "Iteration: 48400, Loss: -161.007080078\n",
      "Iteration: 48410, Loss: -144.744689941\n",
      "Iteration: 48420, Loss: -155.289489746\n",
      "Iteration: 48430, Loss: -159.9269104\n",
      "Iteration: 48440, Loss: -143.703674316\n",
      "Iteration: 48450, Loss: -142.212249756\n",
      "Iteration: 48460, Loss: -133.408721924\n",
      "Iteration: 48470, Loss: -143.792510986\n",
      "Iteration: 48480, Loss: -146.829452515\n",
      "Iteration: 48490, Loss: -138.165893555\n",
      "Iteration: 48500, Loss: -154.778289795\n",
      "Iteration: 48510, Loss: -161.095825195\n",
      "Iteration: 48520, Loss: -134.866149902\n",
      "Iteration: 48530, Loss: -144.799514771\n",
      "Iteration: 48540, Loss: -157.430999756\n",
      "Iteration: 48550, Loss: -142.011322021\n",
      "Iteration: 48560, Loss: -147.012542725\n",
      "Iteration: 48570, Loss: -141.835113525\n",
      "Iteration: 48580, Loss: -158.097625732\n",
      "Iteration: 48590, Loss: -163.395217896\n",
      "Iteration: 48600, Loss: -139.609146118\n",
      "Iteration: 48610, Loss: -134.378433228\n",
      "Iteration: 48620, Loss: -143.595123291\n",
      "Iteration: 48630, Loss: -136.241928101\n",
      "Iteration: 48640, Loss: -145.178482056\n",
      "Iteration: 48650, Loss: -152.507232666\n",
      "Iteration: 48660, Loss: -147.090591431\n",
      "Iteration: 48670, Loss: -144.32194519\n",
      "Iteration: 48680, Loss: -159.469299316\n",
      "Iteration: 48690, Loss: -129.617767334\n",
      "Iteration: 48700, Loss: -144.884338379\n",
      "Iteration: 48710, Loss: -143.371673584\n",
      "Iteration: 48720, Loss: -145.582366943\n",
      "Iteration: 48730, Loss: -162.220550537\n",
      "Iteration: 48740, Loss: -149.33921814\n",
      "Iteration: 48750, Loss: -128.033874512\n",
      "Iteration: 48760, Loss: -153.825759888\n",
      "Iteration: 48770, Loss: -140.291183472\n",
      "Iteration: 48780, Loss: -150.50012207\n",
      "Iteration: 48790, Loss: -153.533706665\n",
      "Iteration: 48800, Loss: -139.435287476\n",
      "Iteration: 48810, Loss: -146.522201538\n",
      "Iteration: 48820, Loss: -147.90045166\n",
      "Iteration: 48830, Loss: -157.885314941\n",
      "Iteration: 48840, Loss: -155.564056396\n",
      "Iteration: 48850, Loss: -141.634033203\n",
      "Iteration: 48860, Loss: -145.75227356\n",
      "Iteration: 48870, Loss: -129.714263916\n",
      "Iteration: 48880, Loss: -151.528030396\n",
      "Iteration: 48890, Loss: -131.784500122\n",
      "Iteration: 48900, Loss: -154.361434937\n",
      "Iteration: 48910, Loss: -139.79107666\n",
      "Iteration: 48920, Loss: -150.403289795\n",
      "Iteration: 48930, Loss: -143.968048096\n",
      "Iteration: 48940, Loss: -127.649337769\n",
      "Iteration: 48950, Loss: -157.984161377\n",
      "Iteration: 48960, Loss: -144.619522095\n",
      "Iteration: 48970, Loss: -146.558929443\n",
      "Iteration: 48980, Loss: -149.673095703\n",
      "Iteration: 48990, Loss: -138.545166016\n",
      "Iteration: 49000, Loss: -140.994155884\n",
      "Iteration: 49010, Loss: -150.95425415\n",
      "Iteration: 49020, Loss: -151.906082153\n",
      "Iteration: 49030, Loss: -133.790039062\n",
      "Iteration: 49040, Loss: -140.694793701\n",
      "Iteration: 49050, Loss: -143.34274292\n",
      "Iteration: 49060, Loss: -143.848678589\n",
      "Iteration: 49070, Loss: -155.360168457\n",
      "Iteration: 49080, Loss: -137.519073486\n",
      "Iteration: 49090, Loss: -151.188156128\n",
      "Iteration: 49100, Loss: -149.581985474\n",
      "Iteration: 49110, Loss: -149.873260498\n",
      "Iteration: 49120, Loss: -142.334060669\n",
      "Iteration: 49130, Loss: -142.048919678\n",
      "Iteration: 49140, Loss: -140.34375\n",
      "Iteration: 49150, Loss: -149.126861572\n",
      "Iteration: 49160, Loss: -154.023406982\n",
      "Iteration: 49170, Loss: -148.228759766\n",
      "Iteration: 49180, Loss: -146.075973511\n",
      "Iteration: 49190, Loss: -145.66696167\n",
      "Iteration: 49200, Loss: -151.257385254\n",
      "Iteration: 49210, Loss: -144.521575928\n",
      "Iteration: 49220, Loss: -137.660400391\n",
      "Iteration: 49230, Loss: -158.50743103\n",
      "Iteration: 49240, Loss: -141.75189209\n",
      "Iteration: 49250, Loss: -156.166931152\n",
      "Iteration: 49260, Loss: -144.790328979\n",
      "Iteration: 49270, Loss: -155.476745605\n",
      "Iteration: 49280, Loss: -144.913360596\n",
      "Iteration: 49290, Loss: -154.072525024\n",
      "Iteration: 49300, Loss: -155.902008057\n",
      "Iteration: 49310, Loss: -146.343933105\n",
      "Iteration: 49320, Loss: -152.454681396\n",
      "Iteration: 49330, Loss: -145.267272949\n",
      "Iteration: 49340, Loss: -148.697265625\n",
      "Iteration: 49350, Loss: -145.586227417\n",
      "Iteration: 49360, Loss: -147.556045532\n",
      "Iteration: 49370, Loss: -135.843215942\n",
      "Iteration: 49380, Loss: -145.495513916\n",
      "Iteration: 49390, Loss: -137.898681641\n",
      "Iteration: 49400, Loss: -144.16519165\n",
      "Iteration: 49410, Loss: -142.860656738\n",
      "Iteration: 49420, Loss: -135.853973389\n",
      "Iteration: 49430, Loss: -158.511138916\n",
      "Iteration: 49440, Loss: -151.865005493\n",
      "Iteration: 49450, Loss: -175.398452759\n",
      "Iteration: 49460, Loss: -140.217254639\n",
      "Iteration: 49470, Loss: -150.126861572\n",
      "Iteration: 49480, Loss: -152.299560547\n",
      "Iteration: 49490, Loss: -147.499847412\n",
      "Iteration: 49500, Loss: -145.280609131\n",
      "Iteration: 49510, Loss: -151.613143921\n",
      "Iteration: 49520, Loss: -145.066589355\n",
      "Iteration: 49530, Loss: -160.481658936\n",
      "Iteration: 49540, Loss: -155.311920166\n",
      "Iteration: 49550, Loss: -144.707611084\n",
      "Iteration: 49560, Loss: -151.566879272\n",
      "Iteration: 49570, Loss: -145.886077881\n",
      "Iteration: 49580, Loss: -147.349853516\n",
      "Iteration: 49590, Loss: -138.475799561\n",
      "Iteration: 49600, Loss: -144.237579346\n",
      "Iteration: 49610, Loss: -155.909637451\n",
      "Iteration: 49620, Loss: -149.065582275\n",
      "Iteration: 49630, Loss: -143.13760376\n",
      "Iteration: 49640, Loss: -146.076751709\n",
      "Iteration: 49650, Loss: -154.899383545\n",
      "Iteration: 49660, Loss: -148.900909424\n",
      "Iteration: 49670, Loss: -154.521514893\n",
      "Iteration: 49680, Loss: -136.989532471\n",
      "Iteration: 49690, Loss: -137.397537231\n",
      "Iteration: 49700, Loss: -138.235870361\n",
      "Iteration: 49710, Loss: -137.428527832\n",
      "Iteration: 49720, Loss: -139.596755981\n",
      "Iteration: 49730, Loss: -144.106796265\n",
      "Iteration: 49740, Loss: -138.418426514\n",
      "Iteration: 49750, Loss: -142.326812744\n",
      "Iteration: 49760, Loss: -153.136932373\n",
      "Iteration: 49770, Loss: -131.239746094\n",
      "Iteration: 49780, Loss: -158.05619812\n",
      "Iteration: 49790, Loss: -139.370452881\n",
      "Iteration: 49800, Loss: -143.73135376\n",
      "Iteration: 49810, Loss: -158.765869141\n",
      "Iteration: 49820, Loss: -148.957122803\n",
      "Iteration: 49830, Loss: -146.706253052\n",
      "Iteration: 49840, Loss: -146.643600464\n",
      "Iteration: 49850, Loss: -155.707641602\n",
      "Iteration: 49860, Loss: -161.338104248\n",
      "Iteration: 49870, Loss: -139.26751709\n",
      "Iteration: 49880, Loss: -149.566238403\n",
      "Iteration: 49890, Loss: -132.492340088\n",
      "Iteration: 49900, Loss: -143.882019043\n",
      "Iteration: 49910, Loss: -145.225463867\n",
      "Iteration: 49920, Loss: -143.750030518\n",
      "Iteration: 49930, Loss: -157.637542725\n",
      "Iteration: 49940, Loss: -146.307662964\n",
      "Iteration: 49950, Loss: -147.74899292\n",
      "Iteration: 49960, Loss: -147.057662964\n",
      "Iteration: 49970, Loss: -143.234924316\n",
      "Iteration: 49980, Loss: -133.103210449\n",
      "Iteration: 49990, Loss: -148.777816772\n",
      "Iteration: 50000, Loss: -143.624572754\n",
      "Iteration: 50010, Loss: -146.844818115\n",
      "Iteration: 50020, Loss: -149.276092529\n",
      "Iteration: 50030, Loss: -136.420532227\n",
      "Iteration: 50040, Loss: -154.232086182\n",
      "Iteration: 50050, Loss: -138.016326904\n",
      "Iteration: 50060, Loss: -144.364562988\n",
      "Iteration: 50070, Loss: -137.213806152\n",
      "Iteration: 50080, Loss: -158.630004883\n",
      "Iteration: 50090, Loss: -155.060348511\n",
      "Iteration: 50100, Loss: -143.959869385\n",
      "Iteration: 50110, Loss: -150.508300781\n",
      "Iteration: 50120, Loss: -149.473129272\n",
      "Iteration: 50130, Loss: -151.302581787\n",
      "Iteration: 50140, Loss: -132.404815674\n",
      "Iteration: 50150, Loss: -127.534202576\n",
      "Iteration: 50160, Loss: -152.458770752\n",
      "Iteration: 50170, Loss: -151.210266113\n",
      "Iteration: 50180, Loss: -145.269104004\n",
      "Iteration: 50190, Loss: -154.732284546\n",
      "Iteration: 50200, Loss: -131.968215942\n",
      "Iteration: 50210, Loss: -146.844528198\n",
      "Iteration: 50220, Loss: -143.207901001\n",
      "Iteration: 50230, Loss: -153.191864014\n",
      "Iteration: 50240, Loss: -148.230789185\n",
      "Iteration: 50250, Loss: -156.181610107\n",
      "Iteration: 50260, Loss: -147.851654053\n",
      "Iteration: 50270, Loss: -137.320861816\n",
      "Iteration: 50280, Loss: -145.392883301\n",
      "Iteration: 50290, Loss: -137.968566895\n",
      "Iteration: 50300, Loss: -132.514358521\n",
      "Iteration: 50310, Loss: -137.631500244\n",
      "Iteration: 50320, Loss: -141.112365723\n",
      "Iteration: 50330, Loss: -153.998718262\n",
      "Iteration: 50340, Loss: -142.564239502\n",
      "Iteration: 50350, Loss: -153.887405396\n",
      "Iteration: 50360, Loss: -143.389190674\n",
      "Iteration: 50370, Loss: -142.856079102\n",
      "Iteration: 50380, Loss: -148.210876465\n",
      "Iteration: 50390, Loss: -157.827331543\n",
      "Iteration: 50400, Loss: -164.85345459\n",
      "Iteration: 50410, Loss: -140.918395996\n",
      "Iteration: 50420, Loss: -142.71661377\n",
      "Iteration: 50430, Loss: -144.021606445\n",
      "Iteration: 50440, Loss: -155.541854858\n",
      "Iteration: 50450, Loss: -138.99647522\n",
      "Iteration: 50460, Loss: -141.615859985\n",
      "Iteration: 50470, Loss: -142.954071045\n",
      "Iteration: 50480, Loss: -142.992248535\n",
      "Iteration: 50490, Loss: -138.626190186\n",
      "Iteration: 50500, Loss: -145.803726196\n",
      "Iteration: 50510, Loss: -148.688522339\n",
      "Iteration: 50520, Loss: -138.056808472\n",
      "Iteration: 50530, Loss: -137.958084106\n",
      "Iteration: 50540, Loss: -135.440582275\n",
      "Iteration: 50550, Loss: -136.002319336\n",
      "Iteration: 50560, Loss: -156.941864014\n",
      "Iteration: 50570, Loss: -153.50642395\n",
      "Iteration: 50580, Loss: -145.056427002\n",
      "Iteration: 50590, Loss: -155.381332397\n",
      "Iteration: 50600, Loss: -136.631729126\n",
      "Iteration: 50610, Loss: -137.336395264\n",
      "Iteration: 50620, Loss: -151.836456299\n",
      "Iteration: 50630, Loss: -156.191986084\n",
      "Iteration: 50640, Loss: -142.386993408\n",
      "Iteration: 50650, Loss: -136.786422729\n",
      "Iteration: 50660, Loss: -144.722198486\n",
      "Iteration: 50670, Loss: -143.709686279\n",
      "Iteration: 50680, Loss: -151.192626953\n",
      "Iteration: 50690, Loss: -144.464111328\n",
      "Iteration: 50700, Loss: -142.261154175\n",
      "Iteration: 50710, Loss: -136.840957642\n",
      "Iteration: 50720, Loss: -145.868286133\n",
      "Iteration: 50730, Loss: -148.415283203\n",
      "Iteration: 50740, Loss: -147.10244751\n",
      "Iteration: 50750, Loss: -148.005340576\n",
      "Iteration: 50760, Loss: -163.61428833\n",
      "Iteration: 50770, Loss: -155.931381226\n",
      "Iteration: 50780, Loss: -129.550704956\n",
      "Iteration: 50790, Loss: -149.410690308\n",
      "Iteration: 50800, Loss: -140.84375\n",
      "Iteration: 50810, Loss: -151.644302368\n",
      "Iteration: 50820, Loss: -163.911895752\n",
      "Iteration: 50830, Loss: -153.475906372\n",
      "Iteration: 50840, Loss: -140.212554932\n",
      "Iteration: 50850, Loss: -151.378082275\n",
      "Iteration: 50860, Loss: -138.596923828\n",
      "Iteration: 50870, Loss: -141.571151733\n",
      "Iteration: 50880, Loss: -131.683166504\n",
      "Iteration: 50890, Loss: -168.882003784\n",
      "Iteration: 50900, Loss: -152.136825562\n",
      "Iteration: 50910, Loss: -140.578491211\n",
      "Iteration: 50920, Loss: -158.470169067\n",
      "Iteration: 50930, Loss: -140.779174805\n",
      "Iteration: 50940, Loss: -136.196624756\n",
      "Iteration: 50950, Loss: -149.647521973\n",
      "Iteration: 50960, Loss: -145.91506958\n",
      "Iteration: 50970, Loss: -130.530609131\n",
      "Iteration: 50980, Loss: -158.195495605\n",
      "Iteration: 50990, Loss: -164.85105896\n",
      "Iteration: 51000, Loss: -150.925857544\n",
      "Iteration: 51010, Loss: -155.674957275\n",
      "Iteration: 51020, Loss: -147.52003479\n",
      "Iteration: 51030, Loss: -146.3175354\n",
      "Iteration: 51040, Loss: -141.727645874\n",
      "Iteration: 51050, Loss: -149.330551147\n",
      "Iteration: 51060, Loss: -140.574813843\n",
      "Iteration: 51070, Loss: -131.102920532\n",
      "Iteration: 51080, Loss: -149.759307861\n",
      "Iteration: 51090, Loss: -168.290374756\n",
      "Iteration: 51100, Loss: -163.1300354\n",
      "Iteration: 51110, Loss: -146.712722778\n",
      "Iteration: 51120, Loss: -142.582794189\n",
      "Iteration: 51130, Loss: -142.480484009\n",
      "Iteration: 51140, Loss: -152.219772339\n",
      "Iteration: 51150, Loss: -145.453231812\n",
      "Iteration: 51160, Loss: -141.209701538\n",
      "Iteration: 51170, Loss: -135.14994812\n",
      "Iteration: 51180, Loss: -145.724273682\n",
      "Iteration: 51190, Loss: -156.561477661\n",
      "Iteration: 51200, Loss: -130.109970093\n",
      "Iteration: 51210, Loss: -153.417724609\n",
      "Iteration: 51220, Loss: -139.621231079\n",
      "Iteration: 51230, Loss: -138.362182617\n",
      "Iteration: 51240, Loss: -153.346633911\n",
      "Iteration: 51250, Loss: -140.539916992\n",
      "Iteration: 51260, Loss: -135.737670898\n",
      "Iteration: 51270, Loss: -150.7940979\n",
      "Iteration: 51280, Loss: -135.421936035\n",
      "Iteration: 51290, Loss: -157.563110352\n",
      "Iteration: 51300, Loss: -144.605957031\n",
      "Iteration: 51310, Loss: -141.135498047\n",
      "Iteration: 51320, Loss: -147.907943726\n",
      "Iteration: 51330, Loss: -136.837463379\n",
      "Iteration: 51340, Loss: -135.139556885\n",
      "Iteration: 51350, Loss: -131.838348389\n",
      "Iteration: 51360, Loss: -145.100158691\n",
      "Iteration: 51370, Loss: -144.311355591\n",
      "Iteration: 51380, Loss: -140.632522583\n",
      "Iteration: 51390, Loss: -141.168258667\n",
      "Iteration: 51400, Loss: -152.186645508\n",
      "Iteration: 51410, Loss: -145.946609497\n",
      "Iteration: 51420, Loss: -141.617828369\n",
      "Iteration: 51430, Loss: -143.773742676\n",
      "Iteration: 51440, Loss: -133.800964355\n",
      "Iteration: 51450, Loss: -158.830001831\n",
      "Iteration: 51460, Loss: -145.985107422\n",
      "Iteration: 51470, Loss: -144.665588379\n",
      "Iteration: 51480, Loss: -139.606842041\n",
      "Iteration: 51490, Loss: -138.720184326\n",
      "Iteration: 51500, Loss: -138.346008301\n",
      "Iteration: 51510, Loss: -143.274642944\n",
      "Iteration: 51520, Loss: -139.337051392\n",
      "Iteration: 51530, Loss: -133.484573364\n",
      "Iteration: 51540, Loss: -170.762802124\n",
      "Iteration: 51550, Loss: -149.047271729\n",
      "Iteration: 51560, Loss: -155.965942383\n",
      "Iteration: 51570, Loss: -136.768508911\n",
      "Iteration: 51580, Loss: -139.792953491\n",
      "Iteration: 51590, Loss: -144.374603271\n",
      "Iteration: 51600, Loss: -142.799926758\n",
      "Iteration: 51610, Loss: -153.275085449\n",
      "Iteration: 51620, Loss: -151.488632202\n",
      "Iteration: 51630, Loss: -137.797302246\n",
      "Iteration: 51640, Loss: -150.84765625\n",
      "Iteration: 51650, Loss: -140.787322998\n",
      "Iteration: 51660, Loss: -143.126159668\n",
      "Iteration: 51670, Loss: -129.710601807\n",
      "Iteration: 51680, Loss: -143.092193604\n",
      "Iteration: 51690, Loss: -141.10647583\n",
      "Iteration: 51700, Loss: -147.467346191\n",
      "Iteration: 51710, Loss: -149.261535645\n",
      "Iteration: 51720, Loss: -142.112594604\n",
      "Iteration: 51730, Loss: -157.174484253\n",
      "Iteration: 51740, Loss: -148.287200928\n",
      "Iteration: 51750, Loss: -160.819381714\n",
      "Iteration: 51760, Loss: -154.656677246\n",
      "Iteration: 51770, Loss: -143.701034546\n",
      "Iteration: 51780, Loss: -137.402206421\n",
      "Iteration: 51790, Loss: -141.4246521\n",
      "Iteration: 51800, Loss: -150.460693359\n",
      "Iteration: 51810, Loss: -129.612030029\n",
      "Iteration: 51820, Loss: -135.047210693\n",
      "Iteration: 51830, Loss: -144.20413208\n",
      "Iteration: 51840, Loss: -141.507492065\n",
      "Iteration: 51850, Loss: -143.177703857\n",
      "Iteration: 51860, Loss: -140.799316406\n",
      "Iteration: 51870, Loss: -134.718475342\n",
      "Iteration: 51880, Loss: -149.232589722\n",
      "Iteration: 51890, Loss: -146.984130859\n",
      "Iteration: 51900, Loss: -151.633422852\n",
      "Iteration: 51910, Loss: -162.451049805\n",
      "Iteration: 51920, Loss: -150.616638184\n",
      "Iteration: 51930, Loss: -143.499450684\n",
      "Iteration: 51940, Loss: -155.917877197\n",
      "Iteration: 51950, Loss: -138.562103271\n",
      "Iteration: 51960, Loss: -129.335464478\n",
      "Iteration: 51970, Loss: -142.3543396\n",
      "Iteration: 51980, Loss: -156.950790405\n",
      "Iteration: 51990, Loss: -146.071884155\n",
      "Iteration: 52000, Loss: -129.730361938\n",
      "Iteration: 52010, Loss: -148.929855347\n",
      "Iteration: 52020, Loss: -141.866210938\n",
      "Iteration: 52030, Loss: -146.092498779\n",
      "Iteration: 52040, Loss: -130.803436279\n",
      "Iteration: 52050, Loss: -150.726425171\n",
      "Iteration: 52060, Loss: -143.412078857\n",
      "Iteration: 52070, Loss: -134.478622437\n",
      "Iteration: 52080, Loss: -136.218688965\n",
      "Iteration: 52090, Loss: -139.089904785\n",
      "Iteration: 52100, Loss: -140.628143311\n",
      "Iteration: 52110, Loss: -139.759063721\n",
      "Iteration: 52120, Loss: -146.491760254\n",
      "Iteration: 52130, Loss: -146.60736084\n",
      "Iteration: 52140, Loss: -153.980987549\n",
      "Iteration: 52150, Loss: -155.415115356\n",
      "Iteration: 52160, Loss: -128.878448486\n",
      "Iteration: 52170, Loss: -153.435379028\n",
      "Iteration: 52180, Loss: -134.811706543\n",
      "Iteration: 52190, Loss: -153.930145264\n",
      "Iteration: 52200, Loss: -130.64666748\n",
      "Iteration: 52210, Loss: -143.045410156\n",
      "Iteration: 52220, Loss: -135.056182861\n",
      "Iteration: 52230, Loss: -154.996658325\n",
      "Iteration: 52240, Loss: -143.683486938\n",
      "Iteration: 52250, Loss: -137.371078491\n",
      "Iteration: 52260, Loss: -137.563995361\n",
      "Iteration: 52270, Loss: -136.008651733\n",
      "Iteration: 52280, Loss: -144.714599609\n",
      "Iteration: 52290, Loss: -155.051498413\n",
      "Iteration: 52300, Loss: -147.044189453\n",
      "Iteration: 52310, Loss: -150.668914795\n",
      "Iteration: 52320, Loss: -137.149490356\n",
      "Iteration: 52330, Loss: -138.687652588\n",
      "Iteration: 52340, Loss: -151.474212646\n",
      "Iteration: 52350, Loss: -146.015457153\n",
      "Iteration: 52360, Loss: -154.364089966\n",
      "Iteration: 52370, Loss: -123.493003845\n",
      "Iteration: 52380, Loss: -151.832839966\n",
      "Iteration: 52390, Loss: -139.180175781\n",
      "Iteration: 52400, Loss: -132.765808105\n",
      "Iteration: 52410, Loss: -128.454284668\n",
      "Iteration: 52420, Loss: -144.661499023\n",
      "Iteration: 52430, Loss: -142.26335144\n",
      "Iteration: 52440, Loss: -149.892501831\n",
      "Iteration: 52450, Loss: -139.463043213\n",
      "Iteration: 52460, Loss: -136.686157227\n",
      "Iteration: 52470, Loss: -144.087219238\n",
      "Iteration: 52480, Loss: -134.000762939\n",
      "Iteration: 52490, Loss: -133.962402344\n",
      "Iteration: 52500, Loss: -133.523269653\n",
      "Iteration: 52510, Loss: -136.752548218\n",
      "Iteration: 52520, Loss: -137.076385498\n",
      "Iteration: 52530, Loss: -153.597167969\n",
      "Iteration: 52540, Loss: -160.093261719\n",
      "Iteration: 52550, Loss: -135.965667725\n",
      "Iteration: 52560, Loss: -156.969970703\n",
      "Iteration: 52570, Loss: -147.571075439\n",
      "Iteration: 52580, Loss: -147.764129639\n",
      "Iteration: 52590, Loss: -134.772979736\n",
      "Iteration: 52600, Loss: -145.656402588\n",
      "Iteration: 52610, Loss: -156.462738037\n",
      "Iteration: 52620, Loss: -140.814758301\n",
      "Iteration: 52630, Loss: -143.431808472\n",
      "Iteration: 52640, Loss: -147.533584595\n",
      "Iteration: 52650, Loss: -142.250473022\n",
      "Iteration: 52660, Loss: -148.235290527\n",
      "Iteration: 52670, Loss: -142.176574707\n",
      "Iteration: 52680, Loss: -143.085830688\n",
      "Iteration: 52690, Loss: -153.999649048\n",
      "Iteration: 52700, Loss: -152.133605957\n",
      "Iteration: 52710, Loss: -146.094512939\n",
      "Iteration: 52720, Loss: -134.271011353\n",
      "Iteration: 52730, Loss: -137.249816895\n",
      "Iteration: 52740, Loss: -149.620986938\n",
      "Iteration: 52750, Loss: -147.630737305\n",
      "Iteration: 52760, Loss: -138.295898438\n",
      "Iteration: 52770, Loss: -143.589248657\n",
      "Iteration: 52780, Loss: -135.544921875\n",
      "Iteration: 52790, Loss: -129.264328003\n",
      "Iteration: 52800, Loss: -142.382385254\n",
      "Iteration: 52810, Loss: -131.3309021\n",
      "Iteration: 52820, Loss: -140.029449463\n",
      "Iteration: 52830, Loss: -151.195220947\n",
      "Iteration: 52840, Loss: -146.379211426\n",
      "Iteration: 52850, Loss: -144.795318604\n",
      "Iteration: 52860, Loss: -154.949249268\n",
      "Iteration: 52870, Loss: -144.488525391\n",
      "Iteration: 52880, Loss: -154.498321533\n",
      "Iteration: 52890, Loss: -143.121276855\n",
      "Iteration: 52900, Loss: -150.086883545\n",
      "Iteration: 52910, Loss: -151.891265869\n",
      "Iteration: 52920, Loss: -152.826629639\n",
      "Iteration: 52930, Loss: -145.876251221\n",
      "Iteration: 52940, Loss: -144.790863037\n",
      "Iteration: 52950, Loss: -138.002929688\n",
      "Iteration: 52960, Loss: -135.084442139\n",
      "Iteration: 52970, Loss: -145.703018188\n",
      "Iteration: 52980, Loss: -148.93081665\n",
      "Iteration: 52990, Loss: -136.924087524\n",
      "Iteration: 53000, Loss: -147.568069458\n",
      "Iteration: 53010, Loss: -155.038543701\n",
      "Iteration: 53020, Loss: -125.139060974\n",
      "Iteration: 53030, Loss: -142.930450439\n",
      "Iteration: 53040, Loss: -145.532867432\n",
      "Iteration: 53050, Loss: -147.662460327\n",
      "Iteration: 53060, Loss: -148.503219604\n",
      "Iteration: 53070, Loss: -143.071243286\n",
      "Iteration: 53080, Loss: -131.743347168\n",
      "Iteration: 53090, Loss: -131.425964355\n",
      "Iteration: 53100, Loss: -145.005096436\n",
      "Iteration: 53110, Loss: -151.230728149\n",
      "Iteration: 53120, Loss: -144.103790283\n",
      "Iteration: 53130, Loss: -140.96005249\n",
      "Iteration: 53140, Loss: -145.582778931\n",
      "Iteration: 53150, Loss: -161.742538452\n",
      "Iteration: 53160, Loss: -157.204116821\n",
      "Iteration: 53170, Loss: -149.243041992\n",
      "Iteration: 53180, Loss: -133.618255615\n",
      "Iteration: 53190, Loss: -140.952453613\n",
      "Iteration: 53200, Loss: -138.259384155\n",
      "Iteration: 53210, Loss: -150.87550354\n",
      "Iteration: 53220, Loss: -145.245178223\n",
      "Iteration: 53230, Loss: -148.629760742\n",
      "Iteration: 53240, Loss: -119.948974609\n",
      "Iteration: 53250, Loss: -144.151916504\n",
      "Iteration: 53260, Loss: -149.11920166\n",
      "Iteration: 53270, Loss: -146.50213623\n",
      "Iteration: 53280, Loss: -133.353302002\n",
      "Iteration: 53290, Loss: -136.577072144\n",
      "Iteration: 53300, Loss: -141.420333862\n",
      "Iteration: 53310, Loss: -126.380096436\n",
      "Iteration: 53320, Loss: -142.979675293\n",
      "Iteration: 53330, Loss: -140.246551514\n",
      "Iteration: 53340, Loss: -147.74609375\n",
      "Iteration: 53350, Loss: -133.707763672\n",
      "Iteration: 53360, Loss: -134.242172241\n",
      "Iteration: 53370, Loss: -145.605957031\n",
      "Iteration: 53380, Loss: -146.369903564\n",
      "Iteration: 53390, Loss: -160.298736572\n",
      "Iteration: 53400, Loss: -155.139953613\n",
      "Iteration: 53410, Loss: -147.158660889\n",
      "Iteration: 53420, Loss: -159.965118408\n",
      "Iteration: 53430, Loss: -150.324478149\n",
      "Iteration: 53440, Loss: -131.587097168\n",
      "Iteration: 53450, Loss: -125.609718323\n",
      "Iteration: 53460, Loss: -148.711212158\n",
      "Iteration: 53470, Loss: -137.365020752\n",
      "Iteration: 53480, Loss: -155.485641479\n",
      "Iteration: 53490, Loss: -143.191375732\n",
      "Iteration: 53500, Loss: -144.387298584\n",
      "Iteration: 53510, Loss: -126.034286499\n",
      "Iteration: 53520, Loss: -138.095794678\n",
      "Iteration: 53530, Loss: -143.701828003\n",
      "Iteration: 53540, Loss: -130.500061035\n",
      "Iteration: 53550, Loss: -153.030792236\n",
      "Iteration: 53560, Loss: -144.272338867\n",
      "Iteration: 53570, Loss: -152.75869751\n",
      "Iteration: 53580, Loss: -135.886871338\n",
      "Iteration: 53590, Loss: -140.067047119\n",
      "Iteration: 53600, Loss: -145.035339355\n",
      "Iteration: 53610, Loss: -146.126083374\n",
      "Iteration: 53620, Loss: -149.730895996\n",
      "Iteration: 53630, Loss: -143.179580688\n",
      "Iteration: 53640, Loss: -147.688995361\n",
      "Iteration: 53650, Loss: -143.076629639\n",
      "Iteration: 53660, Loss: -139.206237793\n",
      "Iteration: 53670, Loss: -153.527587891\n",
      "Iteration: 53680, Loss: -165.697143555\n",
      "Iteration: 53690, Loss: -148.781646729\n",
      "Iteration: 53700, Loss: -148.660339355\n",
      "Iteration: 53710, Loss: -138.459564209\n",
      "Iteration: 53720, Loss: -154.669708252\n",
      "Iteration: 53730, Loss: -132.542144775\n",
      "Iteration: 53740, Loss: -149.827789307\n",
      "Iteration: 53750, Loss: -149.055389404\n",
      "Iteration: 53760, Loss: -151.182891846\n",
      "Iteration: 53770, Loss: -151.029632568\n",
      "Iteration: 53780, Loss: -141.937957764\n",
      "Iteration: 53790, Loss: -143.527130127\n",
      "Iteration: 53800, Loss: -144.476623535\n",
      "Iteration: 53810, Loss: -141.390380859\n",
      "Iteration: 53820, Loss: -148.942672729\n",
      "Iteration: 53830, Loss: -132.372741699\n",
      "Iteration: 53840, Loss: -148.21736145\n",
      "Iteration: 53850, Loss: -144.623260498\n",
      "Iteration: 53860, Loss: -162.632217407\n",
      "Iteration: 53870, Loss: -144.927383423\n",
      "Iteration: 53880, Loss: -149.510635376\n",
      "Iteration: 53890, Loss: -136.26121521\n",
      "Iteration: 53900, Loss: -142.6743927\n",
      "Iteration: 53910, Loss: -140.301849365\n",
      "Iteration: 53920, Loss: -147.055755615\n",
      "Iteration: 53930, Loss: -150.145553589\n",
      "Iteration: 53940, Loss: -154.162979126\n",
      "Iteration: 53950, Loss: -150.507125854\n",
      "Iteration: 53960, Loss: -150.73815918\n",
      "Iteration: 53970, Loss: -148.27130127\n",
      "Iteration: 53980, Loss: -125.381309509\n",
      "Iteration: 53990, Loss: -144.287475586\n",
      "Iteration: 54000, Loss: -138.376144409\n",
      "Iteration: 54010, Loss: -146.2059021\n",
      "Iteration: 54020, Loss: -139.140533447\n",
      "Iteration: 54030, Loss: -141.094970703\n",
      "Iteration: 54040, Loss: -133.30406189\n",
      "Iteration: 54050, Loss: -148.119308472\n",
      "Iteration: 54060, Loss: -145.686737061\n",
      "Iteration: 54070, Loss: -143.393692017\n",
      "Iteration: 54080, Loss: -159.011764526\n",
      "Iteration: 54090, Loss: -141.753601074\n",
      "Iteration: 54100, Loss: -143.026611328\n",
      "Iteration: 54110, Loss: -127.489051819\n",
      "Iteration: 54120, Loss: -146.303527832\n",
      "Iteration: 54130, Loss: -151.619415283\n",
      "Iteration: 54140, Loss: -152.316680908\n",
      "Iteration: 54150, Loss: -141.894989014\n",
      "Iteration: 54160, Loss: -171.556732178\n",
      "Iteration: 54170, Loss: -156.690490723\n",
      "Iteration: 54180, Loss: -153.832427979\n",
      "Iteration: 54190, Loss: -137.198196411\n",
      "Iteration: 54200, Loss: -158.673370361\n",
      "Iteration: 54210, Loss: -142.363723755\n",
      "Iteration: 54220, Loss: -143.922576904\n",
      "Iteration: 54230, Loss: -150.500091553\n",
      "Iteration: 54240, Loss: -150.694946289\n",
      "Iteration: 54250, Loss: -144.671951294\n",
      "Iteration: 54260, Loss: -137.274902344\n",
      "Iteration: 54270, Loss: -137.596755981\n",
      "Iteration: 54280, Loss: -133.643493652\n",
      "Iteration: 54290, Loss: -142.627258301\n",
      "Iteration: 54300, Loss: -154.242431641\n",
      "Iteration: 54310, Loss: -155.353881836\n",
      "Iteration: 54320, Loss: -171.668212891\n",
      "Iteration: 54330, Loss: -155.356491089\n",
      "Iteration: 54340, Loss: -143.177368164\n",
      "Iteration: 54350, Loss: -145.71043396\n",
      "Iteration: 54360, Loss: -141.982894897\n",
      "Iteration: 54370, Loss: -146.483154297\n",
      "Iteration: 54380, Loss: -144.476501465\n",
      "Iteration: 54390, Loss: -142.615936279\n",
      "Iteration: 54400, Loss: -149.270050049\n",
      "Iteration: 54410, Loss: -167.096572876\n",
      "Iteration: 54420, Loss: -148.412567139\n",
      "Iteration: 54430, Loss: -132.047332764\n",
      "Iteration: 54440, Loss: -143.622406006\n",
      "Iteration: 54450, Loss: -141.340332031\n",
      "Iteration: 54460, Loss: -147.861083984\n",
      "Iteration: 54470, Loss: -142.578338623\n",
      "Iteration: 54480, Loss: -137.145996094\n",
      "Iteration: 54490, Loss: -139.369750977\n",
      "Iteration: 54500, Loss: -145.800384521\n",
      "Iteration: 54510, Loss: -152.983337402\n",
      "Iteration: 54520, Loss: -147.719787598\n",
      "Iteration: 54530, Loss: -136.857147217\n",
      "Iteration: 54540, Loss: -139.730377197\n",
      "Iteration: 54550, Loss: -150.375228882\n",
      "Iteration: 54560, Loss: -132.20413208\n",
      "Iteration: 54570, Loss: -155.317901611\n",
      "Iteration: 54580, Loss: -140.153106689\n",
      "Iteration: 54590, Loss: -154.660827637\n",
      "Iteration: 54600, Loss: -140.583679199\n",
      "Iteration: 54610, Loss: -147.320251465\n",
      "Iteration: 54620, Loss: -132.680984497\n",
      "Iteration: 54630, Loss: -141.924667358\n",
      "Iteration: 54640, Loss: -138.079345703\n",
      "Iteration: 54650, Loss: -144.442520142\n",
      "Iteration: 54660, Loss: -134.177062988\n",
      "Iteration: 54670, Loss: -135.881118774\n",
      "Iteration: 54680, Loss: -143.477508545\n",
      "Iteration: 54690, Loss: -146.462112427\n",
      "Iteration: 54700, Loss: -141.466033936\n",
      "Iteration: 54710, Loss: -144.034851074\n",
      "Iteration: 54720, Loss: -150.450378418\n",
      "Iteration: 54730, Loss: -150.591018677\n",
      "Iteration: 54740, Loss: -149.182495117\n",
      "Iteration: 54750, Loss: -148.430358887\n",
      "Iteration: 54760, Loss: -150.397140503\n",
      "Iteration: 54770, Loss: -136.222335815\n",
      "Iteration: 54780, Loss: -152.26385498\n",
      "Iteration: 54790, Loss: -148.565353394\n",
      "Iteration: 54800, Loss: -137.838989258\n",
      "Iteration: 54810, Loss: -151.995635986\n",
      "Iteration: 54820, Loss: -132.781265259\n",
      "Iteration: 54830, Loss: -131.666107178\n",
      "Iteration: 54840, Loss: -144.288757324\n",
      "Iteration: 54850, Loss: -141.51789856\n",
      "Iteration: 54860, Loss: -147.525802612\n",
      "Iteration: 54870, Loss: -148.081817627\n",
      "Iteration: 54880, Loss: -139.00982666\n",
      "Iteration: 54890, Loss: -142.39390564\n",
      "Iteration: 54900, Loss: -153.766693115\n",
      "Iteration: 54910, Loss: -131.862060547\n",
      "Iteration: 54920, Loss: -149.472900391\n",
      "Iteration: 54930, Loss: -148.931762695\n",
      "Iteration: 54940, Loss: -134.100845337\n",
      "Iteration: 54950, Loss: -137.883300781\n",
      "Iteration: 54960, Loss: -154.406188965\n",
      "Iteration: 54970, Loss: -156.608764648\n",
      "Iteration: 54980, Loss: -150.992553711\n",
      "Iteration: 54990, Loss: -151.879867554\n",
      "Iteration: 55000, Loss: -133.256240845\n",
      "Iteration: 55010, Loss: -142.907165527\n",
      "Iteration: 55020, Loss: -151.028915405\n",
      "Iteration: 55030, Loss: -139.813354492\n",
      "Iteration: 55040, Loss: -149.99130249\n",
      "Iteration: 55050, Loss: -146.951690674\n",
      "Iteration: 55060, Loss: -135.020675659\n",
      "Iteration: 55070, Loss: -128.411224365\n",
      "Iteration: 55080, Loss: -160.497283936\n",
      "Iteration: 55090, Loss: -147.079055786\n",
      "Iteration: 55100, Loss: -126.855873108\n",
      "Iteration: 55110, Loss: -145.70211792\n",
      "Iteration: 55120, Loss: -152.938171387\n",
      "Iteration: 55130, Loss: -137.509933472\n",
      "Iteration: 55140, Loss: -152.600799561\n",
      "Iteration: 55150, Loss: -148.574966431\n",
      "Iteration: 55160, Loss: -154.725646973\n",
      "Iteration: 55170, Loss: -131.039535522\n",
      "Iteration: 55180, Loss: -150.207565308\n",
      "Iteration: 55190, Loss: -135.196014404\n",
      "Iteration: 55200, Loss: -142.845367432\n",
      "Iteration: 55210, Loss: -150.081298828\n",
      "Iteration: 55220, Loss: -142.9503479\n",
      "Iteration: 55230, Loss: -125.871101379\n",
      "Iteration: 55240, Loss: -142.084411621\n",
      "Iteration: 55250, Loss: -159.277770996\n",
      "Iteration: 55260, Loss: -149.635269165\n",
      "Iteration: 55270, Loss: -136.359359741\n",
      "Iteration: 55280, Loss: -141.979034424\n",
      "Iteration: 55290, Loss: -133.892471313\n",
      "Iteration: 55300, Loss: -141.414077759\n",
      "Iteration: 55310, Loss: -147.979675293\n",
      "Iteration: 55320, Loss: -139.383407593\n",
      "Iteration: 55330, Loss: -132.537384033\n",
      "Iteration: 55340, Loss: -133.461853027\n",
      "Iteration: 55350, Loss: -141.078887939\n",
      "Iteration: 55360, Loss: -147.142318726\n",
      "Iteration: 55370, Loss: -151.95401001\n",
      "Iteration: 55380, Loss: -145.400985718\n",
      "Iteration: 55390, Loss: -146.014953613\n",
      "Iteration: 55400, Loss: -147.201690674\n",
      "Iteration: 55410, Loss: -142.439239502\n",
      "Iteration: 55420, Loss: -143.76675415\n",
      "Iteration: 55430, Loss: -153.827728271\n",
      "Iteration: 55440, Loss: -134.504043579\n",
      "Iteration: 55450, Loss: -140.379272461\n",
      "Iteration: 55460, Loss: -134.741699219\n",
      "Iteration: 55470, Loss: -139.781906128\n",
      "Iteration: 55480, Loss: -144.10017395\n",
      "Iteration: 55490, Loss: -151.823242188\n",
      "Iteration: 55500, Loss: -145.921813965\n",
      "Iteration: 55510, Loss: -141.624191284\n",
      "Iteration: 55520, Loss: -146.157485962\n",
      "Iteration: 55530, Loss: -130.819885254\n",
      "Iteration: 55540, Loss: -146.998535156\n",
      "Iteration: 55550, Loss: -137.29095459\n",
      "Iteration: 55560, Loss: -145.653289795\n",
      "Iteration: 55570, Loss: -157.66519165\n",
      "Iteration: 55580, Loss: -139.527404785\n",
      "Iteration: 55590, Loss: -144.218414307\n",
      "Iteration: 55600, Loss: -129.520355225\n",
      "Iteration: 55610, Loss: -147.915161133\n",
      "Iteration: 55620, Loss: -144.519012451\n",
      "Iteration: 55630, Loss: -134.671905518\n",
      "Iteration: 55640, Loss: -148.13104248\n",
      "Iteration: 55650, Loss: -144.130142212\n",
      "Iteration: 55660, Loss: -156.147628784\n",
      "Iteration: 55670, Loss: -137.163604736\n",
      "Iteration: 55680, Loss: -134.581542969\n",
      "Iteration: 55690, Loss: -151.320495605\n",
      "Iteration: 55700, Loss: -144.009185791\n",
      "Iteration: 55710, Loss: -145.665481567\n",
      "Iteration: 55720, Loss: -145.623626709\n",
      "Iteration: 55730, Loss: -134.66192627\n",
      "Iteration: 55740, Loss: -152.086883545\n",
      "Iteration: 55750, Loss: -142.050231934\n",
      "Iteration: 55760, Loss: -139.700424194\n",
      "Iteration: 55770, Loss: -156.471099854\n",
      "Iteration: 55780, Loss: -137.783477783\n",
      "Iteration: 55790, Loss: -143.885498047\n",
      "Iteration: 55800, Loss: -139.190368652\n",
      "Iteration: 55810, Loss: -130.25970459\n",
      "Iteration: 55820, Loss: -130.423248291\n",
      "Iteration: 55830, Loss: -150.796508789\n",
      "Iteration: 55840, Loss: -141.906311035\n",
      "Iteration: 55850, Loss: -145.679260254\n",
      "Iteration: 55860, Loss: -138.997558594\n",
      "Iteration: 55870, Loss: -144.906036377\n",
      "Iteration: 55880, Loss: -144.990142822\n",
      "Iteration: 55890, Loss: -136.342102051\n",
      "Iteration: 55900, Loss: -146.414733887\n",
      "Iteration: 55910, Loss: -141.672393799\n",
      "Iteration: 55920, Loss: -158.494277954\n",
      "Iteration: 55930, Loss: -140.361663818\n",
      "Iteration: 55940, Loss: -134.657577515\n",
      "Iteration: 55950, Loss: -145.773757935\n",
      "Iteration: 55960, Loss: -137.119140625\n",
      "Iteration: 55970, Loss: -144.637634277\n",
      "Iteration: 55980, Loss: -150.930725098\n",
      "Iteration: 55990, Loss: -140.834838867\n",
      "Iteration: 56000, Loss: -142.029174805\n",
      "Iteration: 56010, Loss: -132.835510254\n",
      "Iteration: 56020, Loss: -142.054443359\n",
      "Iteration: 56030, Loss: -142.188171387\n",
      "Iteration: 56040, Loss: -146.76739502\n",
      "Iteration: 56050, Loss: -151.165588379\n",
      "Iteration: 56060, Loss: -146.857025146\n",
      "Iteration: 56070, Loss: -145.271270752\n",
      "Iteration: 56080, Loss: -158.249542236\n",
      "Iteration: 56090, Loss: -158.718811035\n",
      "Iteration: 56100, Loss: -147.594161987\n",
      "Iteration: 56110, Loss: -150.603729248\n",
      "Iteration: 56120, Loss: -136.976272583\n",
      "Iteration: 56130, Loss: -143.678573608\n",
      "Iteration: 56140, Loss: -143.686721802\n",
      "Iteration: 56150, Loss: -140.887451172\n",
      "Iteration: 56160, Loss: -127.737251282\n",
      "Iteration: 56170, Loss: -152.296035767\n",
      "Iteration: 56180, Loss: -135.007507324\n",
      "Iteration: 56190, Loss: -152.021133423\n",
      "Iteration: 56200, Loss: -145.047851562\n",
      "Iteration: 56210, Loss: -132.078704834\n",
      "Iteration: 56220, Loss: -134.070709229\n",
      "Iteration: 56230, Loss: -136.276947021\n",
      "Iteration: 56240, Loss: -149.954559326\n",
      "Iteration: 56250, Loss: -163.974395752\n",
      "Iteration: 56260, Loss: -141.049072266\n",
      "Iteration: 56270, Loss: -137.165283203\n",
      "Iteration: 56280, Loss: -148.416488647\n",
      "Iteration: 56290, Loss: -157.023712158\n",
      "Iteration: 56300, Loss: -140.594787598\n",
      "Iteration: 56310, Loss: -153.822738647\n",
      "Iteration: 56320, Loss: -142.07371521\n",
      "Iteration: 56330, Loss: -149.919036865\n",
      "Iteration: 56340, Loss: -124.427352905\n",
      "Iteration: 56350, Loss: -133.59854126\n",
      "Iteration: 56360, Loss: -136.054656982\n",
      "Iteration: 56370, Loss: -149.73135376\n",
      "Iteration: 56380, Loss: -156.981750488\n",
      "Iteration: 56390, Loss: -142.101394653\n",
      "Iteration: 56400, Loss: -139.143814087\n",
      "Iteration: 56410, Loss: -146.625091553\n",
      "Iteration: 56420, Loss: -151.949066162\n",
      "Iteration: 56430, Loss: -144.634002686\n",
      "Iteration: 56440, Loss: -144.856735229\n",
      "Iteration: 56450, Loss: -133.923858643\n",
      "Iteration: 56460, Loss: -142.324310303\n",
      "Iteration: 56470, Loss: -139.258850098\n",
      "Iteration: 56480, Loss: -144.453948975\n",
      "Iteration: 56490, Loss: -140.025650024\n",
      "Iteration: 56500, Loss: -146.794647217\n",
      "Iteration: 56510, Loss: -139.785430908\n",
      "Iteration: 56520, Loss: -141.349151611\n",
      "Iteration: 56530, Loss: -147.605255127\n",
      "Iteration: 56540, Loss: -140.841522217\n",
      "Iteration: 56550, Loss: -142.541107178\n",
      "Iteration: 56560, Loss: -144.563201904\n",
      "Iteration: 56570, Loss: -144.705383301\n",
      "Iteration: 56580, Loss: -137.368515015\n",
      "Iteration: 56590, Loss: -158.040969849\n",
      "Iteration: 56600, Loss: -145.627319336\n",
      "Iteration: 56610, Loss: -136.163589478\n",
      "Iteration: 56620, Loss: -139.375473022\n",
      "Iteration: 56630, Loss: -146.56149292\n",
      "Iteration: 56640, Loss: -132.104125977\n",
      "Iteration: 56650, Loss: -128.362930298\n",
      "Iteration: 56660, Loss: -158.806152344\n",
      "Iteration: 56670, Loss: -146.952178955\n",
      "Iteration: 56680, Loss: -139.449798584\n",
      "Iteration: 56690, Loss: -152.960647583\n",
      "Iteration: 56700, Loss: -152.69821167\n",
      "Iteration: 56710, Loss: -140.534851074\n",
      "Iteration: 56720, Loss: -133.493560791\n",
      "Iteration: 56730, Loss: -134.415267944\n",
      "Iteration: 56740, Loss: -136.820571899\n",
      "Iteration: 56750, Loss: -140.093612671\n",
      "Iteration: 56760, Loss: -138.985015869\n",
      "Iteration: 56770, Loss: -140.238616943\n",
      "Iteration: 56780, Loss: -150.323623657\n",
      "Iteration: 56790, Loss: -150.257278442\n",
      "Iteration: 56800, Loss: -130.062988281\n",
      "Iteration: 56810, Loss: -160.337860107\n",
      "Iteration: 56820, Loss: -135.733001709\n",
      "Iteration: 56830, Loss: -135.992706299\n",
      "Iteration: 56840, Loss: -140.944656372\n",
      "Iteration: 56850, Loss: -140.074798584\n",
      "Iteration: 56860, Loss: -147.769927979\n",
      "Iteration: 56870, Loss: -149.718261719\n",
      "Iteration: 56880, Loss: -137.670532227\n",
      "Iteration: 56890, Loss: -144.301025391\n",
      "Iteration: 56900, Loss: -155.1512146\n",
      "Iteration: 56910, Loss: -135.166442871\n",
      "Iteration: 56920, Loss: -126.188102722\n",
      "Iteration: 56930, Loss: -146.598724365\n",
      "Iteration: 56940, Loss: -158.207244873\n",
      "Iteration: 56950, Loss: -151.987792969\n",
      "Iteration: 56960, Loss: -138.306640625\n",
      "Iteration: 56970, Loss: -152.449493408\n",
      "Iteration: 56980, Loss: -129.955505371\n",
      "Iteration: 56990, Loss: -143.899154663\n",
      "Iteration: 57000, Loss: -152.112197876\n",
      "Iteration: 57010, Loss: -143.110412598\n",
      "Iteration: 57020, Loss: -149.453292847\n",
      "Iteration: 57030, Loss: -143.866104126\n",
      "Iteration: 57040, Loss: -151.070159912\n",
      "Iteration: 57050, Loss: -135.848693848\n",
      "Iteration: 57060, Loss: -159.322662354\n",
      "Iteration: 57070, Loss: -149.181060791\n",
      "Iteration: 57080, Loss: -144.816818237\n",
      "Iteration: 57090, Loss: -135.591003418\n",
      "Iteration: 57100, Loss: -137.670471191\n",
      "Iteration: 57110, Loss: -138.470062256\n",
      "Iteration: 57120, Loss: -135.459014893\n",
      "Iteration: 57130, Loss: -146.688232422\n",
      "Iteration: 57140, Loss: -146.722106934\n",
      "Iteration: 57150, Loss: -132.41355896\n",
      "Iteration: 57160, Loss: -132.49786377\n",
      "Iteration: 57170, Loss: -132.857543945\n",
      "Iteration: 57180, Loss: -148.182189941\n",
      "Iteration: 57190, Loss: -140.050537109\n",
      "Iteration: 57200, Loss: -140.279403687\n",
      "Iteration: 57210, Loss: -148.394790649\n",
      "Iteration: 57220, Loss: -136.853729248\n",
      "Iteration: 57230, Loss: -161.708496094\n",
      "Iteration: 57240, Loss: -158.955078125\n",
      "Iteration: 57250, Loss: -137.684814453\n",
      "Iteration: 57260, Loss: -142.794326782\n",
      "Iteration: 57270, Loss: -144.821472168\n",
      "Iteration: 57280, Loss: -140.982849121\n",
      "Iteration: 57290, Loss: -152.312255859\n",
      "Iteration: 57300, Loss: -133.572494507\n",
      "Iteration: 57310, Loss: -141.522399902\n",
      "Iteration: 57320, Loss: -142.265075684\n",
      "Iteration: 57330, Loss: -145.664703369\n",
      "Iteration: 57340, Loss: -142.198547363\n",
      "Iteration: 57350, Loss: -155.884674072\n",
      "Iteration: 57360, Loss: -135.257614136\n",
      "Iteration: 57370, Loss: -151.230499268\n",
      "Iteration: 57380, Loss: -137.192596436\n",
      "Iteration: 57390, Loss: -150.578979492\n",
      "Iteration: 57400, Loss: -150.159942627\n",
      "Iteration: 57410, Loss: -135.320098877\n",
      "Iteration: 57420, Loss: -149.399368286\n",
      "Iteration: 57430, Loss: -137.604675293\n",
      "Iteration: 57440, Loss: -140.371795654\n",
      "Iteration: 57450, Loss: -154.981567383\n",
      "Iteration: 57460, Loss: -131.588378906\n",
      "Iteration: 57470, Loss: -143.587585449\n",
      "Iteration: 57480, Loss: -149.040283203\n",
      "Iteration: 57490, Loss: -136.491424561\n",
      "Iteration: 57500, Loss: -154.247283936\n",
      "Iteration: 57510, Loss: -136.383178711\n",
      "Iteration: 57520, Loss: -136.790222168\n",
      "Iteration: 57530, Loss: -148.581588745\n",
      "Iteration: 57540, Loss: -126.424713135\n",
      "Iteration: 57550, Loss: -145.844451904\n",
      "Iteration: 57560, Loss: -145.530044556\n",
      "Iteration: 57570, Loss: -135.183410645\n",
      "Iteration: 57580, Loss: -151.998977661\n",
      "Iteration: 57590, Loss: -133.386688232\n",
      "Iteration: 57600, Loss: -136.576065063\n",
      "Iteration: 57610, Loss: -139.498657227\n",
      "Iteration: 57620, Loss: -148.7318573\n",
      "Iteration: 57630, Loss: -144.260406494\n",
      "Iteration: 57640, Loss: -133.027801514\n",
      "Iteration: 57650, Loss: -148.105819702\n",
      "Iteration: 57660, Loss: -138.633026123\n",
      "Iteration: 57670, Loss: -138.03767395\n",
      "Iteration: 57680, Loss: -148.058563232\n",
      "Iteration: 57690, Loss: -161.495849609\n",
      "Iteration: 57700, Loss: -141.099700928\n",
      "Iteration: 57710, Loss: -133.118118286\n",
      "Iteration: 57720, Loss: -131.430053711\n",
      "Iteration: 57730, Loss: -136.083847046\n",
      "Iteration: 57740, Loss: -134.982055664\n",
      "Iteration: 57750, Loss: -147.808013916\n",
      "Iteration: 57760, Loss: -145.145126343\n",
      "Iteration: 57770, Loss: -136.590148926\n",
      "Iteration: 57780, Loss: -138.157669067\n",
      "Iteration: 57790, Loss: -147.46673584\n",
      "Iteration: 57800, Loss: -136.908203125\n",
      "Iteration: 57810, Loss: -134.128829956\n",
      "Iteration: 57820, Loss: -148.752990723\n",
      "Iteration: 57830, Loss: -145.946014404\n",
      "Iteration: 57840, Loss: -130.640762329\n",
      "Iteration: 57850, Loss: -150.678588867\n",
      "Iteration: 57860, Loss: -139.82460022\n",
      "Iteration: 57870, Loss: -139.428344727\n",
      "Iteration: 57880, Loss: -154.165237427\n",
      "Iteration: 57890, Loss: -139.973556519\n",
      "Iteration: 57900, Loss: -132.646514893\n",
      "Iteration: 57910, Loss: -130.846343994\n",
      "Iteration: 57920, Loss: -154.470748901\n",
      "Iteration: 57930, Loss: -146.333709717\n",
      "Iteration: 57940, Loss: -144.376220703\n",
      "Iteration: 57950, Loss: -155.82409668\n",
      "Iteration: 57960, Loss: -129.065841675\n",
      "Iteration: 57970, Loss: -144.73147583\n",
      "Iteration: 57980, Loss: -159.229598999\n",
      "Iteration: 57990, Loss: -136.606109619\n",
      "Iteration: 58000, Loss: -145.688293457\n",
      "Iteration: 58010, Loss: -149.664611816\n",
      "Iteration: 58020, Loss: -148.699707031\n",
      "Iteration: 58030, Loss: -153.797149658\n",
      "Iteration: 58040, Loss: -142.352111816\n",
      "Iteration: 58050, Loss: -141.238677979\n",
      "Iteration: 58060, Loss: -142.295654297\n",
      "Iteration: 58070, Loss: -150.869003296\n",
      "Iteration: 58080, Loss: -134.777893066\n",
      "Iteration: 58090, Loss: -140.392471313\n",
      "Iteration: 58100, Loss: -145.393859863\n",
      "Iteration: 58110, Loss: -131.205825806\n",
      "Iteration: 58120, Loss: -141.411132812\n",
      "Iteration: 58130, Loss: -157.537246704\n",
      "Iteration: 58140, Loss: -127.324157715\n",
      "Iteration: 58150, Loss: -150.749649048\n",
      "Iteration: 58160, Loss: -139.793304443\n",
      "Iteration: 58170, Loss: -146.459671021\n",
      "Iteration: 58180, Loss: -138.694091797\n",
      "Iteration: 58190, Loss: -152.588150024\n",
      "Iteration: 58200, Loss: -144.274002075\n",
      "Iteration: 58210, Loss: -140.857543945\n",
      "Iteration: 58220, Loss: -134.609375\n",
      "Iteration: 58230, Loss: -154.52645874\n",
      "Iteration: 58240, Loss: -129.383148193\n",
      "Iteration: 58250, Loss: -134.440979004\n",
      "Iteration: 58260, Loss: -136.542877197\n",
      "Iteration: 58270, Loss: -131.539978027\n",
      "Iteration: 58280, Loss: -145.447692871\n",
      "Iteration: 58290, Loss: -148.246765137\n",
      "Iteration: 58300, Loss: -147.452178955\n",
      "Iteration: 58310, Loss: -143.576629639\n",
      "Iteration: 58320, Loss: -130.47756958\n",
      "Iteration: 58330, Loss: -131.029525757\n",
      "Iteration: 58340, Loss: -157.638183594\n",
      "Iteration: 58350, Loss: -130.140563965\n",
      "Iteration: 58360, Loss: -134.002853394\n",
      "Iteration: 58370, Loss: -147.785675049\n",
      "Iteration: 58380, Loss: -138.252105713\n",
      "Iteration: 58390, Loss: -130.429046631\n",
      "Iteration: 58400, Loss: -152.494598389\n",
      "Iteration: 58410, Loss: -151.736160278\n",
      "Iteration: 58420, Loss: -136.670654297\n",
      "Iteration: 58430, Loss: -142.532897949\n",
      "Iteration: 58440, Loss: -136.845550537\n",
      "Iteration: 58450, Loss: -133.818435669\n",
      "Iteration: 58460, Loss: -139.636108398\n",
      "Iteration: 58470, Loss: -153.013580322\n",
      "Iteration: 58480, Loss: -160.822418213\n",
      "Iteration: 58490, Loss: -129.612609863\n",
      "Iteration: 58500, Loss: -151.165390015\n",
      "Iteration: 58510, Loss: -129.114624023\n",
      "Iteration: 58520, Loss: -156.873580933\n",
      "Iteration: 58530, Loss: -139.687759399\n",
      "Iteration: 58540, Loss: -140.010955811\n",
      "Iteration: 58550, Loss: -142.123687744\n",
      "Iteration: 58560, Loss: -148.556838989\n",
      "Iteration: 58570, Loss: -157.957870483\n",
      "Iteration: 58580, Loss: -141.849151611\n",
      "Iteration: 58590, Loss: -150.066802979\n",
      "Iteration: 58600, Loss: -152.499908447\n",
      "Iteration: 58610, Loss: -144.725982666\n",
      "Iteration: 58620, Loss: -141.72265625\n",
      "Iteration: 58630, Loss: -132.707977295\n",
      "Iteration: 58640, Loss: -148.985168457\n",
      "Iteration: 58650, Loss: -154.772491455\n",
      "Iteration: 58660, Loss: -154.075042725\n",
      "Iteration: 58670, Loss: -158.048431396\n",
      "Iteration: 58680, Loss: -141.21321106\n",
      "Iteration: 58690, Loss: -141.588302612\n",
      "Iteration: 58700, Loss: -149.34602356\n",
      "Iteration: 58710, Loss: -148.278717041\n",
      "Iteration: 58720, Loss: -132.782897949\n",
      "Iteration: 58730, Loss: -154.314941406\n",
      "Iteration: 58740, Loss: -147.764648438\n",
      "Iteration: 58750, Loss: -136.453933716\n",
      "Iteration: 58760, Loss: -142.891998291\n",
      "Iteration: 58770, Loss: -139.672927856\n",
      "Iteration: 58780, Loss: -137.318161011\n",
      "Iteration: 58790, Loss: -139.980133057\n",
      "Iteration: 58800, Loss: -144.071594238\n",
      "Iteration: 58810, Loss: -128.140594482\n",
      "Iteration: 58820, Loss: -145.630844116\n",
      "Iteration: 58830, Loss: -152.372589111\n",
      "Iteration: 58840, Loss: -158.467391968\n",
      "Iteration: 58850, Loss: -139.666870117\n",
      "Iteration: 58860, Loss: -140.884613037\n",
      "Iteration: 58870, Loss: -158.569168091\n",
      "Iteration: 58880, Loss: -155.567230225\n",
      "Iteration: 58890, Loss: -135.626846313\n",
      "Iteration: 58900, Loss: -134.62361145\n",
      "Iteration: 58910, Loss: -152.645782471\n",
      "Iteration: 58920, Loss: -152.246078491\n",
      "Iteration: 58930, Loss: -132.09727478\n",
      "Iteration: 58940, Loss: -141.155776978\n",
      "Iteration: 58950, Loss: -138.586486816\n",
      "Iteration: 58960, Loss: -141.47479248\n",
      "Iteration: 58970, Loss: -136.422332764\n",
      "Iteration: 58980, Loss: -135.697387695\n",
      "Iteration: 58990, Loss: -135.368469238\n",
      "Iteration: 59000, Loss: -142.52281189\n",
      "Iteration: 59010, Loss: -149.694076538\n",
      "Iteration: 59020, Loss: -142.003753662\n",
      "Iteration: 59030, Loss: -148.832855225\n",
      "Iteration: 59040, Loss: -136.931243896\n",
      "Iteration: 59050, Loss: -145.101272583\n",
      "Iteration: 59060, Loss: -132.98638916\n",
      "Iteration: 59070, Loss: -144.439544678\n",
      "Iteration: 59080, Loss: -135.969787598\n",
      "Iteration: 59090, Loss: -145.15020752\n",
      "Iteration: 59100, Loss: -153.023956299\n",
      "Iteration: 59110, Loss: -136.793701172\n",
      "Iteration: 59120, Loss: -130.736938477\n",
      "Iteration: 59130, Loss: -135.268859863\n",
      "Iteration: 59140, Loss: -130.896514893\n",
      "Iteration: 59150, Loss: -136.801742554\n",
      "Iteration: 59160, Loss: -152.506011963\n",
      "Iteration: 59170, Loss: -133.508728027\n",
      "Iteration: 59180, Loss: -140.603210449\n",
      "Iteration: 59190, Loss: -136.702316284\n",
      "Iteration: 59200, Loss: -146.089996338\n",
      "Iteration: 59210, Loss: -139.447647095\n",
      "Iteration: 59220, Loss: -147.615325928\n",
      "Iteration: 59230, Loss: -135.815338135\n",
      "Iteration: 59240, Loss: -154.809371948\n",
      "Iteration: 59250, Loss: -144.969543457\n",
      "Iteration: 59260, Loss: -142.927398682\n",
      "Iteration: 59270, Loss: -160.017150879\n",
      "Iteration: 59280, Loss: -150.660491943\n",
      "Iteration: 59290, Loss: -137.552520752\n",
      "Iteration: 59300, Loss: -154.717498779\n",
      "Iteration: 59310, Loss: -134.187316895\n",
      "Iteration: 59320, Loss: -164.086517334\n",
      "Iteration: 59330, Loss: -155.909332275\n",
      "Iteration: 59340, Loss: -141.810379028\n",
      "Iteration: 59350, Loss: -140.027435303\n",
      "Iteration: 59360, Loss: -132.581665039\n",
      "Iteration: 59370, Loss: -147.342407227\n",
      "Iteration: 59380, Loss: -133.120849609\n",
      "Iteration: 59390, Loss: -139.704772949\n",
      "Iteration: 59400, Loss: -146.566101074\n",
      "Iteration: 59410, Loss: -145.869567871\n",
      "Iteration: 59420, Loss: -134.991760254\n",
      "Iteration: 59430, Loss: -144.9243927\n",
      "Iteration: 59440, Loss: -147.580566406\n",
      "Iteration: 59450, Loss: -134.926940918\n",
      "Iteration: 59460, Loss: -137.774612427\n",
      "Iteration: 59470, Loss: -139.492660522\n",
      "Iteration: 59480, Loss: -144.73626709\n",
      "Iteration: 59490, Loss: -134.933319092\n",
      "Iteration: 59500, Loss: -142.864883423\n",
      "Iteration: 59510, Loss: -139.111541748\n",
      "Iteration: 59520, Loss: -148.020462036\n",
      "Iteration: 59530, Loss: -142.469436646\n",
      "Iteration: 59540, Loss: -143.257644653\n",
      "Iteration: 59550, Loss: -134.737548828\n",
      "Iteration: 59560, Loss: -155.31741333\n",
      "Iteration: 59570, Loss: -152.918884277\n",
      "Iteration: 59580, Loss: -132.281692505\n",
      "Iteration: 59590, Loss: -157.594482422\n",
      "Iteration: 59600, Loss: -155.301605225\n",
      "Iteration: 59610, Loss: -137.218902588\n",
      "Iteration: 59620, Loss: -138.024032593\n",
      "Iteration: 59630, Loss: -139.496429443\n",
      "Iteration: 59640, Loss: -139.573257446\n",
      "Iteration: 59650, Loss: -143.881256104\n",
      "Iteration: 59660, Loss: -139.001083374\n",
      "Iteration: 59670, Loss: -139.178771973\n",
      "Iteration: 59680, Loss: -141.21975708\n",
      "Iteration: 59690, Loss: -154.02494812\n",
      "Iteration: 59700, Loss: -136.115631104\n",
      "Iteration: 59710, Loss: -127.934143066\n",
      "Iteration: 59720, Loss: -132.945281982\n",
      "Iteration: 59730, Loss: -161.769790649\n",
      "Iteration: 59740, Loss: -145.702606201\n",
      "Iteration: 59750, Loss: -144.700592041\n",
      "Iteration: 59760, Loss: -144.043640137\n",
      "Iteration: 59770, Loss: -146.359207153\n",
      "Iteration: 59780, Loss: -130.766693115\n",
      "Iteration: 59790, Loss: -129.289825439\n",
      "Iteration: 59800, Loss: -143.214141846\n",
      "Iteration: 59810, Loss: -148.430084229\n",
      "Iteration: 59820, Loss: -136.026794434\n",
      "Iteration: 59830, Loss: -136.045074463\n",
      "Iteration: 59840, Loss: -146.064605713\n",
      "Iteration: 59850, Loss: -152.334686279\n",
      "Iteration: 59860, Loss: -144.40512085\n",
      "Iteration: 59870, Loss: -137.724822998\n",
      "Iteration: 59880, Loss: -139.428039551\n",
      "Iteration: 59890, Loss: -137.318603516\n",
      "Iteration: 59900, Loss: -132.476501465\n",
      "Iteration: 59910, Loss: -143.921936035\n",
      "Iteration: 59920, Loss: -131.730987549\n",
      "Iteration: 59930, Loss: -154.863708496\n",
      "Iteration: 59940, Loss: -132.064910889\n",
      "Iteration: 59950, Loss: -148.581268311\n",
      "Iteration: 59960, Loss: -128.391113281\n",
      "Iteration: 59970, Loss: -146.723297119\n",
      "Iteration: 59980, Loss: -145.316970825\n",
      "Iteration: 59990, Loss: -145.244750977\n",
      "Iteration: 60000, Loss: -161.302246094\n",
      "Iteration: 60010, Loss: -144.67350769\n",
      "Iteration: 60020, Loss: -140.205596924\n",
      "Iteration: 60030, Loss: -155.467041016\n",
      "Iteration: 60040, Loss: -147.210906982\n",
      "Iteration: 60050, Loss: -135.565948486\n",
      "Iteration: 60060, Loss: -142.349731445\n",
      "Iteration: 60070, Loss: -141.146270752\n",
      "Iteration: 60080, Loss: -141.181427002\n",
      "Iteration: 60090, Loss: -155.882156372\n",
      "Iteration: 60100, Loss: -142.850341797\n",
      "Iteration: 60110, Loss: -137.290878296\n",
      "Iteration: 60120, Loss: -134.149642944\n",
      "Iteration: 60130, Loss: -141.424804688\n",
      "Iteration: 60140, Loss: -141.3515625\n",
      "Iteration: 60150, Loss: -142.095657349\n",
      "Iteration: 60160, Loss: -151.953674316\n",
      "Iteration: 60170, Loss: -142.107467651\n",
      "Iteration: 60180, Loss: -144.471862793\n",
      "Iteration: 60190, Loss: -133.114471436\n",
      "Iteration: 60200, Loss: -135.042297363\n",
      "Iteration: 60210, Loss: -137.803588867\n",
      "Iteration: 60220, Loss: -155.111083984\n",
      "Iteration: 60230, Loss: -144.018768311\n",
      "Iteration: 60240, Loss: -145.576126099\n",
      "Iteration: 60250, Loss: -128.62852478\n",
      "Iteration: 60260, Loss: -142.679855347\n",
      "Iteration: 60270, Loss: -143.10256958\n",
      "Iteration: 60280, Loss: -151.279098511\n",
      "Iteration: 60290, Loss: -125.488189697\n",
      "Iteration: 60300, Loss: -141.478866577\n",
      "Iteration: 60310, Loss: -139.590148926\n",
      "Iteration: 60320, Loss: -142.79284668\n",
      "Iteration: 60330, Loss: -143.407043457\n",
      "Iteration: 60340, Loss: -157.022888184\n",
      "Iteration: 60350, Loss: -128.361480713\n",
      "Iteration: 60360, Loss: -138.521270752\n",
      "Iteration: 60370, Loss: -132.425598145\n",
      "Iteration: 60380, Loss: -160.932006836\n",
      "Iteration: 60390, Loss: -129.180404663\n",
      "Iteration: 60400, Loss: -156.008865356\n",
      "Iteration: 60410, Loss: -147.845977783\n",
      "Iteration: 60420, Loss: -145.760116577\n",
      "Iteration: 60430, Loss: -142.66468811\n",
      "Iteration: 60440, Loss: -134.230316162\n",
      "Iteration: 60450, Loss: -138.391174316\n",
      "Iteration: 60460, Loss: -142.243621826\n",
      "Iteration: 60470, Loss: -135.942703247\n",
      "Iteration: 60480, Loss: -136.28187561\n",
      "Iteration: 60490, Loss: -138.418518066\n",
      "Iteration: 60500, Loss: -146.337142944\n",
      "Iteration: 60510, Loss: -152.745834351\n",
      "Iteration: 60520, Loss: -136.850280762\n",
      "Iteration: 60530, Loss: -140.891815186\n",
      "Iteration: 60540, Loss: -151.943267822\n",
      "Iteration: 60550, Loss: -140.813552856\n",
      "Iteration: 60560, Loss: -142.618270874\n",
      "Iteration: 60570, Loss: -140.6512146\n",
      "Iteration: 60580, Loss: -141.42527771\n",
      "Iteration: 60590, Loss: -148.399108887\n",
      "Iteration: 60600, Loss: -137.772003174\n",
      "Iteration: 60610, Loss: -126.356307983\n",
      "Iteration: 60620, Loss: -147.394256592\n",
      "Iteration: 60630, Loss: -152.919784546\n",
      "Iteration: 60640, Loss: -139.966674805\n",
      "Iteration: 60650, Loss: -153.8934021\n",
      "Iteration: 60660, Loss: -141.082778931\n",
      "Iteration: 60670, Loss: -138.63609314\n",
      "Iteration: 60680, Loss: -140.957763672\n",
      "Iteration: 60690, Loss: -150.542068481\n",
      "Iteration: 60700, Loss: -141.906845093\n",
      "Iteration: 60710, Loss: -150.719909668\n",
      "Iteration: 60720, Loss: -148.102035522\n",
      "Iteration: 60730, Loss: -129.115310669\n",
      "Iteration: 60740, Loss: -138.540985107\n",
      "Iteration: 60750, Loss: -156.410095215\n",
      "Iteration: 60760, Loss: -144.71987915\n",
      "Iteration: 60770, Loss: -136.683166504\n",
      "Iteration: 60780, Loss: -133.744094849\n",
      "Iteration: 60790, Loss: -136.405426025\n",
      "Iteration: 60800, Loss: -146.603302002\n",
      "Iteration: 60810, Loss: -144.894439697\n",
      "Iteration: 60820, Loss: -145.87298584\n",
      "Iteration: 60830, Loss: -139.871887207\n",
      "Iteration: 60840, Loss: -141.352584839\n",
      "Iteration: 60850, Loss: -130.32220459\n",
      "Iteration: 60860, Loss: -148.960388184\n",
      "Iteration: 60870, Loss: -155.515167236\n",
      "Iteration: 60880, Loss: -140.848144531\n",
      "Iteration: 60890, Loss: -137.421234131\n",
      "Iteration: 60900, Loss: -143.983398438\n",
      "Iteration: 60910, Loss: -142.133178711\n",
      "Iteration: 60920, Loss: -157.078613281\n",
      "Iteration: 60930, Loss: -141.736083984\n",
      "Iteration: 60940, Loss: -138.815490723\n",
      "Iteration: 60950, Loss: -143.756652832\n",
      "Iteration: 60960, Loss: -156.992446899\n",
      "Iteration: 60970, Loss: -149.879547119\n",
      "Iteration: 60980, Loss: -154.919326782\n",
      "Iteration: 60990, Loss: -136.349700928\n",
      "Iteration: 61000, Loss: -143.884536743\n",
      "Iteration: 61010, Loss: -151.338623047\n",
      "Iteration: 61020, Loss: -152.747161865\n",
      "Iteration: 61030, Loss: -137.200531006\n",
      "Iteration: 61040, Loss: -142.042663574\n",
      "Iteration: 61050, Loss: -139.245986938\n",
      "Iteration: 61060, Loss: -160.45652771\n",
      "Iteration: 61070, Loss: -143.54057312\n",
      "Iteration: 61080, Loss: -159.575454712\n",
      "Iteration: 61090, Loss: -136.39263916\n",
      "Iteration: 61100, Loss: -140.693252563\n",
      "Iteration: 61110, Loss: -149.050720215\n",
      "Iteration: 61120, Loss: -146.404815674\n",
      "Iteration: 61130, Loss: -154.494918823\n",
      "Iteration: 61140, Loss: -133.175552368\n",
      "Iteration: 61150, Loss: -129.029663086\n",
      "Iteration: 61160, Loss: -139.480026245\n",
      "Iteration: 61170, Loss: -125.390235901\n",
      "Iteration: 61180, Loss: -158.054199219\n",
      "Iteration: 61190, Loss: -134.809921265\n",
      "Iteration: 61200, Loss: -145.358673096\n",
      "Iteration: 61210, Loss: -150.350158691\n",
      "Iteration: 61220, Loss: -134.606384277\n",
      "Iteration: 61230, Loss: -137.675079346\n",
      "Iteration: 61240, Loss: -139.340866089\n",
      "Iteration: 61250, Loss: -122.610221863\n",
      "Iteration: 61260, Loss: -125.756607056\n",
      "Iteration: 61270, Loss: -149.820617676\n",
      "Iteration: 61280, Loss: -125.249900818\n",
      "Iteration: 61290, Loss: -134.39805603\n",
      "Iteration: 61300, Loss: -141.906204224\n",
      "Iteration: 61310, Loss: -150.577636719\n",
      "Iteration: 61320, Loss: -136.075698853\n",
      "Iteration: 61330, Loss: -127.554893494\n",
      "Iteration: 61340, Loss: -138.876480103\n",
      "Iteration: 61350, Loss: -145.362915039\n",
      "Iteration: 61360, Loss: -145.652038574\n",
      "Iteration: 61370, Loss: -135.719680786\n",
      "Iteration: 61380, Loss: -134.664367676\n",
      "Iteration: 61390, Loss: -143.275939941\n",
      "Iteration: 61400, Loss: -141.008865356\n",
      "Iteration: 61410, Loss: -150.035186768\n",
      "Iteration: 61420, Loss: -151.697006226\n",
      "Iteration: 61430, Loss: -128.628921509\n",
      "Iteration: 61440, Loss: -140.113601685\n",
      "Iteration: 61450, Loss: -128.37902832\n",
      "Iteration: 61460, Loss: -148.935165405\n",
      "Iteration: 61470, Loss: -148.236114502\n",
      "Iteration: 61480, Loss: -129.952209473\n",
      "Iteration: 61490, Loss: -145.482971191\n",
      "Iteration: 61500, Loss: -125.654968262\n",
      "Iteration: 61510, Loss: -140.390777588\n",
      "Iteration: 61520, Loss: -148.29258728\n",
      "Iteration: 61530, Loss: -148.571411133\n",
      "Iteration: 61540, Loss: -142.790786743\n",
      "Iteration: 61550, Loss: -148.254684448\n",
      "Iteration: 61560, Loss: -134.413757324\n",
      "Iteration: 61570, Loss: -125.972579956\n",
      "Iteration: 61580, Loss: -136.666290283\n",
      "Iteration: 61590, Loss: -139.479812622\n",
      "Iteration: 61600, Loss: -148.839309692\n",
      "Iteration: 61610, Loss: -144.386138916\n",
      "Iteration: 61620, Loss: -133.054199219\n",
      "Iteration: 61630, Loss: -137.103942871\n",
      "Iteration: 61640, Loss: -130.920593262\n",
      "Iteration: 61650, Loss: -145.58442688\n",
      "Iteration: 61660, Loss: -129.481719971\n",
      "Iteration: 61670, Loss: -125.007171631\n",
      "Iteration: 61680, Loss: -135.853790283\n",
      "Iteration: 61690, Loss: -144.096603394\n",
      "Iteration: 61700, Loss: -143.168121338\n",
      "Iteration: 61710, Loss: -141.501144409\n",
      "Iteration: 61720, Loss: -130.697769165\n",
      "Iteration: 61730, Loss: -139.490875244\n",
      "Iteration: 61740, Loss: -134.922424316\n",
      "Iteration: 61750, Loss: -143.124023438\n",
      "Iteration: 61760, Loss: -133.219589233\n",
      "Iteration: 61770, Loss: -134.386459351\n",
      "Iteration: 61780, Loss: -136.705856323\n",
      "Iteration: 61790, Loss: -134.143981934\n",
      "Iteration: 61800, Loss: -148.862976074\n",
      "Iteration: 61810, Loss: -132.940887451\n",
      "Iteration: 61820, Loss: -158.478240967\n",
      "Iteration: 61830, Loss: -162.394226074\n",
      "Iteration: 61840, Loss: -127.468215942\n",
      "Iteration: 61850, Loss: -151.022628784\n",
      "Iteration: 61860, Loss: -142.37020874\n",
      "Iteration: 61870, Loss: -139.199996948\n",
      "Iteration: 61880, Loss: -130.38482666\n",
      "Iteration: 61890, Loss: -137.810211182\n",
      "Iteration: 61900, Loss: -148.349868774\n",
      "Iteration: 61910, Loss: -127.582443237\n",
      "Iteration: 61920, Loss: -132.135574341\n",
      "Iteration: 61930, Loss: -141.108276367\n",
      "Iteration: 61940, Loss: -131.849304199\n",
      "Iteration: 61950, Loss: -133.069366455\n",
      "Iteration: 61960, Loss: -142.571502686\n",
      "Iteration: 61970, Loss: -133.594558716\n",
      "Iteration: 61980, Loss: -125.049377441\n",
      "Iteration: 61990, Loss: -148.904907227\n",
      "Iteration: 62000, Loss: -133.791137695\n",
      "Iteration: 62010, Loss: -143.73449707\n",
      "Iteration: 62020, Loss: -127.70905304\n",
      "Iteration: 62030, Loss: -138.087524414\n",
      "Iteration: 62040, Loss: -132.172286987\n",
      "Iteration: 62050, Loss: -133.670928955\n",
      "Iteration: 62060, Loss: -121.403900146\n",
      "Iteration: 62070, Loss: -130.597839355\n",
      "Iteration: 62080, Loss: -152.188171387\n",
      "Iteration: 62090, Loss: -136.132644653\n",
      "Iteration: 62100, Loss: -139.32824707\n",
      "Iteration: 62110, Loss: -145.531890869\n",
      "Iteration: 62120, Loss: -132.375366211\n",
      "Iteration: 62130, Loss: -148.319869995\n",
      "Iteration: 62140, Loss: -146.960235596\n",
      "Iteration: 62150, Loss: -128.623840332\n",
      "Iteration: 62160, Loss: -149.156738281\n",
      "Iteration: 62170, Loss: -134.544418335\n",
      "Iteration: 62180, Loss: -137.886444092\n",
      "Iteration: 62190, Loss: -139.971221924\n",
      "Iteration: 62200, Loss: -149.277679443\n",
      "Iteration: 62210, Loss: -147.245071411\n",
      "Iteration: 62220, Loss: -141.620147705\n",
      "Iteration: 62230, Loss: -136.574829102\n",
      "Iteration: 62240, Loss: -141.373504639\n",
      "Iteration: 62250, Loss: -149.304855347\n",
      "Iteration: 62260, Loss: -159.572967529\n",
      "Iteration: 62270, Loss: -141.408874512\n",
      "Iteration: 62280, Loss: -141.487930298\n",
      "Iteration: 62290, Loss: -140.582641602\n",
      "Iteration: 62300, Loss: -134.599502563\n",
      "Iteration: 62310, Loss: -137.823730469\n",
      "Iteration: 62320, Loss: -137.863861084\n",
      "Iteration: 62330, Loss: -149.647506714\n",
      "Iteration: 62340, Loss: -148.817260742\n",
      "Iteration: 62350, Loss: -137.529098511\n",
      "Iteration: 62360, Loss: -151.336044312\n",
      "Iteration: 62370, Loss: -132.266815186\n",
      "Iteration: 62380, Loss: -136.562042236\n",
      "Iteration: 62390, Loss: -141.221176147\n",
      "Iteration: 62400, Loss: -154.041549683\n",
      "Iteration: 62410, Loss: -151.268676758\n",
      "Iteration: 62420, Loss: -129.389572144\n",
      "Iteration: 62430, Loss: -136.888122559\n",
      "Iteration: 62440, Loss: -135.557144165\n",
      "Iteration: 62450, Loss: -142.024536133\n",
      "Iteration: 62460, Loss: -133.003768921\n",
      "Iteration: 62470, Loss: -130.419647217\n",
      "Iteration: 62480, Loss: -135.721557617\n",
      "Iteration: 62490, Loss: -138.97442627\n",
      "Iteration: 62500, Loss: -131.963684082\n",
      "Iteration: 62510, Loss: -152.904708862\n",
      "Iteration: 62520, Loss: -137.365600586\n",
      "Iteration: 62530, Loss: -145.135345459\n",
      "Iteration: 62540, Loss: -144.028701782\n",
      "Iteration: 62550, Loss: -136.217819214\n",
      "Iteration: 62560, Loss: -130.335388184\n",
      "Iteration: 62570, Loss: -139.456726074\n",
      "Iteration: 62580, Loss: -148.600326538\n",
      "Iteration: 62590, Loss: -135.301437378\n",
      "Iteration: 62600, Loss: -140.645950317\n",
      "Iteration: 62610, Loss: -145.167572021\n",
      "Iteration: 62620, Loss: -133.796920776\n",
      "Iteration: 62630, Loss: -140.867004395\n",
      "Iteration: 62640, Loss: -149.63494873\n",
      "Iteration: 62650, Loss: -132.751861572\n",
      "Iteration: 62660, Loss: -137.089569092\n",
      "Iteration: 62670, Loss: -146.670623779\n",
      "Iteration: 62680, Loss: -136.811859131\n",
      "Iteration: 62690, Loss: -139.19519043\n",
      "Iteration: 62700, Loss: -152.473419189\n",
      "Iteration: 62710, Loss: -137.630187988\n",
      "Iteration: 62720, Loss: -144.809417725\n",
      "Iteration: 62730, Loss: -145.898468018\n",
      "Iteration: 62740, Loss: -132.110046387\n",
      "Iteration: 62750, Loss: -153.595458984\n",
      "Iteration: 62760, Loss: -133.425964355\n",
      "Iteration: 62770, Loss: -136.274871826\n",
      "Iteration: 62780, Loss: -150.332305908\n",
      "Iteration: 62790, Loss: -135.086090088\n",
      "Iteration: 62800, Loss: -147.377868652\n",
      "Iteration: 62810, Loss: -136.197952271\n",
      "Iteration: 62820, Loss: -140.153686523\n",
      "Iteration: 62830, Loss: -134.125427246\n",
      "Iteration: 62840, Loss: -127.080947876\n",
      "Iteration: 62850, Loss: -135.19909668\n",
      "Iteration: 62860, Loss: -144.459503174\n",
      "Iteration: 62870, Loss: -159.522766113\n",
      "Iteration: 62880, Loss: -160.572525024\n",
      "Iteration: 62890, Loss: -134.211532593\n",
      "Iteration: 62900, Loss: -148.208740234\n",
      "Iteration: 62910, Loss: -137.83265686\n",
      "Iteration: 62920, Loss: -149.539016724\n",
      "Iteration: 62930, Loss: -151.196655273\n",
      "Iteration: 62940, Loss: -134.119430542\n",
      "Iteration: 62950, Loss: -138.620376587\n",
      "Iteration: 62960, Loss: -141.066146851\n",
      "Iteration: 62970, Loss: -131.689300537\n",
      "Iteration: 62980, Loss: -150.575195312\n",
      "Iteration: 62990, Loss: -130.795379639\n",
      "Iteration: 63000, Loss: -133.808990479\n",
      "Iteration: 63010, Loss: -144.214233398\n",
      "Iteration: 63020, Loss: -140.256530762\n",
      "Iteration: 63030, Loss: -140.544448853\n",
      "Iteration: 63040, Loss: -143.122344971\n",
      "Iteration: 63050, Loss: -133.992843628\n",
      "Iteration: 63060, Loss: -139.402313232\n",
      "Iteration: 63070, Loss: -129.903167725\n",
      "Iteration: 63080, Loss: -142.778259277\n",
      "Iteration: 63090, Loss: -138.302612305\n",
      "Iteration: 63100, Loss: -139.109100342\n",
      "Iteration: 63110, Loss: -144.930023193\n",
      "Iteration: 63120, Loss: -145.132415771\n",
      "Iteration: 63130, Loss: -129.571350098\n",
      "Iteration: 63140, Loss: -141.408599854\n",
      "Iteration: 63150, Loss: -138.68157959\n",
      "Iteration: 63160, Loss: -138.638000488\n",
      "Iteration: 63170, Loss: -145.705276489\n",
      "Iteration: 63180, Loss: -148.433425903\n",
      "Iteration: 63190, Loss: -142.226745605\n",
      "Iteration: 63200, Loss: -146.353271484\n",
      "Iteration: 63210, Loss: -134.674331665\n",
      "Iteration: 63220, Loss: -138.97543335\n",
      "Iteration: 63230, Loss: -122.399200439\n",
      "Iteration: 63240, Loss: -141.131317139\n",
      "Iteration: 63250, Loss: -159.971725464\n",
      "Iteration: 63260, Loss: -148.760498047\n",
      "Iteration: 63270, Loss: -129.543869019\n",
      "Iteration: 63280, Loss: -141.993255615\n",
      "Iteration: 63290, Loss: -138.861206055\n",
      "Iteration: 63300, Loss: -140.646209717\n",
      "Iteration: 63310, Loss: -119.377532959\n",
      "Iteration: 63320, Loss: -142.975326538\n",
      "Iteration: 63330, Loss: -148.337768555\n",
      "Iteration: 63340, Loss: -139.538848877\n",
      "Iteration: 63350, Loss: -130.383285522\n",
      "Iteration: 63360, Loss: -129.098999023\n",
      "Iteration: 63370, Loss: -140.931732178\n",
      "Iteration: 63380, Loss: -146.176879883\n",
      "Iteration: 63390, Loss: -141.122650146\n",
      "Iteration: 63400, Loss: -125.8099823\n",
      "Iteration: 63410, Loss: -142.450531006\n",
      "Iteration: 63420, Loss: -143.975997925\n",
      "Iteration: 63430, Loss: -156.457092285\n",
      "Iteration: 63440, Loss: -127.29120636\n",
      "Iteration: 63450, Loss: -138.788085938\n",
      "Iteration: 63460, Loss: -149.336456299\n",
      "Iteration: 63470, Loss: -140.207092285\n",
      "Iteration: 63480, Loss: -152.559692383\n",
      "Iteration: 63490, Loss: -140.347045898\n",
      "Iteration: 63500, Loss: -137.563903809\n",
      "Iteration: 63510, Loss: -149.303146362\n",
      "Iteration: 63520, Loss: -127.428016663\n",
      "Iteration: 63530, Loss: -138.220916748\n",
      "Iteration: 63540, Loss: -142.816162109\n",
      "Iteration: 63550, Loss: -128.407241821\n",
      "Iteration: 63560, Loss: -140.127044678\n",
      "Iteration: 63570, Loss: -138.70501709\n",
      "Iteration: 63580, Loss: -140.499328613\n",
      "Iteration: 63590, Loss: -138.2527771\n",
      "Iteration: 63600, Loss: -140.924316406\n",
      "Iteration: 63610, Loss: -141.883148193\n",
      "Iteration: 63620, Loss: -125.966506958\n",
      "Iteration: 63630, Loss: -119.046539307\n",
      "Iteration: 63640, Loss: -145.456115723\n",
      "Iteration: 63650, Loss: -135.806808472\n",
      "Iteration: 63660, Loss: -139.578796387\n",
      "Iteration: 63670, Loss: -122.764862061\n",
      "Iteration: 63680, Loss: -127.70375824\n",
      "Iteration: 63690, Loss: -124.900421143\n",
      "Iteration: 63700, Loss: -133.426895142\n",
      "Iteration: 63710, Loss: -135.615631104\n",
      "Iteration: 63720, Loss: -135.433822632\n",
      "Iteration: 63730, Loss: -145.221237183\n",
      "Iteration: 63740, Loss: -140.006881714\n",
      "Iteration: 63750, Loss: -145.042922974\n",
      "Iteration: 63760, Loss: -143.96685791\n",
      "Iteration: 63770, Loss: -140.566925049\n",
      "Iteration: 63780, Loss: -152.106918335\n",
      "Iteration: 63790, Loss: -151.920089722\n",
      "Iteration: 63800, Loss: -144.67906189\n",
      "Iteration: 63810, Loss: -143.586700439\n",
      "Iteration: 63820, Loss: -141.98135376\n",
      "Iteration: 63830, Loss: -152.016540527\n",
      "Iteration: 63840, Loss: -150.687744141\n",
      "Iteration: 63850, Loss: -135.177246094\n",
      "Iteration: 63860, Loss: -128.360153198\n",
      "Iteration: 63870, Loss: -126.296340942\n",
      "Iteration: 63880, Loss: -143.449539185\n",
      "Iteration: 63890, Loss: -145.624923706\n",
      "Iteration: 63900, Loss: -150.848800659\n",
      "Iteration: 63910, Loss: -125.736412048\n",
      "Iteration: 63920, Loss: -143.897369385\n",
      "Iteration: 63930, Loss: -137.971954346\n",
      "Iteration: 63940, Loss: -149.386322021\n",
      "Iteration: 63950, Loss: -135.667678833\n",
      "Iteration: 63960, Loss: -132.620498657\n",
      "Iteration: 63970, Loss: -138.34185791\n",
      "Iteration: 63980, Loss: -137.304656982\n",
      "Iteration: 63990, Loss: -148.544937134\n",
      "Iteration: 64000, Loss: -148.855926514\n",
      "Iteration: 64010, Loss: -144.806030273\n",
      "Iteration: 64020, Loss: -137.317169189\n",
      "Iteration: 64030, Loss: -126.878051758\n",
      "Iteration: 64040, Loss: -143.999649048\n",
      "Iteration: 64050, Loss: -136.414215088\n",
      "Iteration: 64060, Loss: -125.791503906\n",
      "Iteration: 64070, Loss: -134.710968018\n",
      "Iteration: 64080, Loss: -131.850524902\n",
      "Iteration: 64090, Loss: -134.814498901\n",
      "Iteration: 64100, Loss: -138.090423584\n",
      "Iteration: 64110, Loss: -137.886505127\n",
      "Iteration: 64120, Loss: -143.315612793\n",
      "Iteration: 64130, Loss: -140.740066528\n",
      "Iteration: 64140, Loss: -134.46395874\n",
      "Iteration: 64150, Loss: -151.153366089\n",
      "Iteration: 64160, Loss: -130.009521484\n",
      "Iteration: 64170, Loss: -146.215454102\n",
      "Iteration: 64180, Loss: -141.101745605\n",
      "Iteration: 64190, Loss: -140.009017944\n",
      "Iteration: 64200, Loss: -120.453613281\n",
      "Iteration: 64210, Loss: -147.0287323\n",
      "Iteration: 64220, Loss: -159.777252197\n",
      "Iteration: 64230, Loss: -137.313995361\n",
      "Iteration: 64240, Loss: -133.212799072\n",
      "Iteration: 64250, Loss: -127.564079285\n",
      "Iteration: 64260, Loss: -134.766021729\n",
      "Iteration: 64270, Loss: -139.391265869\n",
      "Iteration: 64280, Loss: -158.190048218\n",
      "Iteration: 64290, Loss: -137.45300293\n",
      "Iteration: 64300, Loss: -146.331878662\n",
      "Iteration: 64310, Loss: -137.296112061\n",
      "Iteration: 64320, Loss: -148.364715576\n",
      "Iteration: 64330, Loss: -144.060913086\n",
      "Iteration: 64340, Loss: -144.908630371\n",
      "Iteration: 64350, Loss: -154.020843506\n",
      "Iteration: 64360, Loss: -147.235076904\n",
      "Iteration: 64370, Loss: -126.842987061\n",
      "Iteration: 64380, Loss: -147.006225586\n",
      "Iteration: 64390, Loss: -132.051742554\n",
      "Iteration: 64400, Loss: -148.105728149\n",
      "Iteration: 64410, Loss: -136.678833008\n",
      "Iteration: 64420, Loss: -136.913070679\n",
      "Iteration: 64430, Loss: -147.574676514\n",
      "Iteration: 64440, Loss: -128.186721802\n",
      "Iteration: 64450, Loss: -143.567840576\n",
      "Iteration: 64460, Loss: -132.002334595\n",
      "Iteration: 64470, Loss: -151.238494873\n",
      "Iteration: 64480, Loss: -140.596115112\n",
      "Iteration: 64490, Loss: -151.616973877\n",
      "Iteration: 64500, Loss: -149.000701904\n",
      "Iteration: 64510, Loss: -134.270278931\n",
      "Iteration: 64520, Loss: -140.000167847\n",
      "Iteration: 64530, Loss: -145.445327759\n",
      "Iteration: 64540, Loss: -137.435516357\n",
      "Iteration: 64550, Loss: -135.508163452\n",
      "Iteration: 64560, Loss: -150.720504761\n",
      "Iteration: 64570, Loss: -140.064727783\n",
      "Iteration: 64580, Loss: -128.176361084\n",
      "Iteration: 64590, Loss: -139.880645752\n",
      "Iteration: 64600, Loss: -141.230682373\n",
      "Iteration: 64610, Loss: -138.075408936\n",
      "Iteration: 64620, Loss: -145.820144653\n",
      "Iteration: 64630, Loss: -136.677505493\n",
      "Iteration: 64640, Loss: -145.821517944\n",
      "Iteration: 64650, Loss: -154.904678345\n",
      "Iteration: 64660, Loss: -129.058166504\n",
      "Iteration: 64670, Loss: -142.96144104\n",
      "Iteration: 64680, Loss: -152.509811401\n",
      "Iteration: 64690, Loss: -134.773284912\n",
      "Iteration: 64700, Loss: -143.721252441\n",
      "Iteration: 64710, Loss: -154.213134766\n",
      "Iteration: 64720, Loss: -138.740753174\n",
      "Iteration: 64730, Loss: -139.792144775\n",
      "Iteration: 64740, Loss: -155.870132446\n",
      "Iteration: 64750, Loss: -130.197875977\n",
      "Iteration: 64760, Loss: -144.628448486\n",
      "Iteration: 64770, Loss: -138.390274048\n",
      "Iteration: 64780, Loss: -143.766220093\n",
      "Iteration: 64790, Loss: -149.400268555\n",
      "Iteration: 64800, Loss: -151.070266724\n",
      "Iteration: 64810, Loss: -140.282684326\n",
      "Iteration: 64820, Loss: -143.051422119\n",
      "Iteration: 64830, Loss: -147.411102295\n",
      "Iteration: 64840, Loss: -146.062271118\n",
      "Iteration: 64850, Loss: -137.248764038\n",
      "Iteration: 64860, Loss: -123.925056458\n",
      "Iteration: 64870, Loss: -153.296356201\n",
      "Iteration: 64880, Loss: -132.823425293\n",
      "Iteration: 64890, Loss: -134.465713501\n",
      "Iteration: 64900, Loss: -138.394897461\n",
      "Iteration: 64910, Loss: -135.186737061\n",
      "Iteration: 64920, Loss: -136.790618896\n",
      "Iteration: 64930, Loss: -141.119537354\n",
      "Iteration: 64940, Loss: -141.187698364\n",
      "Iteration: 64950, Loss: -134.532196045\n",
      "Iteration: 64960, Loss: -129.922821045\n",
      "Iteration: 64970, Loss: -138.76222229\n",
      "Iteration: 64980, Loss: -152.706237793\n",
      "Iteration: 64990, Loss: -131.22857666\n",
      "Iteration: 65000, Loss: -130.544677734\n",
      "Iteration: 65010, Loss: -147.717803955\n",
      "Iteration: 65020, Loss: -134.226715088\n",
      "Iteration: 65030, Loss: -128.355102539\n",
      "Iteration: 65040, Loss: -143.282440186\n",
      "Iteration: 65050, Loss: -155.969512939\n",
      "Iteration: 65060, Loss: -129.735855103\n",
      "Iteration: 65070, Loss: -138.780822754\n",
      "Iteration: 65080, Loss: -139.882156372\n",
      "Iteration: 65090, Loss: -143.783935547\n",
      "Iteration: 65100, Loss: -139.685028076\n",
      "Iteration: 65110, Loss: -136.602905273\n",
      "Iteration: 65120, Loss: -130.693389893\n",
      "Iteration: 65130, Loss: -134.467041016\n",
      "Iteration: 65140, Loss: -139.03125\n",
      "Iteration: 65150, Loss: -148.141723633\n",
      "Iteration: 65160, Loss: -144.986450195\n",
      "Iteration: 65170, Loss: -155.291778564\n",
      "Iteration: 65180, Loss: -149.386520386\n",
      "Iteration: 65190, Loss: -129.304748535\n",
      "Iteration: 65200, Loss: -138.998321533\n",
      "Iteration: 65210, Loss: -152.057434082\n",
      "Iteration: 65220, Loss: -142.09463501\n",
      "Iteration: 65230, Loss: -142.54914856\n",
      "Iteration: 65240, Loss: -145.859954834\n",
      "Iteration: 65250, Loss: -145.385528564\n",
      "Iteration: 65260, Loss: -139.007583618\n",
      "Iteration: 65270, Loss: -155.026489258\n",
      "Iteration: 65280, Loss: -144.676986694\n",
      "Iteration: 65290, Loss: -142.225250244\n",
      "Iteration: 65300, Loss: -142.455444336\n",
      "Iteration: 65310, Loss: -137.09916687\n",
      "Iteration: 65320, Loss: -129.402496338\n",
      "Iteration: 65330, Loss: -145.374984741\n",
      "Iteration: 65340, Loss: -143.915863037\n",
      "Iteration: 65350, Loss: -147.252853394\n",
      "Iteration: 65360, Loss: -132.860168457\n",
      "Iteration: 65370, Loss: -128.849609375\n",
      "Iteration: 65380, Loss: -137.835449219\n",
      "Iteration: 65390, Loss: -137.949111938\n",
      "Iteration: 65400, Loss: -122.857803345\n",
      "Iteration: 65410, Loss: -142.083496094\n",
      "Iteration: 65420, Loss: -152.462615967\n",
      "Iteration: 65430, Loss: -134.434783936\n",
      "Iteration: 65440, Loss: -150.591339111\n",
      "Iteration: 65450, Loss: -142.334152222\n",
      "Iteration: 65460, Loss: -127.116485596\n",
      "Iteration: 65470, Loss: -140.845031738\n",
      "Iteration: 65480, Loss: -134.584518433\n",
      "Iteration: 65490, Loss: -149.448654175\n",
      "Iteration: 65500, Loss: -135.722244263\n",
      "Iteration: 65510, Loss: -138.848129272\n",
      "Iteration: 65520, Loss: -152.15536499\n",
      "Iteration: 65530, Loss: -140.419433594\n",
      "Iteration: 65540, Loss: -133.702285767\n",
      "Iteration: 65550, Loss: -147.025695801\n",
      "Iteration: 65560, Loss: -136.719238281\n",
      "Iteration: 65570, Loss: -135.298126221\n",
      "Iteration: 65580, Loss: -131.653076172\n",
      "Iteration: 65590, Loss: -142.538024902\n",
      "Iteration: 65600, Loss: -144.571350098\n",
      "Iteration: 65610, Loss: -134.580490112\n",
      "Iteration: 65620, Loss: -133.582183838\n",
      "Iteration: 65630, Loss: -140.428985596\n",
      "Iteration: 65640, Loss: -134.589172363\n",
      "Iteration: 65650, Loss: -142.698989868\n",
      "Iteration: 65660, Loss: -134.469802856\n",
      "Iteration: 65670, Loss: -139.114959717\n",
      "Iteration: 65680, Loss: -138.388931274\n",
      "Iteration: 65690, Loss: -147.948471069\n",
      "Iteration: 65700, Loss: -156.52671814\n",
      "Iteration: 65710, Loss: -137.087921143\n",
      "Iteration: 65720, Loss: -157.178863525\n",
      "Iteration: 65730, Loss: -137.325927734\n",
      "Iteration: 65740, Loss: -131.960296631\n",
      "Iteration: 65750, Loss: -144.557388306\n",
      "Iteration: 65760, Loss: -131.532684326\n",
      "Iteration: 65770, Loss: -125.812095642\n",
      "Iteration: 65780, Loss: -150.528442383\n",
      "Iteration: 65790, Loss: -129.669891357\n",
      "Iteration: 65800, Loss: -142.723114014\n",
      "Iteration: 65810, Loss: -152.677658081\n",
      "Iteration: 65820, Loss: -135.702407837\n",
      "Iteration: 65830, Loss: -132.882263184\n",
      "Iteration: 65840, Loss: -144.717605591\n",
      "Iteration: 65850, Loss: -139.247375488\n",
      "Iteration: 65860, Loss: -126.646133423\n",
      "Iteration: 65870, Loss: -146.422134399\n",
      "Iteration: 65880, Loss: -140.857452393\n",
      "Iteration: 65890, Loss: -126.151504517\n",
      "Iteration: 65900, Loss: -142.725799561\n",
      "Iteration: 65910, Loss: -134.986755371\n",
      "Iteration: 65920, Loss: -148.037780762\n",
      "Iteration: 65930, Loss: -142.019165039\n",
      "Iteration: 65940, Loss: -146.126358032\n",
      "Iteration: 65950, Loss: -147.878540039\n",
      "Iteration: 65960, Loss: -134.471374512\n",
      "Iteration: 65970, Loss: -143.947937012\n",
      "Iteration: 65980, Loss: -134.540512085\n",
      "Iteration: 65990, Loss: -136.284896851\n",
      "Iteration: 66000, Loss: -153.969711304\n",
      "Iteration: 66010, Loss: -142.208908081\n",
      "Iteration: 66020, Loss: -135.143585205\n",
      "Iteration: 66030, Loss: -127.25402832\n",
      "Iteration: 66040, Loss: -140.496887207\n",
      "Iteration: 66050, Loss: -135.282348633\n",
      "Iteration: 66060, Loss: -138.932861328\n",
      "Iteration: 66070, Loss: -128.423858643\n",
      "Iteration: 66080, Loss: -138.185699463\n",
      "Iteration: 66090, Loss: -137.039535522\n",
      "Iteration: 66100, Loss: -135.717651367\n",
      "Iteration: 66110, Loss: -125.260704041\n",
      "Iteration: 66120, Loss: -138.977767944\n",
      "Iteration: 66130, Loss: -136.000732422\n",
      "Iteration: 66140, Loss: -149.273620605\n",
      "Iteration: 66150, Loss: -150.304473877\n",
      "Iteration: 66160, Loss: -147.996063232\n",
      "Iteration: 66170, Loss: -140.016937256\n",
      "Iteration: 66180, Loss: -147.602539062\n",
      "Iteration: 66190, Loss: -128.250671387\n",
      "Iteration: 66200, Loss: -146.305725098\n",
      "Iteration: 66210, Loss: -149.069351196\n",
      "Iteration: 66220, Loss: -131.913146973\n",
      "Iteration: 66230, Loss: -135.607543945\n",
      "Iteration: 66240, Loss: -148.028839111\n",
      "Iteration: 66250, Loss: -140.743743896\n",
      "Iteration: 66260, Loss: -127.556045532\n",
      "Iteration: 66270, Loss: -127.712104797\n",
      "Iteration: 66280, Loss: -129.110610962\n",
      "Iteration: 66290, Loss: -139.42276001\n",
      "Iteration: 66300, Loss: -137.17755127\n",
      "Iteration: 66310, Loss: -141.395675659\n",
      "Iteration: 66320, Loss: -136.875488281\n",
      "Iteration: 66330, Loss: -146.191970825\n",
      "Iteration: 66340, Loss: -124.260253906\n",
      "Iteration: 66350, Loss: -145.801391602\n",
      "Iteration: 66360, Loss: -136.584457397\n",
      "Iteration: 66370, Loss: -139.023651123\n",
      "Iteration: 66380, Loss: -132.034698486\n",
      "Iteration: 66390, Loss: -138.749633789\n",
      "Iteration: 66400, Loss: -141.590332031\n",
      "Iteration: 66410, Loss: -127.657417297\n",
      "Iteration: 66420, Loss: -139.121704102\n",
      "Iteration: 66430, Loss: -123.925842285\n",
      "Iteration: 66440, Loss: -141.355255127\n",
      "Iteration: 66450, Loss: -123.975250244\n",
      "Iteration: 66460, Loss: -137.801055908\n",
      "Iteration: 66470, Loss: -133.171798706\n",
      "Iteration: 66480, Loss: -144.827636719\n",
      "Iteration: 66490, Loss: -136.076370239\n",
      "Iteration: 66500, Loss: -142.368682861\n",
      "Iteration: 66510, Loss: -132.331054688\n",
      "Iteration: 66520, Loss: -148.307357788\n",
      "Iteration: 66530, Loss: -139.314727783\n",
      "Iteration: 66540, Loss: -134.041320801\n",
      "Iteration: 66550, Loss: -129.129699707\n",
      "Iteration: 66560, Loss: -135.667022705\n",
      "Iteration: 66570, Loss: -140.916717529\n",
      "Iteration: 66580, Loss: -137.954345703\n",
      "Iteration: 66590, Loss: -144.920196533\n",
      "Iteration: 66600, Loss: -130.08694458\n",
      "Iteration: 66610, Loss: -141.531585693\n",
      "Iteration: 66620, Loss: -144.638763428\n",
      "Iteration: 66630, Loss: -143.130157471\n",
      "Iteration: 66640, Loss: -133.564300537\n",
      "Iteration: 66650, Loss: -136.679168701\n",
      "Iteration: 66660, Loss: -132.200241089\n",
      "Iteration: 66670, Loss: -138.757598877\n",
      "Iteration: 66680, Loss: -144.361480713\n",
      "Iteration: 66690, Loss: -140.058288574\n",
      "Iteration: 66700, Loss: -159.849365234\n",
      "Iteration: 66710, Loss: -141.372955322\n",
      "Iteration: 66720, Loss: -134.773773193\n",
      "Iteration: 66730, Loss: -149.607452393\n",
      "Iteration: 66740, Loss: -148.34942627\n",
      "Iteration: 66750, Loss: -133.411605835\n",
      "Iteration: 66760, Loss: -156.60017395\n",
      "Iteration: 66770, Loss: -132.628036499\n",
      "Iteration: 66780, Loss: -155.630874634\n",
      "Iteration: 66790, Loss: -148.874160767\n",
      "Iteration: 66800, Loss: -143.843383789\n",
      "Iteration: 66810, Loss: -139.388671875\n",
      "Iteration: 66820, Loss: -139.33026123\n",
      "Iteration: 66830, Loss: -146.911209106\n",
      "Iteration: 66840, Loss: -145.104598999\n",
      "Iteration: 66850, Loss: -138.183990479\n",
      "Iteration: 66860, Loss: -139.352996826\n",
      "Iteration: 66870, Loss: -144.546096802\n",
      "Iteration: 66880, Loss: -150.884399414\n",
      "Iteration: 66890, Loss: -124.839324951\n",
      "Iteration: 66900, Loss: -138.196990967\n",
      "Iteration: 66910, Loss: -133.884002686\n",
      "Iteration: 66920, Loss: -144.069244385\n",
      "Iteration: 66930, Loss: -138.496520996\n",
      "Iteration: 66940, Loss: -136.65814209\n",
      "Iteration: 66950, Loss: -149.692611694\n",
      "Iteration: 66960, Loss: -132.856292725\n",
      "Iteration: 66970, Loss: -135.413223267\n",
      "Iteration: 66980, Loss: -130.71182251\n",
      "Iteration: 66990, Loss: -139.770980835\n",
      "Iteration: 67000, Loss: -134.82484436\n",
      "Iteration: 67010, Loss: -138.396591187\n",
      "Iteration: 67020, Loss: -141.417053223\n",
      "Iteration: 67030, Loss: -146.046966553\n",
      "Iteration: 67040, Loss: -131.843353271\n",
      "Iteration: 67050, Loss: -118.929084778\n",
      "Iteration: 67060, Loss: -127.85559082\n",
      "Iteration: 67070, Loss: -140.348632812\n",
      "Iteration: 67080, Loss: -133.295379639\n",
      "Iteration: 67090, Loss: -126.023338318\n",
      "Iteration: 67100, Loss: -148.634765625\n",
      "Iteration: 67110, Loss: -145.495117188\n",
      "Iteration: 67120, Loss: -141.08493042\n",
      "Iteration: 67130, Loss: -125.372955322\n",
      "Iteration: 67140, Loss: -142.720031738\n",
      "Iteration: 67150, Loss: -143.067565918\n",
      "Iteration: 67160, Loss: -137.141998291\n",
      "Iteration: 67170, Loss: -133.258239746\n",
      "Iteration: 67180, Loss: -137.114227295\n",
      "Iteration: 67190, Loss: -142.505157471\n",
      "Iteration: 67200, Loss: -135.775604248\n",
      "Iteration: 67210, Loss: -144.429290771\n",
      "Iteration: 67220, Loss: -137.009094238\n",
      "Iteration: 67230, Loss: -159.307098389\n",
      "Iteration: 67240, Loss: -130.532562256\n",
      "Iteration: 67250, Loss: -128.398376465\n",
      "Iteration: 67260, Loss: -144.916351318\n",
      "Iteration: 67270, Loss: -139.364105225\n",
      "Iteration: 67280, Loss: -136.352203369\n",
      "Iteration: 67290, Loss: -152.318969727\n",
      "Iteration: 67300, Loss: -138.410385132\n",
      "Iteration: 67310, Loss: -157.08303833\n",
      "Iteration: 67320, Loss: -138.780944824\n",
      "Iteration: 67330, Loss: -149.465072632\n",
      "Iteration: 67340, Loss: -128.683898926\n",
      "Iteration: 67350, Loss: -144.194030762\n",
      "Iteration: 67360, Loss: -141.769897461\n",
      "Iteration: 67370, Loss: -158.413833618\n",
      "Iteration: 67380, Loss: -160.327072144\n",
      "Iteration: 67390, Loss: -156.995056152\n",
      "Iteration: 67400, Loss: -150.695495605\n",
      "Iteration: 67410, Loss: -138.739746094\n",
      "Iteration: 67420, Loss: -137.741394043\n",
      "Iteration: 67430, Loss: -123.609092712\n",
      "Iteration: 67440, Loss: -144.745941162\n",
      "Iteration: 67450, Loss: -141.203338623\n",
      "Iteration: 67460, Loss: -145.106750488\n",
      "Iteration: 67470, Loss: -125.025688171\n",
      "Iteration: 67480, Loss: -138.696426392\n",
      "Iteration: 67490, Loss: -150.166900635\n",
      "Iteration: 67500, Loss: -155.59552002\n",
      "Iteration: 67510, Loss: -135.570541382\n",
      "Iteration: 67520, Loss: -141.095611572\n",
      "Iteration: 67530, Loss: -138.246398926\n",
      "Iteration: 67540, Loss: -148.583389282\n",
      "Iteration: 67550, Loss: -155.676574707\n",
      "Iteration: 67560, Loss: -137.525848389\n",
      "Iteration: 67570, Loss: -137.611236572\n",
      "Iteration: 67580, Loss: -143.114578247\n",
      "Iteration: 67590, Loss: -130.607055664\n",
      "Iteration: 67600, Loss: -134.561126709\n",
      "Iteration: 67610, Loss: -149.576828003\n",
      "Iteration: 67620, Loss: -140.963638306\n",
      "Iteration: 67630, Loss: -140.052215576\n",
      "Iteration: 67640, Loss: -150.399673462\n",
      "Iteration: 67650, Loss: -123.489082336\n",
      "Iteration: 67660, Loss: -134.116317749\n",
      "Iteration: 67670, Loss: -137.351287842\n",
      "Iteration: 67680, Loss: -134.673553467\n",
      "Iteration: 67690, Loss: -144.555831909\n",
      "Iteration: 67700, Loss: -142.138122559\n",
      "Iteration: 67710, Loss: -140.45211792\n",
      "Iteration: 67720, Loss: -122.091239929\n",
      "Iteration: 67730, Loss: -137.954071045\n",
      "Iteration: 67740, Loss: -140.951187134\n",
      "Iteration: 67750, Loss: -147.661392212\n",
      "Iteration: 67760, Loss: -119.022979736\n",
      "Iteration: 67770, Loss: -135.731109619\n",
      "Iteration: 67780, Loss: -127.163009644\n",
      "Iteration: 67790, Loss: -135.017578125\n",
      "Iteration: 67800, Loss: -142.869766235\n",
      "Iteration: 67810, Loss: -145.837524414\n",
      "Iteration: 67820, Loss: -143.364562988\n",
      "Iteration: 67830, Loss: -142.75982666\n",
      "Iteration: 67840, Loss: -139.269638062\n",
      "Iteration: 67850, Loss: -142.020355225\n",
      "Iteration: 67860, Loss: -127.639144897\n",
      "Iteration: 67870, Loss: -133.190994263\n",
      "Iteration: 67880, Loss: -137.364135742\n",
      "Iteration: 67890, Loss: -130.292877197\n",
      "Iteration: 67900, Loss: -140.02557373\n",
      "Iteration: 67910, Loss: -128.644119263\n",
      "Iteration: 67920, Loss: -137.329360962\n",
      "Iteration: 67930, Loss: -136.857650757\n",
      "Iteration: 67940, Loss: -137.304626465\n",
      "Iteration: 67950, Loss: -146.922927856\n",
      "Iteration: 67960, Loss: -151.474853516\n",
      "Iteration: 67970, Loss: -134.378356934\n",
      "Iteration: 67980, Loss: -136.377029419\n",
      "Iteration: 67990, Loss: -148.483215332\n",
      "Iteration: 68000, Loss: -122.521255493\n",
      "Iteration: 68010, Loss: -148.864715576\n",
      "Iteration: 68020, Loss: -152.162643433\n",
      "Iteration: 68030, Loss: -131.549957275\n",
      "Iteration: 68040, Loss: -141.653442383\n",
      "Iteration: 68050, Loss: -140.886978149\n",
      "Iteration: 68060, Loss: -139.703521729\n",
      "Iteration: 68070, Loss: -152.040008545\n",
      "Iteration: 68080, Loss: -151.827728271\n",
      "Iteration: 68090, Loss: -140.302719116\n",
      "Iteration: 68100, Loss: -134.009155273\n",
      "Iteration: 68110, Loss: -140.107757568\n",
      "Iteration: 68120, Loss: -137.320465088\n",
      "Iteration: 68130, Loss: -133.665023804\n",
      "Iteration: 68140, Loss: -143.656402588\n",
      "Iteration: 68150, Loss: -130.781280518\n",
      "Iteration: 68160, Loss: -162.305419922\n",
      "Iteration: 68170, Loss: -138.62046814\n",
      "Iteration: 68180, Loss: -140.251998901\n",
      "Iteration: 68190, Loss: -138.660354614\n",
      "Iteration: 68200, Loss: -133.950866699\n",
      "Iteration: 68210, Loss: -149.162139893\n",
      "Iteration: 68220, Loss: -131.227386475\n",
      "Iteration: 68230, Loss: -147.78024292\n",
      "Iteration: 68240, Loss: -130.772369385\n",
      "Iteration: 68250, Loss: -132.477249146\n",
      "Iteration: 68260, Loss: -149.990768433\n",
      "Iteration: 68270, Loss: -141.199234009\n",
      "Iteration: 68280, Loss: -131.343765259\n",
      "Iteration: 68290, Loss: -131.495056152\n",
      "Iteration: 68300, Loss: -137.175613403\n",
      "Iteration: 68310, Loss: -145.553253174\n",
      "Iteration: 68320, Loss: -129.642196655\n",
      "Iteration: 68330, Loss: -136.164001465\n",
      "Iteration: 68340, Loss: -133.831756592\n",
      "Iteration: 68350, Loss: -141.914215088\n",
      "Iteration: 68360, Loss: -146.257064819\n",
      "Iteration: 68370, Loss: -129.002059937\n",
      "Iteration: 68380, Loss: -138.480514526\n",
      "Iteration: 68390, Loss: -142.030548096\n",
      "Iteration: 68400, Loss: -143.872375488\n",
      "Iteration: 68410, Loss: -137.380340576\n",
      "Iteration: 68420, Loss: -139.174468994\n",
      "Iteration: 68430, Loss: -149.425079346\n",
      "Iteration: 68440, Loss: -143.837921143\n",
      "Iteration: 68450, Loss: -126.54234314\n",
      "Iteration: 68460, Loss: -136.248046875\n",
      "Iteration: 68470, Loss: -141.345657349\n",
      "Iteration: 68480, Loss: -150.771728516\n",
      "Iteration: 68490, Loss: -148.980499268\n",
      "Iteration: 68500, Loss: -151.557556152\n",
      "Iteration: 68510, Loss: -134.177520752\n",
      "Iteration: 68520, Loss: -131.659423828\n",
      "Iteration: 68530, Loss: -144.403045654\n",
      "Iteration: 68540, Loss: -138.802856445\n",
      "Iteration: 68550, Loss: -160.368087769\n",
      "Iteration: 68560, Loss: -140.056686401\n",
      "Iteration: 68570, Loss: -134.324798584\n",
      "Iteration: 68580, Loss: -139.860733032\n",
      "Iteration: 68590, Loss: -142.274200439\n",
      "Iteration: 68600, Loss: -139.423370361\n",
      "Iteration: 68610, Loss: -135.959899902\n",
      "Iteration: 68620, Loss: -126.98072052\n",
      "Iteration: 68630, Loss: -139.936767578\n",
      "Iteration: 68640, Loss: -140.868286133\n",
      "Iteration: 68650, Loss: -139.135025024\n",
      "Iteration: 68660, Loss: -143.248474121\n",
      "Iteration: 68670, Loss: -139.457580566\n",
      "Iteration: 68680, Loss: -149.597106934\n",
      "Iteration: 68690, Loss: -140.536178589\n",
      "Iteration: 68700, Loss: -143.525558472\n",
      "Iteration: 68710, Loss: -147.723052979\n",
      "Iteration: 68720, Loss: -135.656433105\n",
      "Iteration: 68730, Loss: -148.036178589\n",
      "Iteration: 68740, Loss: -132.41166687\n",
      "Iteration: 68750, Loss: -144.055877686\n",
      "Iteration: 68760, Loss: -133.453475952\n",
      "Iteration: 68770, Loss: -133.666275024\n",
      "Iteration: 68780, Loss: -130.572052002\n",
      "Iteration: 68790, Loss: -140.080200195\n",
      "Iteration: 68800, Loss: -128.545043945\n",
      "Iteration: 68810, Loss: -152.246780396\n",
      "Iteration: 68820, Loss: -131.59085083\n",
      "Iteration: 68830, Loss: -129.674591064\n",
      "Iteration: 68840, Loss: -141.057342529\n",
      "Iteration: 68850, Loss: -147.004257202\n",
      "Iteration: 68860, Loss: -150.654937744\n",
      "Iteration: 68870, Loss: -138.63142395\n",
      "Iteration: 68880, Loss: -142.550949097\n",
      "Iteration: 68890, Loss: -143.935974121\n",
      "Iteration: 68900, Loss: -130.375534058\n",
      "Iteration: 68910, Loss: -117.830513\n",
      "Iteration: 68920, Loss: -128.017578125\n",
      "Iteration: 68930, Loss: -134.356887817\n",
      "Iteration: 68940, Loss: -138.324432373\n",
      "Iteration: 68950, Loss: -131.249023438\n",
      "Iteration: 68960, Loss: -142.794525146\n",
      "Iteration: 68970, Loss: -139.663772583\n",
      "Iteration: 68980, Loss: -137.885131836\n",
      "Iteration: 68990, Loss: -141.322494507\n",
      "Iteration: 69000, Loss: -133.571884155\n",
      "Iteration: 69010, Loss: -138.558197021\n",
      "Iteration: 69020, Loss: -163.889892578\n",
      "Iteration: 69030, Loss: -137.50617981\n",
      "Iteration: 69040, Loss: -134.358184814\n",
      "Iteration: 69050, Loss: -143.600494385\n",
      "Iteration: 69060, Loss: -134.323181152\n",
      "Iteration: 69070, Loss: -144.155059814\n",
      "Iteration: 69080, Loss: -148.895431519\n",
      "Iteration: 69090, Loss: -129.202316284\n",
      "Iteration: 69100, Loss: -128.124603271\n",
      "Iteration: 69110, Loss: -130.975982666\n",
      "Iteration: 69120, Loss: -136.741973877\n",
      "Iteration: 69130, Loss: -148.551223755\n",
      "Iteration: 69140, Loss: -122.5418396\n",
      "Iteration: 69150, Loss: -141.488861084\n",
      "Iteration: 69160, Loss: -144.037353516\n",
      "Iteration: 69170, Loss: -134.409515381\n",
      "Iteration: 69180, Loss: -147.012863159\n",
      "Iteration: 69190, Loss: -130.139541626\n",
      "Iteration: 69200, Loss: -146.424697876\n",
      "Iteration: 69210, Loss: -129.872253418\n",
      "Iteration: 69220, Loss: -136.797943115\n",
      "Iteration: 69230, Loss: -141.318908691\n",
      "Iteration: 69240, Loss: -136.639434814\n",
      "Iteration: 69250, Loss: -120.470855713\n",
      "Iteration: 69260, Loss: -136.014770508\n",
      "Iteration: 69270, Loss: -137.894943237\n",
      "Iteration: 69280, Loss: -129.601379395\n",
      "Iteration: 69290, Loss: -133.688186646\n",
      "Iteration: 69300, Loss: -149.047271729\n",
      "Iteration: 69310, Loss: -147.425888062\n",
      "Iteration: 69320, Loss: -131.570831299\n",
      "Iteration: 69330, Loss: -145.090240479\n",
      "Iteration: 69340, Loss: -139.563598633\n",
      "Iteration: 69350, Loss: -149.386383057\n",
      "Iteration: 69360, Loss: -142.113677979\n",
      "Iteration: 69370, Loss: -133.879364014\n",
      "Iteration: 69380, Loss: -167.1118927\n",
      "Iteration: 69390, Loss: -142.051376343\n",
      "Iteration: 69400, Loss: -141.872070312\n",
      "Iteration: 69410, Loss: -132.154342651\n",
      "Iteration: 69420, Loss: -145.233459473\n",
      "Iteration: 69430, Loss: -142.640899658\n",
      "Iteration: 69440, Loss: -146.831115723\n",
      "Iteration: 69450, Loss: -120.132705688\n",
      "Iteration: 69460, Loss: -140.026580811\n",
      "Iteration: 69470, Loss: -149.118438721\n",
      "Iteration: 69480, Loss: -143.891021729\n",
      "Iteration: 69490, Loss: -129.229736328\n",
      "Iteration: 69500, Loss: -139.202789307\n",
      "Iteration: 69510, Loss: -132.022888184\n",
      "Iteration: 69520, Loss: -138.087142944\n",
      "Iteration: 69530, Loss: -148.929779053\n",
      "Iteration: 69540, Loss: -141.932983398\n",
      "Iteration: 69550, Loss: -133.997924805\n",
      "Iteration: 69560, Loss: -151.27911377\n",
      "Iteration: 69570, Loss: -139.575714111\n",
      "Iteration: 69580, Loss: -143.401168823\n",
      "Iteration: 69590, Loss: -150.68182373\n",
      "Iteration: 69600, Loss: -129.860809326\n",
      "Iteration: 69610, Loss: -129.780380249\n",
      "Iteration: 69620, Loss: -145.331787109\n",
      "Iteration: 69630, Loss: -138.593963623\n",
      "Iteration: 69640, Loss: -148.873626709\n",
      "Iteration: 69650, Loss: -131.26449585\n",
      "Iteration: 69660, Loss: -129.651016235\n",
      "Iteration: 69670, Loss: -142.536941528\n",
      "Iteration: 69680, Loss: -151.057525635\n",
      "Iteration: 69690, Loss: -138.482696533\n",
      "Iteration: 69700, Loss: -143.219665527\n",
      "Iteration: 69710, Loss: -130.521774292\n",
      "Iteration: 69720, Loss: -136.684143066\n",
      "Iteration: 69730, Loss: -127.494636536\n",
      "Iteration: 69740, Loss: -144.757568359\n",
      "Iteration: 69750, Loss: -138.829956055\n",
      "Iteration: 69760, Loss: -128.349075317\n",
      "Iteration: 69770, Loss: -140.812515259\n",
      "Iteration: 69780, Loss: -156.245330811\n",
      "Iteration: 69790, Loss: -142.608337402\n",
      "Iteration: 69800, Loss: -127.153335571\n",
      "Iteration: 69810, Loss: -148.115631104\n",
      "Iteration: 69820, Loss: -144.197494507\n",
      "Iteration: 69830, Loss: -143.275238037\n",
      "Iteration: 69840, Loss: -146.832870483\n",
      "Iteration: 69850, Loss: -138.838653564\n",
      "Iteration: 69860, Loss: -150.461929321\n",
      "Iteration: 69870, Loss: -117.603340149\n",
      "Iteration: 69880, Loss: -133.367019653\n",
      "Iteration: 69890, Loss: -138.682556152\n",
      "Iteration: 69900, Loss: -134.191558838\n",
      "Iteration: 69910, Loss: -133.057907104\n",
      "Iteration: 69920, Loss: -137.744491577\n",
      "Iteration: 69930, Loss: -130.984054565\n",
      "Iteration: 69940, Loss: -151.282165527\n",
      "Iteration: 69950, Loss: -138.006835938\n",
      "Iteration: 69960, Loss: -153.084869385\n",
      "Iteration: 69970, Loss: -142.018585205\n",
      "Iteration: 69980, Loss: -151.091522217\n",
      "Iteration: 69990, Loss: -123.294937134\n",
      "Iteration: 70000, Loss: -138.701690674\n",
      "Iteration: 70010, Loss: -161.540466309\n",
      "Iteration: 70020, Loss: -148.729675293\n",
      "Iteration: 70030, Loss: -131.45199585\n",
      "Iteration: 70040, Loss: -146.038787842\n",
      "Iteration: 70050, Loss: -139.083374023\n",
      "Iteration: 70060, Loss: -123.809921265\n",
      "Iteration: 70070, Loss: -146.908355713\n",
      "Iteration: 70080, Loss: -127.317634583\n",
      "Iteration: 70090, Loss: -137.609954834\n",
      "Iteration: 70100, Loss: -158.63911438\n",
      "Iteration: 70110, Loss: -132.799972534\n",
      "Iteration: 70120, Loss: -125.461334229\n",
      "Iteration: 70130, Loss: -150.783203125\n",
      "Iteration: 70140, Loss: -132.378738403\n",
      "Iteration: 70150, Loss: -147.524780273\n",
      "Iteration: 70160, Loss: -155.798950195\n",
      "Iteration: 70170, Loss: -133.761291504\n",
      "Iteration: 70180, Loss: -147.650543213\n",
      "Iteration: 70190, Loss: -134.785614014\n",
      "Iteration: 70200, Loss: -136.256332397\n",
      "Iteration: 70210, Loss: -134.759307861\n",
      "Iteration: 70220, Loss: -145.910446167\n",
      "Iteration: 70230, Loss: -139.686126709\n",
      "Iteration: 70240, Loss: -136.244384766\n",
      "Iteration: 70250, Loss: -139.248596191\n",
      "Iteration: 70260, Loss: -147.097579956\n",
      "Iteration: 70270, Loss: -133.341262817\n",
      "Iteration: 70280, Loss: -143.984893799\n",
      "Iteration: 70290, Loss: -142.147186279\n",
      "Iteration: 70300, Loss: -134.477172852\n",
      "Iteration: 70310, Loss: -136.417633057\n",
      "Iteration: 70320, Loss: -137.405670166\n",
      "Iteration: 70330, Loss: -146.386398315\n",
      "Iteration: 70340, Loss: -136.579818726\n",
      "Iteration: 70350, Loss: -131.022171021\n",
      "Iteration: 70360, Loss: -134.273986816\n",
      "Iteration: 70370, Loss: -138.69152832\n",
      "Iteration: 70380, Loss: -131.209716797\n",
      "Iteration: 70390, Loss: -129.074523926\n",
      "Iteration: 70400, Loss: -138.069671631\n",
      "Iteration: 70410, Loss: -143.216430664\n",
      "Iteration: 70420, Loss: -145.650024414\n",
      "Iteration: 70430, Loss: -131.042205811\n",
      "Iteration: 70440, Loss: -147.547241211\n",
      "Iteration: 70450, Loss: -138.275253296\n",
      "Iteration: 70460, Loss: -135.08895874\n",
      "Iteration: 70470, Loss: -146.236434937\n",
      "Iteration: 70480, Loss: -133.327941895\n",
      "Iteration: 70490, Loss: -132.293563843\n",
      "Iteration: 70500, Loss: -135.249572754\n",
      "Iteration: 70510, Loss: -136.363006592\n",
      "Iteration: 70520, Loss: -142.392852783\n",
      "Iteration: 70530, Loss: -134.07989502\n",
      "Iteration: 70540, Loss: -139.0753479\n",
      "Iteration: 70550, Loss: -132.411331177\n",
      "Iteration: 70560, Loss: -144.05859375\n",
      "Iteration: 70570, Loss: -149.729644775\n",
      "Iteration: 70580, Loss: -138.42024231\n",
      "Iteration: 70590, Loss: -124.797363281\n",
      "Iteration: 70600, Loss: -137.855163574\n",
      "Iteration: 70610, Loss: -155.000854492\n",
      "Iteration: 70620, Loss: -129.957366943\n",
      "Iteration: 70630, Loss: -137.581634521\n",
      "Iteration: 70640, Loss: -144.863189697\n",
      "Iteration: 70650, Loss: -141.203811646\n",
      "Iteration: 70660, Loss: -145.230529785\n",
      "Iteration: 70670, Loss: -135.378814697\n",
      "Iteration: 70680, Loss: -130.350692749\n",
      "Iteration: 70690, Loss: -126.318161011\n",
      "Iteration: 70700, Loss: -138.708770752\n",
      "Iteration: 70710, Loss: -134.668334961\n",
      "Iteration: 70720, Loss: -128.107543945\n",
      "Iteration: 70730, Loss: -128.476074219\n",
      "Iteration: 70740, Loss: -127.514091492\n",
      "Iteration: 70750, Loss: -136.136993408\n",
      "Iteration: 70760, Loss: -159.420837402\n",
      "Iteration: 70770, Loss: -141.844909668\n",
      "Iteration: 70780, Loss: -128.082168579\n",
      "Iteration: 70790, Loss: -136.551208496\n",
      "Iteration: 70800, Loss: -130.348373413\n",
      "Iteration: 70810, Loss: -142.409317017\n",
      "Iteration: 70820, Loss: -136.588684082\n",
      "Iteration: 70830, Loss: -145.28692627\n",
      "Iteration: 70840, Loss: -155.901580811\n",
      "Iteration: 70850, Loss: -135.755264282\n",
      "Iteration: 70860, Loss: -137.455200195\n",
      "Iteration: 70870, Loss: -127.750350952\n",
      "Iteration: 70880, Loss: -127.729385376\n",
      "Iteration: 70890, Loss: -147.768218994\n",
      "Iteration: 70900, Loss: -141.724365234\n",
      "Iteration: 70910, Loss: -144.158691406\n",
      "Iteration: 70920, Loss: -147.191436768\n",
      "Iteration: 70930, Loss: -117.130348206\n",
      "Iteration: 70940, Loss: -142.24659729\n",
      "Iteration: 70950, Loss: -125.615570068\n",
      "Iteration: 70960, Loss: -141.804138184\n",
      "Iteration: 70970, Loss: -129.752990723\n",
      "Iteration: 70980, Loss: -136.430328369\n",
      "Iteration: 70990, Loss: -152.856140137\n",
      "Iteration: 71000, Loss: -135.856765747\n",
      "Iteration: 71010, Loss: -144.987548828\n",
      "Iteration: 71020, Loss: -142.697998047\n",
      "Iteration: 71030, Loss: -127.764709473\n",
      "Iteration: 71040, Loss: -157.393692017\n",
      "Iteration: 71050, Loss: -144.256851196\n",
      "Iteration: 71060, Loss: -139.816070557\n",
      "Iteration: 71070, Loss: -137.906478882\n",
      "Iteration: 71080, Loss: -143.746948242\n",
      "Iteration: 71090, Loss: -144.634490967\n",
      "Iteration: 71100, Loss: -133.104156494\n",
      "Iteration: 71110, Loss: -139.556854248\n",
      "Iteration: 71120, Loss: -136.609603882\n",
      "Iteration: 71130, Loss: -124.483436584\n",
      "Iteration: 71140, Loss: -137.698791504\n",
      "Iteration: 71150, Loss: -137.283508301\n",
      "Iteration: 71160, Loss: -149.619216919\n",
      "Iteration: 71170, Loss: -160.053497314\n",
      "Iteration: 71180, Loss: -138.743255615\n",
      "Iteration: 71190, Loss: -139.671188354\n",
      "Iteration: 71200, Loss: -130.840927124\n",
      "Iteration: 71210, Loss: -150.534423828\n",
      "Iteration: 71220, Loss: -132.784942627\n",
      "Iteration: 71230, Loss: -146.376220703\n",
      "Iteration: 71240, Loss: -128.631134033\n",
      "Iteration: 71250, Loss: -134.215209961\n",
      "Iteration: 71260, Loss: -128.721160889\n",
      "Iteration: 71270, Loss: -144.366134644\n",
      "Iteration: 71280, Loss: -126.571563721\n",
      "Iteration: 71290, Loss: -139.011322021\n",
      "Iteration: 71300, Loss: -133.349746704\n",
      "Iteration: 71310, Loss: -125.507461548\n",
      "Iteration: 71320, Loss: -140.861633301\n",
      "Iteration: 71330, Loss: -137.981948853\n",
      "Iteration: 71340, Loss: -137.463989258\n",
      "Iteration: 71350, Loss: -127.908424377\n",
      "Iteration: 71360, Loss: -140.425125122\n",
      "Iteration: 71370, Loss: -147.06338501\n",
      "Iteration: 71380, Loss: -134.918762207\n",
      "Iteration: 71390, Loss: -137.270568848\n",
      "Iteration: 71400, Loss: -129.655456543\n",
      "Iteration: 71410, Loss: -135.478942871\n",
      "Iteration: 71420, Loss: -147.204833984\n",
      "Iteration: 71430, Loss: -141.002624512\n",
      "Iteration: 71440, Loss: -139.406677246\n",
      "Iteration: 71450, Loss: -145.518325806\n",
      "Iteration: 71460, Loss: -150.616577148\n",
      "Iteration: 71470, Loss: -134.385284424\n",
      "Iteration: 71480, Loss: -156.245513916\n",
      "Iteration: 71490, Loss: -144.178253174\n",
      "Iteration: 71500, Loss: -144.727813721\n",
      "Iteration: 71510, Loss: -146.833068848\n",
      "Iteration: 71520, Loss: -131.075592041\n",
      "Iteration: 71530, Loss: -120.996734619\n",
      "Iteration: 71540, Loss: -162.460632324\n",
      "Iteration: 71550, Loss: -153.344024658\n",
      "Iteration: 71560, Loss: -141.789047241\n",
      "Iteration: 71570, Loss: -139.101318359\n",
      "Iteration: 71580, Loss: -163.80960083\n",
      "Iteration: 71590, Loss: -129.485916138\n",
      "Iteration: 71600, Loss: -158.159881592\n",
      "Iteration: 71610, Loss: -140.849700928\n",
      "Iteration: 71620, Loss: -135.644622803\n",
      "Iteration: 71630, Loss: -137.047393799\n",
      "Iteration: 71640, Loss: -135.420440674\n",
      "Iteration: 71650, Loss: -134.882461548\n",
      "Iteration: 71660, Loss: -125.167617798\n",
      "Iteration: 71670, Loss: -143.915893555\n",
      "Iteration: 71680, Loss: -137.161087036\n",
      "Iteration: 71690, Loss: -135.384490967\n",
      "Iteration: 71700, Loss: -122.872573853\n",
      "Iteration: 71710, Loss: -130.147399902\n",
      "Iteration: 71720, Loss: -144.227340698\n",
      "Iteration: 71730, Loss: -131.376983643\n",
      "Iteration: 71740, Loss: -140.54057312\n",
      "Iteration: 71750, Loss: -135.211090088\n",
      "Iteration: 71760, Loss: -134.887893677\n",
      "Iteration: 71770, Loss: -137.118850708\n",
      "Iteration: 71780, Loss: -133.145843506\n",
      "Iteration: 71790, Loss: -132.2940979\n",
      "Iteration: 71800, Loss: -149.630203247\n",
      "Iteration: 71810, Loss: -137.869354248\n",
      "Iteration: 71820, Loss: -148.820465088\n",
      "Iteration: 71830, Loss: -152.081176758\n",
      "Iteration: 71840, Loss: -144.354370117\n",
      "Iteration: 71850, Loss: -145.137237549\n",
      "Iteration: 71860, Loss: -143.878890991\n",
      "Iteration: 71870, Loss: -137.930053711\n",
      "Iteration: 71880, Loss: -132.068115234\n",
      "Iteration: 71890, Loss: -142.317977905\n",
      "Iteration: 71900, Loss: -138.589569092\n",
      "Iteration: 71910, Loss: -144.466003418\n",
      "Iteration: 71920, Loss: -126.226974487\n",
      "Iteration: 71930, Loss: -129.337966919\n",
      "Iteration: 71940, Loss: -142.202911377\n",
      "Iteration: 71950, Loss: -124.97467804\n",
      "Iteration: 71960, Loss: -142.292984009\n",
      "Iteration: 71970, Loss: -146.563201904\n",
      "Iteration: 71980, Loss: -130.478363037\n",
      "Iteration: 71990, Loss: -117.499557495\n",
      "Iteration: 72000, Loss: -140.537994385\n",
      "Iteration: 72010, Loss: -150.002471924\n",
      "Iteration: 72020, Loss: -144.340255737\n",
      "Iteration: 72030, Loss: -149.875427246\n",
      "Iteration: 72040, Loss: -135.31918335\n",
      "Iteration: 72050, Loss: -138.675613403\n",
      "Iteration: 72060, Loss: -148.947799683\n",
      "Iteration: 72070, Loss: -117.172966003\n",
      "Iteration: 72080, Loss: -140.074691772\n",
      "Iteration: 72090, Loss: -142.87449646\n",
      "Iteration: 72100, Loss: -128.70602417\n",
      "Iteration: 72110, Loss: -125.190383911\n",
      "Iteration: 72120, Loss: -131.840332031\n",
      "Iteration: 72130, Loss: -142.141296387\n",
      "Iteration: 72140, Loss: -143.302703857\n",
      "Iteration: 72150, Loss: -132.460678101\n",
      "Iteration: 72160, Loss: -152.916534424\n",
      "Iteration: 72170, Loss: -137.485931396\n",
      "Iteration: 72180, Loss: -147.223449707\n",
      "Iteration: 72190, Loss: -140.997131348\n",
      "Iteration: 72200, Loss: -131.756271362\n",
      "Iteration: 72210, Loss: -143.610977173\n",
      "Iteration: 72220, Loss: -133.621124268\n",
      "Iteration: 72230, Loss: -141.109786987\n",
      "Iteration: 72240, Loss: -145.184585571\n",
      "Iteration: 72250, Loss: -125.010726929\n",
      "Iteration: 72260, Loss: -140.771896362\n",
      "Iteration: 72270, Loss: -135.157333374\n",
      "Iteration: 72280, Loss: -143.396606445\n",
      "Iteration: 72290, Loss: -133.970932007\n",
      "Iteration: 72300, Loss: -123.844398499\n",
      "Iteration: 72310, Loss: -130.475830078\n",
      "Iteration: 72320, Loss: -114.158256531\n",
      "Iteration: 72330, Loss: -127.488319397\n",
      "Iteration: 72340, Loss: -135.854064941\n",
      "Iteration: 72350, Loss: -148.99848938\n",
      "Iteration: 72360, Loss: -132.721740723\n",
      "Iteration: 72370, Loss: -159.446487427\n",
      "Iteration: 72380, Loss: -127.795005798\n",
      "Iteration: 72390, Loss: -140.84967041\n",
      "Iteration: 72400, Loss: -128.799697876\n",
      "Iteration: 72410, Loss: -138.020629883\n",
      "Iteration: 72420, Loss: -140.117477417\n",
      "Iteration: 72430, Loss: -149.490600586\n",
      "Iteration: 72440, Loss: -136.596160889\n",
      "Iteration: 72450, Loss: -139.45602417\n",
      "Iteration: 72460, Loss: -134.859405518\n",
      "Iteration: 72470, Loss: -146.40524292\n",
      "Iteration: 72480, Loss: -125.234992981\n",
      "Iteration: 72490, Loss: -154.898651123\n",
      "Iteration: 72500, Loss: -134.427352905\n",
      "Iteration: 72510, Loss: -118.990936279\n",
      "Iteration: 72520, Loss: -144.559860229\n",
      "Iteration: 72530, Loss: -132.88684082\n",
      "Iteration: 72540, Loss: -128.261962891\n",
      "Iteration: 72550, Loss: -130.5546875\n",
      "Iteration: 72560, Loss: -144.013214111\n",
      "Iteration: 72570, Loss: -138.379547119\n",
      "Iteration: 72580, Loss: -131.202728271\n",
      "Iteration: 72590, Loss: -122.485809326\n",
      "Iteration: 72600, Loss: -148.926055908\n",
      "Iteration: 72610, Loss: -142.646026611\n",
      "Iteration: 72620, Loss: -135.819381714\n",
      "Iteration: 72630, Loss: -128.037841797\n",
      "Iteration: 72640, Loss: -149.95211792\n",
      "Iteration: 72650, Loss: -141.679916382\n",
      "Iteration: 72660, Loss: -127.143325806\n",
      "Iteration: 72670, Loss: -144.581314087\n",
      "Iteration: 72680, Loss: -140.846054077\n",
      "Iteration: 72690, Loss: -135.28125\n",
      "Iteration: 72700, Loss: -133.492156982\n",
      "Iteration: 72710, Loss: -149.588867188\n",
      "Iteration: 72720, Loss: -137.525802612\n",
      "Iteration: 72730, Loss: -136.519439697\n",
      "Iteration: 72740, Loss: -137.961959839\n",
      "Iteration: 72750, Loss: -132.721130371\n",
      "Iteration: 72760, Loss: -145.481079102\n",
      "Iteration: 72770, Loss: -149.970733643\n",
      "Iteration: 72780, Loss: -140.44078064\n",
      "Iteration: 72790, Loss: -144.046020508\n",
      "Iteration: 72800, Loss: -147.671783447\n",
      "Iteration: 72810, Loss: -137.07333374\n",
      "Iteration: 72820, Loss: -138.259048462\n",
      "Iteration: 72830, Loss: -140.97543335\n",
      "Iteration: 72840, Loss: -132.259002686\n",
      "Iteration: 72850, Loss: -135.28338623\n",
      "Iteration: 72860, Loss: -129.739990234\n",
      "Iteration: 72870, Loss: -130.248641968\n",
      "Iteration: 72880, Loss: -126.96686554\n",
      "Iteration: 72890, Loss: -147.138397217\n",
      "Iteration: 72900, Loss: -130.152740479\n",
      "Iteration: 72910, Loss: -146.26222229\n",
      "Iteration: 72920, Loss: -129.356552124\n",
      "Iteration: 72930, Loss: -149.29486084\n",
      "Iteration: 72940, Loss: -136.037796021\n",
      "Iteration: 72950, Loss: -141.72946167\n",
      "Iteration: 72960, Loss: -146.249145508\n",
      "Iteration: 72970, Loss: -139.638244629\n",
      "Iteration: 72980, Loss: -137.317504883\n",
      "Iteration: 72990, Loss: -142.901138306\n",
      "Iteration: 73000, Loss: -130.89944458\n",
      "Iteration: 73010, Loss: -148.901947021\n",
      "Iteration: 73020, Loss: -142.459869385\n",
      "Iteration: 73030, Loss: -147.288146973\n",
      "Iteration: 73040, Loss: -131.938644409\n",
      "Iteration: 73050, Loss: -149.458435059\n",
      "Iteration: 73060, Loss: -135.033294678\n",
      "Iteration: 73070, Loss: -125.162475586\n",
      "Iteration: 73080, Loss: -129.618286133\n",
      "Iteration: 73090, Loss: -134.194335938\n",
      "Iteration: 73100, Loss: -125.852272034\n",
      "Iteration: 73110, Loss: -153.577850342\n",
      "Iteration: 73120, Loss: -134.228439331\n",
      "Iteration: 73130, Loss: -132.703720093\n",
      "Iteration: 73140, Loss: -143.587554932\n",
      "Iteration: 73150, Loss: -137.177139282\n",
      "Iteration: 73160, Loss: -133.987487793\n",
      "Iteration: 73170, Loss: -124.295303345\n",
      "Iteration: 73180, Loss: -127.452651978\n",
      "Iteration: 73190, Loss: -129.723754883\n",
      "Iteration: 73200, Loss: -139.036331177\n",
      "Iteration: 73210, Loss: -154.329162598\n",
      "Iteration: 73220, Loss: -155.275161743\n",
      "Iteration: 73230, Loss: -146.129592896\n",
      "Iteration: 73240, Loss: -142.495071411\n",
      "Iteration: 73250, Loss: -140.397415161\n",
      "Iteration: 73260, Loss: -145.111175537\n",
      "Iteration: 73270, Loss: -141.714447021\n",
      "Iteration: 73280, Loss: -138.783172607\n",
      "Iteration: 73290, Loss: -142.256469727\n",
      "Iteration: 73300, Loss: -142.563613892\n",
      "Iteration: 73310, Loss: -143.295654297\n",
      "Iteration: 73320, Loss: -143.809860229\n",
      "Iteration: 73330, Loss: -129.961624146\n",
      "Iteration: 73340, Loss: -141.299102783\n",
      "Iteration: 73350, Loss: -137.035705566\n",
      "Iteration: 73360, Loss: -132.341949463\n",
      "Iteration: 73370, Loss: -156.860168457\n",
      "Iteration: 73380, Loss: -133.639556885\n",
      "Iteration: 73390, Loss: -136.559265137\n",
      "Iteration: 73400, Loss: -123.945251465\n",
      "Iteration: 73410, Loss: -138.941955566\n",
      "Iteration: 73420, Loss: -143.594055176\n",
      "Iteration: 73430, Loss: -145.095275879\n",
      "Iteration: 73440, Loss: -144.38458252\n",
      "Iteration: 73450, Loss: -138.563568115\n",
      "Iteration: 73460, Loss: -131.511413574\n",
      "Iteration: 73470, Loss: -130.148849487\n",
      "Iteration: 73480, Loss: -145.540939331\n",
      "Iteration: 73490, Loss: -135.231750488\n",
      "Iteration: 73500, Loss: -125.859039307\n",
      "Iteration: 73510, Loss: -132.736724854\n",
      "Iteration: 73520, Loss: -144.116470337\n",
      "Iteration: 73530, Loss: -148.8777771\n",
      "Iteration: 73540, Loss: -148.751525879\n",
      "Iteration: 73550, Loss: -128.787506104\n",
      "Iteration: 73560, Loss: -139.112091064\n",
      "Iteration: 73570, Loss: -135.429595947\n",
      "Iteration: 73580, Loss: -152.594116211\n",
      "Iteration: 73590, Loss: -131.111663818\n",
      "Iteration: 73600, Loss: -140.034240723\n",
      "Iteration: 73610, Loss: -146.353149414\n",
      "Iteration: 73620, Loss: -151.971542358\n",
      "Iteration: 73630, Loss: -141.741378784\n",
      "Iteration: 73640, Loss: -121.465072632\n",
      "Iteration: 73650, Loss: -124.638656616\n",
      "Iteration: 73660, Loss: -122.099662781\n",
      "Iteration: 73670, Loss: -141.267242432\n",
      "Iteration: 73680, Loss: -143.422637939\n",
      "Iteration: 73690, Loss: -143.820343018\n",
      "Iteration: 73700, Loss: -135.781890869\n",
      "Iteration: 73710, Loss: -141.783599854\n",
      "Iteration: 73720, Loss: -144.24597168\n",
      "Iteration: 73730, Loss: -140.931106567\n",
      "Iteration: 73740, Loss: -137.352020264\n",
      "Iteration: 73750, Loss: -141.500396729\n",
      "Iteration: 73760, Loss: -142.399047852\n",
      "Iteration: 73770, Loss: -146.193099976\n",
      "Iteration: 73780, Loss: -143.290863037\n",
      "Iteration: 73790, Loss: -141.96270752\n",
      "Iteration: 73800, Loss: -126.181777954\n",
      "Iteration: 73810, Loss: -122.432220459\n",
      "Iteration: 73820, Loss: -149.558502197\n",
      "Iteration: 73830, Loss: -139.442382812\n",
      "Iteration: 73840, Loss: -133.938644409\n",
      "Iteration: 73850, Loss: -134.725509644\n",
      "Iteration: 73860, Loss: -128.593093872\n",
      "Iteration: 73870, Loss: -147.139373779\n",
      "Iteration: 73880, Loss: -132.063369751\n",
      "Iteration: 73890, Loss: -144.897445679\n",
      "Iteration: 73900, Loss: -143.300796509\n",
      "Iteration: 73910, Loss: -137.911270142\n",
      "Iteration: 73920, Loss: -138.074737549\n",
      "Iteration: 73930, Loss: -126.429550171\n",
      "Iteration: 73940, Loss: -149.254196167\n",
      "Iteration: 73950, Loss: -138.887283325\n",
      "Iteration: 73960, Loss: -139.366958618\n",
      "Iteration: 73970, Loss: -127.072174072\n",
      "Iteration: 73980, Loss: -134.90574646\n",
      "Iteration: 73990, Loss: -142.381820679\n",
      "Iteration: 74000, Loss: -131.297302246\n",
      "Iteration: 74010, Loss: -134.611984253\n",
      "Iteration: 74020, Loss: -137.718505859\n",
      "Iteration: 74030, Loss: -157.779495239\n",
      "Iteration: 74040, Loss: -146.889602661\n",
      "Iteration: 74050, Loss: -135.325164795\n",
      "Iteration: 74060, Loss: -153.164154053\n",
      "Iteration: 74070, Loss: -133.495788574\n",
      "Iteration: 74080, Loss: -119.242698669\n",
      "Iteration: 74090, Loss: -131.562286377\n",
      "Iteration: 74100, Loss: -137.256469727\n",
      "Iteration: 74110, Loss: -141.819320679\n",
      "Iteration: 74120, Loss: -137.422149658\n",
      "Iteration: 74130, Loss: -137.14503479\n",
      "Iteration: 74140, Loss: -135.584106445\n",
      "Iteration: 74150, Loss: -132.880554199\n",
      "Iteration: 74160, Loss: -134.84538269\n",
      "Iteration: 74170, Loss: -131.613311768\n",
      "Iteration: 74180, Loss: -146.63381958\n",
      "Iteration: 74190, Loss: -138.293838501\n",
      "Iteration: 74200, Loss: -151.912780762\n",
      "Iteration: 74210, Loss: -147.41293335\n",
      "Iteration: 74220, Loss: -137.744644165\n",
      "Iteration: 74230, Loss: -131.76385498\n",
      "Iteration: 74240, Loss: -133.946395874\n",
      "Iteration: 74250, Loss: -127.771965027\n",
      "Iteration: 74260, Loss: -136.373779297\n",
      "Iteration: 74270, Loss: -150.516693115\n",
      "Iteration: 74280, Loss: -137.862976074\n",
      "Iteration: 74290, Loss: -136.964279175\n",
      "Iteration: 74300, Loss: -152.344467163\n",
      "Iteration: 74310, Loss: -137.765533447\n",
      "Iteration: 74320, Loss: -132.346481323\n",
      "Iteration: 74330, Loss: -133.956542969\n",
      "Iteration: 74340, Loss: -143.805175781\n",
      "Iteration: 74350, Loss: -139.254714966\n",
      "Iteration: 74360, Loss: -133.631530762\n",
      "Iteration: 74370, Loss: -140.665283203\n",
      "Iteration: 74380, Loss: -137.686767578\n",
      "Iteration: 74390, Loss: -146.536560059\n",
      "Iteration: 74400, Loss: -138.671417236\n",
      "Iteration: 74410, Loss: -124.635643005\n",
      "Iteration: 74420, Loss: -145.831558228\n",
      "Iteration: 74430, Loss: -138.165130615\n",
      "Iteration: 74440, Loss: -138.506149292\n",
      "Iteration: 74450, Loss: -147.385986328\n",
      "Iteration: 74460, Loss: -150.190170288\n",
      "Iteration: 74470, Loss: -149.025283813\n",
      "Iteration: 74480, Loss: -146.227096558\n",
      "Iteration: 74490, Loss: -138.272003174\n",
      "Iteration: 74500, Loss: -147.935089111\n",
      "Iteration: 74510, Loss: -128.194885254\n",
      "Iteration: 74520, Loss: -116.07950592\n",
      "Iteration: 74530, Loss: -128.544784546\n",
      "Iteration: 74540, Loss: -147.450332642\n",
      "Iteration: 74550, Loss: -132.747055054\n",
      "Iteration: 74560, Loss: -141.377761841\n",
      "Iteration: 74570, Loss: -147.565200806\n",
      "Iteration: 74580, Loss: -146.142669678\n",
      "Iteration: 74590, Loss: -123.793983459\n",
      "Iteration: 74600, Loss: -146.76864624\n",
      "Iteration: 74610, Loss: -141.050537109\n",
      "Iteration: 74620, Loss: -158.266769409\n",
      "Iteration: 74630, Loss: -136.785491943\n",
      "Iteration: 74640, Loss: -136.307342529\n",
      "Iteration: 74650, Loss: -136.33140564\n",
      "Iteration: 74660, Loss: -141.965026855\n",
      "Iteration: 74670, Loss: -129.29019165\n",
      "Iteration: 74680, Loss: -130.823699951\n",
      "Iteration: 74690, Loss: -140.342208862\n",
      "Iteration: 74700, Loss: -137.423797607\n",
      "Iteration: 74710, Loss: -128.743560791\n",
      "Iteration: 74720, Loss: -128.449584961\n",
      "Iteration: 74730, Loss: -137.524291992\n",
      "Iteration: 74740, Loss: -137.85736084\n",
      "Iteration: 74750, Loss: -138.145507812\n",
      "Iteration: 74760, Loss: -137.992401123\n",
      "Iteration: 74770, Loss: -135.961853027\n",
      "Iteration: 74780, Loss: -147.101333618\n",
      "Iteration: 74790, Loss: -127.481163025\n",
      "Iteration: 74800, Loss: -143.259780884\n",
      "Iteration: 74810, Loss: -143.918075562\n",
      "Iteration: 74820, Loss: -125.996520996\n",
      "Iteration: 74830, Loss: -153.483825684\n",
      "Iteration: 74840, Loss: -128.830383301\n",
      "Iteration: 74850, Loss: -129.829437256\n",
      "Iteration: 74860, Loss: -140.287017822\n",
      "Iteration: 74870, Loss: -144.485107422\n",
      "Iteration: 74880, Loss: -129.592971802\n",
      "Iteration: 74890, Loss: -142.68057251\n",
      "Iteration: 74900, Loss: -117.330123901\n",
      "Iteration: 74910, Loss: -129.022827148\n",
      "Iteration: 74920, Loss: -143.752227783\n",
      "Iteration: 74930, Loss: -135.302276611\n",
      "Iteration: 74940, Loss: -138.458053589\n",
      "Iteration: 74950, Loss: -143.176223755\n",
      "Iteration: 74960, Loss: -124.00994873\n",
      "Iteration: 74970, Loss: -121.920951843\n",
      "Iteration: 74980, Loss: -137.547851562\n",
      "Iteration: 74990, Loss: -142.402420044\n",
      "Iteration: 75000, Loss: -137.836334229\n",
      "Iteration: 75010, Loss: -130.288070679\n",
      "Iteration: 75020, Loss: -124.906181335\n",
      "Iteration: 75030, Loss: -131.869613647\n",
      "Iteration: 75040, Loss: -131.665969849\n",
      "Iteration: 75050, Loss: -138.458343506\n",
      "Iteration: 75060, Loss: -130.305206299\n",
      "Iteration: 75070, Loss: -120.069572449\n",
      "Iteration: 75080, Loss: -134.780670166\n",
      "Iteration: 75090, Loss: -132.282333374\n",
      "Iteration: 75100, Loss: -134.205596924\n",
      "Iteration: 75110, Loss: -131.810241699\n",
      "Iteration: 75120, Loss: -138.11541748\n",
      "Iteration: 75130, Loss: -129.718566895\n",
      "Iteration: 75140, Loss: -152.385742188\n",
      "Iteration: 75150, Loss: -133.727310181\n",
      "Iteration: 75160, Loss: -140.54397583\n",
      "Iteration: 75170, Loss: -142.063140869\n",
      "Iteration: 75180, Loss: -147.581481934\n",
      "Iteration: 75190, Loss: -143.8956604\n",
      "Iteration: 75200, Loss: -137.322753906\n",
      "Iteration: 75210, Loss: -136.206710815\n",
      "Iteration: 75220, Loss: -136.230194092\n",
      "Iteration: 75230, Loss: -140.277526855\n",
      "Iteration: 75240, Loss: -133.626861572\n",
      "Iteration: 75250, Loss: -135.92086792\n",
      "Iteration: 75260, Loss: -137.107269287\n",
      "Iteration: 75270, Loss: -149.519927979\n",
      "Iteration: 75280, Loss: -127.808601379\n",
      "Iteration: 75290, Loss: -129.006835938\n",
      "Iteration: 75300, Loss: -120.495162964\n",
      "Iteration: 75310, Loss: -136.666000366\n",
      "Iteration: 75320, Loss: -133.097625732\n",
      "Iteration: 75330, Loss: -137.302825928\n",
      "Iteration: 75340, Loss: -139.748855591\n",
      "Iteration: 75350, Loss: -147.510681152\n",
      "Iteration: 75360, Loss: -119.570556641\n",
      "Iteration: 75370, Loss: -135.49395752\n",
      "Iteration: 75380, Loss: -134.916137695\n",
      "Iteration: 75390, Loss: -130.43447876\n",
      "Iteration: 75400, Loss: -138.219360352\n",
      "Iteration: 75410, Loss: -134.653717041\n",
      "Iteration: 75420, Loss: -128.953521729\n",
      "Iteration: 75430, Loss: -130.118453979\n",
      "Iteration: 75440, Loss: -126.607917786\n",
      "Iteration: 75450, Loss: -120.145004272\n",
      "Iteration: 75460, Loss: -133.623504639\n",
      "Iteration: 75470, Loss: -130.948028564\n",
      "Iteration: 75480, Loss: -123.352737427\n",
      "Iteration: 75490, Loss: -126.787986755\n",
      "Iteration: 75500, Loss: -155.703552246\n",
      "Iteration: 75510, Loss: -139.349121094\n",
      "Iteration: 75520, Loss: -140.855926514\n",
      "Iteration: 75530, Loss: -136.241973877\n",
      "Iteration: 75540, Loss: -134.772857666\n",
      "Iteration: 75550, Loss: -122.142715454\n",
      "Iteration: 75560, Loss: -122.768066406\n",
      "Iteration: 75570, Loss: -130.982131958\n",
      "Iteration: 75580, Loss: -127.696777344\n",
      "Iteration: 75590, Loss: -134.793457031\n",
      "Iteration: 75600, Loss: -119.705947876\n",
      "Iteration: 75610, Loss: -137.58505249\n",
      "Iteration: 75620, Loss: -129.774749756\n",
      "Iteration: 75630, Loss: -149.33404541\n",
      "Iteration: 75640, Loss: -160.116516113\n",
      "Iteration: 75650, Loss: -134.434906006\n",
      "Iteration: 75660, Loss: -129.292129517\n",
      "Iteration: 75670, Loss: -132.127410889\n",
      "Iteration: 75680, Loss: -143.424942017\n",
      "Iteration: 75690, Loss: -140.584609985\n",
      "Iteration: 75700, Loss: -147.101287842\n",
      "Iteration: 75710, Loss: -142.152130127\n",
      "Iteration: 75720, Loss: -148.704284668\n",
      "Iteration: 75730, Loss: -133.677185059\n",
      "Iteration: 75740, Loss: -126.681350708\n",
      "Iteration: 75750, Loss: -140.295059204\n",
      "Iteration: 75760, Loss: -140.581863403\n",
      "Iteration: 75770, Loss: -135.886260986\n",
      "Iteration: 75780, Loss: -139.533996582\n",
      "Iteration: 75790, Loss: -142.644577026\n",
      "Iteration: 75800, Loss: -132.653030396\n",
      "Iteration: 75810, Loss: -144.116790771\n",
      "Iteration: 75820, Loss: -142.925979614\n",
      "Iteration: 75830, Loss: -131.385620117\n",
      "Iteration: 75840, Loss: -135.425994873\n",
      "Iteration: 75850, Loss: -141.611068726\n",
      "Iteration: 75860, Loss: -145.678894043\n",
      "Iteration: 75870, Loss: -134.40814209\n",
      "Iteration: 75880, Loss: -137.410614014\n",
      "Iteration: 75890, Loss: -149.727798462\n",
      "Iteration: 75900, Loss: -133.55909729\n",
      "Iteration: 75910, Loss: -129.129577637\n",
      "Iteration: 75920, Loss: -141.345275879\n",
      "Iteration: 75930, Loss: -149.181411743\n",
      "Iteration: 75940, Loss: -130.324234009\n",
      "Iteration: 75950, Loss: -125.937919617\n",
      "Iteration: 75960, Loss: -139.532989502\n",
      "Iteration: 75970, Loss: -147.985290527\n",
      "Iteration: 75980, Loss: -135.489059448\n",
      "Iteration: 75990, Loss: -147.608978271\n",
      "Iteration: 76000, Loss: -142.536468506\n",
      "Iteration: 76010, Loss: -147.442062378\n",
      "Iteration: 76020, Loss: -146.754669189\n",
      "Iteration: 76030, Loss: -131.904571533\n",
      "Iteration: 76040, Loss: -135.097595215\n",
      "Iteration: 76050, Loss: -141.574462891\n",
      "Iteration: 76060, Loss: -137.667175293\n",
      "Iteration: 76070, Loss: -121.867210388\n",
      "Iteration: 76080, Loss: -132.052383423\n",
      "Iteration: 76090, Loss: -143.254898071\n",
      "Iteration: 76100, Loss: -138.258163452\n",
      "Iteration: 76110, Loss: -135.562316895\n",
      "Iteration: 76120, Loss: -129.523239136\n",
      "Iteration: 76130, Loss: -146.482971191\n",
      "Iteration: 76140, Loss: -135.70614624\n",
      "Iteration: 76150, Loss: -142.063049316\n",
      "Iteration: 76160, Loss: -144.971160889\n",
      "Iteration: 76170, Loss: -147.87197876\n",
      "Iteration: 76180, Loss: -138.477325439\n",
      "Iteration: 76190, Loss: -139.506988525\n",
      "Iteration: 76200, Loss: -129.556091309\n",
      "Iteration: 76210, Loss: -131.735992432\n",
      "Iteration: 76220, Loss: -140.567626953\n",
      "Iteration: 76230, Loss: -137.096542358\n",
      "Iteration: 76240, Loss: -138.122756958\n",
      "Iteration: 76250, Loss: -141.242889404\n",
      "Iteration: 76260, Loss: -137.737289429\n",
      "Iteration: 76270, Loss: -140.577392578\n",
      "Iteration: 76280, Loss: -132.400726318\n",
      "Iteration: 76290, Loss: -151.494674683\n",
      "Iteration: 76300, Loss: -141.071090698\n",
      "Iteration: 76310, Loss: -127.373535156\n",
      "Iteration: 76320, Loss: -137.086257935\n",
      "Iteration: 76330, Loss: -124.941146851\n",
      "Iteration: 76340, Loss: -133.431732178\n",
      "Iteration: 76350, Loss: -138.586196899\n",
      "Iteration: 76360, Loss: -128.072189331\n",
      "Iteration: 76370, Loss: -136.098846436\n",
      "Iteration: 76380, Loss: -134.215698242\n",
      "Iteration: 76390, Loss: -147.706268311\n",
      "Iteration: 76400, Loss: -147.456314087\n",
      "Iteration: 76410, Loss: -141.263183594\n",
      "Iteration: 76420, Loss: -133.947906494\n",
      "Iteration: 76430, Loss: -141.169448853\n",
      "Iteration: 76440, Loss: -128.376983643\n",
      "Iteration: 76450, Loss: -132.932388306\n",
      "Iteration: 76460, Loss: -144.007720947\n",
      "Iteration: 76470, Loss: -135.275009155\n",
      "Iteration: 76480, Loss: -136.231994629\n",
      "Iteration: 76490, Loss: -138.698959351\n",
      "Iteration: 76500, Loss: -138.890884399\n",
      "Iteration: 76510, Loss: -131.439056396\n",
      "Iteration: 76520, Loss: -132.685409546\n",
      "Iteration: 76530, Loss: -146.559661865\n",
      "Iteration: 76540, Loss: -143.419128418\n",
      "Iteration: 76550, Loss: -121.106208801\n",
      "Iteration: 76560, Loss: -135.259429932\n",
      "Iteration: 76570, Loss: -146.563140869\n",
      "Iteration: 76580, Loss: -148.464538574\n",
      "Iteration: 76590, Loss: -132.269104004\n",
      "Iteration: 76600, Loss: -140.438034058\n",
      "Iteration: 76610, Loss: -145.593048096\n",
      "Iteration: 76620, Loss: -134.752929688\n",
      "Iteration: 76630, Loss: -142.478027344\n",
      "Iteration: 76640, Loss: -126.40965271\n",
      "Iteration: 76650, Loss: -141.198059082\n",
      "Iteration: 76660, Loss: -125.816497803\n",
      "Iteration: 76670, Loss: -145.616668701\n",
      "Iteration: 76680, Loss: -129.868148804\n",
      "Iteration: 76690, Loss: -132.079040527\n",
      "Iteration: 76700, Loss: -134.553771973\n",
      "Iteration: 76710, Loss: -130.785949707\n",
      "Iteration: 76720, Loss: -132.621414185\n",
      "Iteration: 76730, Loss: -156.158752441\n",
      "Iteration: 76740, Loss: -128.442016602\n",
      "Iteration: 76750, Loss: -143.954101562\n",
      "Iteration: 76760, Loss: -139.647460938\n",
      "Iteration: 76770, Loss: -132.913146973\n",
      "Iteration: 76780, Loss: -126.237625122\n",
      "Iteration: 76790, Loss: -134.330993652\n",
      "Iteration: 76800, Loss: -138.744049072\n",
      "Iteration: 76810, Loss: -148.979644775\n",
      "Iteration: 76820, Loss: -145.784973145\n",
      "Iteration: 76830, Loss: -131.782165527\n",
      "Iteration: 76840, Loss: -127.42124939\n",
      "Iteration: 76850, Loss: -126.537506104\n",
      "Iteration: 76860, Loss: -154.286605835\n",
      "Iteration: 76870, Loss: -149.783721924\n",
      "Iteration: 76880, Loss: -134.875946045\n",
      "Iteration: 76890, Loss: -128.770263672\n",
      "Iteration: 76900, Loss: -130.544998169\n",
      "Iteration: 76910, Loss: -141.670166016\n",
      "Iteration: 76920, Loss: -137.256164551\n",
      "Iteration: 76930, Loss: -137.721710205\n",
      "Iteration: 76940, Loss: -138.989944458\n",
      "Iteration: 76950, Loss: -127.860549927\n",
      "Iteration: 76960, Loss: -148.203552246\n",
      "Iteration: 76970, Loss: -132.809753418\n",
      "Iteration: 76980, Loss: -137.740112305\n",
      "Iteration: 76990, Loss: -142.89932251\n",
      "Iteration: 77000, Loss: -141.571182251\n",
      "Iteration: 77010, Loss: -138.958587646\n",
      "Iteration: 77020, Loss: -129.691467285\n",
      "Iteration: 77030, Loss: -140.151000977\n",
      "Iteration: 77040, Loss: -145.105010986\n",
      "Iteration: 77050, Loss: -132.287979126\n",
      "Iteration: 77060, Loss: -148.420898438\n",
      "Iteration: 77070, Loss: -143.871627808\n",
      "Iteration: 77080, Loss: -137.090713501\n",
      "Iteration: 77090, Loss: -133.609924316\n",
      "Iteration: 77100, Loss: -146.527618408\n",
      "Iteration: 77110, Loss: -134.537216187\n",
      "Iteration: 77120, Loss: -145.783660889\n",
      "Iteration: 77130, Loss: -134.533340454\n",
      "Iteration: 77140, Loss: -123.89831543\n",
      "Iteration: 77150, Loss: -133.860015869\n",
      "Iteration: 77160, Loss: -123.404678345\n",
      "Iteration: 77170, Loss: -140.510177612\n",
      "Iteration: 77180, Loss: -138.365692139\n",
      "Iteration: 77190, Loss: -144.948486328\n",
      "Iteration: 77200, Loss: -133.215530396\n",
      "Iteration: 77210, Loss: -137.886230469\n",
      "Iteration: 77220, Loss: -128.973800659\n",
      "Iteration: 77230, Loss: -139.338928223\n",
      "Iteration: 77240, Loss: -139.893707275\n",
      "Iteration: 77250, Loss: -134.088470459\n",
      "Iteration: 77260, Loss: -149.685211182\n",
      "Iteration: 77270, Loss: -126.384155273\n",
      "Iteration: 77280, Loss: -144.604980469\n",
      "Iteration: 77290, Loss: -129.016983032\n",
      "Iteration: 77300, Loss: -135.390075684\n",
      "Iteration: 77310, Loss: -146.888442993\n",
      "Iteration: 77320, Loss: -138.637969971\n",
      "Iteration: 77330, Loss: -146.850143433\n",
      "Iteration: 77340, Loss: -143.657058716\n",
      "Iteration: 77350, Loss: -138.930755615\n",
      "Iteration: 77360, Loss: -130.735733032\n",
      "Iteration: 77370, Loss: -144.7681427\n",
      "Iteration: 77380, Loss: -132.993209839\n",
      "Iteration: 77390, Loss: -146.530639648\n",
      "Iteration: 77400, Loss: -145.211639404\n",
      "Iteration: 77410, Loss: -142.82244873\n",
      "Iteration: 77420, Loss: -138.224731445\n",
      "Iteration: 77430, Loss: -124.721176147\n",
      "Iteration: 77440, Loss: -133.552978516\n",
      "Iteration: 77450, Loss: -124.083511353\n",
      "Iteration: 77460, Loss: -122.46774292\n",
      "Iteration: 77470, Loss: -141.515151978\n",
      "Iteration: 77480, Loss: -140.760650635\n",
      "Iteration: 77490, Loss: -135.333129883\n",
      "Iteration: 77500, Loss: -143.10295105\n",
      "Iteration: 77510, Loss: -145.746246338\n",
      "Iteration: 77520, Loss: -136.139846802\n",
      "Iteration: 77530, Loss: -136.473052979\n",
      "Iteration: 77540, Loss: -131.539749146\n",
      "Iteration: 77550, Loss: -130.420150757\n",
      "Iteration: 77560, Loss: -143.88470459\n",
      "Iteration: 77570, Loss: -134.119415283\n",
      "Iteration: 77580, Loss: -161.255493164\n",
      "Iteration: 77590, Loss: -138.061981201\n",
      "Iteration: 77600, Loss: -119.761505127\n",
      "Iteration: 77610, Loss: -142.470245361\n",
      "Iteration: 77620, Loss: -140.19468689\n",
      "Iteration: 77630, Loss: -125.666168213\n",
      "Iteration: 77640, Loss: -137.167633057\n",
      "Iteration: 77650, Loss: -146.887176514\n",
      "Iteration: 77660, Loss: -148.234664917\n",
      "Iteration: 77670, Loss: -138.637237549\n",
      "Iteration: 77680, Loss: -144.729949951\n",
      "Iteration: 77690, Loss: -124.109527588\n",
      "Iteration: 77700, Loss: -123.934295654\n",
      "Iteration: 77710, Loss: -134.861557007\n",
      "Iteration: 77720, Loss: -123.676376343\n",
      "Iteration: 77730, Loss: -140.141860962\n",
      "Iteration: 77740, Loss: -134.67288208\n",
      "Iteration: 77750, Loss: -131.078643799\n",
      "Iteration: 77760, Loss: -130.751525879\n",
      "Iteration: 77770, Loss: -137.837890625\n",
      "Iteration: 77780, Loss: -130.499237061\n",
      "Iteration: 77790, Loss: -151.302032471\n",
      "Iteration: 77800, Loss: -141.49899292\n",
      "Iteration: 77810, Loss: -136.847473145\n",
      "Iteration: 77820, Loss: -158.81048584\n",
      "Iteration: 77830, Loss: -153.156616211\n",
      "Iteration: 77840, Loss: -139.273956299\n",
      "Iteration: 77850, Loss: -138.586044312\n",
      "Iteration: 77860, Loss: -142.092041016\n",
      "Iteration: 77870, Loss: -134.860671997\n",
      "Iteration: 77880, Loss: -123.024429321\n",
      "Iteration: 77890, Loss: -134.118453979\n",
      "Iteration: 77900, Loss: -130.811935425\n",
      "Iteration: 77910, Loss: -133.877593994\n",
      "Iteration: 77920, Loss: -114.430038452\n",
      "Iteration: 77930, Loss: -134.929077148\n",
      "Iteration: 77940, Loss: -143.234649658\n",
      "Iteration: 77950, Loss: -142.590820312\n",
      "Iteration: 77960, Loss: -140.308898926\n",
      "Iteration: 77970, Loss: -149.770721436\n",
      "Iteration: 77980, Loss: -141.202270508\n",
      "Iteration: 77990, Loss: -127.742332458\n",
      "Iteration: 78000, Loss: -132.308578491\n",
      "Iteration: 78010, Loss: -131.933990479\n",
      "Iteration: 78020, Loss: -141.020233154\n",
      "Iteration: 78030, Loss: -142.163833618\n",
      "Iteration: 78040, Loss: -128.680480957\n",
      "Iteration: 78050, Loss: -135.927474976\n",
      "Iteration: 78060, Loss: -128.87210083\n",
      "Iteration: 78070, Loss: -137.544708252\n",
      "Iteration: 78080, Loss: -143.74597168\n",
      "Iteration: 78090, Loss: -144.775024414\n",
      "Iteration: 78100, Loss: -148.561752319\n",
      "Iteration: 78110, Loss: -132.32333374\n",
      "Iteration: 78120, Loss: -132.536697388\n",
      "Iteration: 78130, Loss: -147.260467529\n",
      "Iteration: 78140, Loss: -125.958267212\n",
      "Iteration: 78150, Loss: -147.618148804\n",
      "Iteration: 78160, Loss: -130.514404297\n",
      "Iteration: 78170, Loss: -151.24697876\n",
      "Iteration: 78180, Loss: -132.304229736\n",
      "Iteration: 78190, Loss: -135.665512085\n",
      "Iteration: 78200, Loss: -125.603240967\n",
      "Iteration: 78210, Loss: -140.274017334\n",
      "Iteration: 78220, Loss: -130.422439575\n",
      "Iteration: 78230, Loss: -142.404418945\n",
      "Iteration: 78240, Loss: -143.092041016\n",
      "Iteration: 78250, Loss: -131.872192383\n",
      "Iteration: 78260, Loss: -137.747055054\n",
      "Iteration: 78270, Loss: -124.077827454\n",
      "Iteration: 78280, Loss: -131.874176025\n",
      "Iteration: 78290, Loss: -156.566345215\n",
      "Iteration: 78300, Loss: -131.484909058\n",
      "Iteration: 78310, Loss: -129.621414185\n",
      "Iteration: 78320, Loss: -146.139282227\n",
      "Iteration: 78330, Loss: -129.168731689\n",
      "Iteration: 78340, Loss: -123.281265259\n",
      "Iteration: 78350, Loss: -130.50201416\n",
      "Iteration: 78360, Loss: -129.015991211\n",
      "Iteration: 78370, Loss: -125.894340515\n",
      "Iteration: 78380, Loss: -151.014053345\n",
      "Iteration: 78390, Loss: -141.942382812\n",
      "Iteration: 78400, Loss: -140.921691895\n",
      "Iteration: 78410, Loss: -127.123794556\n",
      "Iteration: 78420, Loss: -130.1222229\n",
      "Iteration: 78430, Loss: -144.507232666\n",
      "Iteration: 78440, Loss: -145.319534302\n",
      "Iteration: 78450, Loss: -137.523391724\n",
      "Iteration: 78460, Loss: -157.335205078\n",
      "Iteration: 78470, Loss: -141.34072876\n",
      "Iteration: 78480, Loss: -148.24055481\n",
      "Iteration: 78490, Loss: -128.90612793\n",
      "Iteration: 78500, Loss: -146.016662598\n",
      "Iteration: 78510, Loss: -137.770446777\n",
      "Iteration: 78520, Loss: -127.950370789\n",
      "Iteration: 78530, Loss: -131.593353271\n",
      "Iteration: 78540, Loss: -137.623840332\n",
      "Iteration: 78550, Loss: -131.36807251\n",
      "Iteration: 78560, Loss: -134.526412964\n",
      "Iteration: 78570, Loss: -122.653251648\n",
      "Iteration: 78580, Loss: -140.64465332\n",
      "Iteration: 78590, Loss: -135.610473633\n",
      "Iteration: 78600, Loss: -129.896606445\n",
      "Iteration: 78610, Loss: -145.617431641\n",
      "Iteration: 78620, Loss: -126.768577576\n",
      "Iteration: 78630, Loss: -141.090332031\n",
      "Iteration: 78640, Loss: -129.848114014\n",
      "Iteration: 78650, Loss: -150.702850342\n",
      "Iteration: 78660, Loss: -136.155273438\n",
      "Iteration: 78670, Loss: -131.516021729\n",
      "Iteration: 78680, Loss: -136.804321289\n",
      "Iteration: 78690, Loss: -138.055862427\n",
      "Iteration: 78700, Loss: -155.328018188\n",
      "Iteration: 78710, Loss: -136.944671631\n",
      "Iteration: 78720, Loss: -139.203582764\n",
      "Iteration: 78730, Loss: -133.668106079\n",
      "Iteration: 78740, Loss: -137.810913086\n",
      "Iteration: 78750, Loss: -135.183639526\n",
      "Iteration: 78760, Loss: -124.689712524\n",
      "Iteration: 78770, Loss: -124.722396851\n",
      "Iteration: 78780, Loss: -135.571899414\n",
      "Iteration: 78790, Loss: -122.557289124\n",
      "Iteration: 78800, Loss: -140.451934814\n",
      "Iteration: 78810, Loss: -132.288024902\n",
      "Iteration: 78820, Loss: -128.020751953\n",
      "Iteration: 78830, Loss: -133.698303223\n",
      "Iteration: 78840, Loss: -144.016693115\n",
      "Iteration: 78850, Loss: -128.423416138\n",
      "Iteration: 78860, Loss: -132.153259277\n",
      "Iteration: 78870, Loss: -127.917312622\n",
      "Iteration: 78880, Loss: -131.917510986\n",
      "Iteration: 78890, Loss: -136.543167114\n",
      "Iteration: 78900, Loss: -134.073471069\n",
      "Iteration: 78910, Loss: -133.372192383\n",
      "Iteration: 78920, Loss: -139.377487183\n",
      "Iteration: 78930, Loss: -154.448638916\n",
      "Iteration: 78940, Loss: -149.894165039\n",
      "Iteration: 78950, Loss: -127.7682724\n",
      "Iteration: 78960, Loss: -141.274841309\n",
      "Iteration: 78970, Loss: -125.53074646\n",
      "Iteration: 78980, Loss: -138.589126587\n",
      "Iteration: 78990, Loss: -130.289215088\n",
      "Iteration: 79000, Loss: -131.145858765\n",
      "Iteration: 79010, Loss: -137.538909912\n",
      "Iteration: 79020, Loss: -144.292755127\n",
      "Iteration: 79030, Loss: -131.438018799\n",
      "Iteration: 79040, Loss: -142.252197266\n",
      "Iteration: 79050, Loss: -150.856063843\n",
      "Iteration: 79060, Loss: -136.903274536\n",
      "Iteration: 79070, Loss: -147.984191895\n",
      "Iteration: 79080, Loss: -141.710601807\n",
      "Iteration: 79090, Loss: -143.650268555\n",
      "Iteration: 79100, Loss: -146.036026001\n",
      "Iteration: 79110, Loss: -136.030929565\n",
      "Iteration: 79120, Loss: -127.846328735\n",
      "Iteration: 79130, Loss: -138.608779907\n",
      "Iteration: 79140, Loss: -129.807159424\n",
      "Iteration: 79150, Loss: -125.018112183\n",
      "Iteration: 79160, Loss: -146.537261963\n",
      "Iteration: 79170, Loss: -133.99772644\n",
      "Iteration: 79180, Loss: -139.720825195\n",
      "Iteration: 79190, Loss: -139.840408325\n",
      "Iteration: 79200, Loss: -132.868133545\n",
      "Iteration: 79210, Loss: -143.18447876\n",
      "Iteration: 79220, Loss: -134.26159668\n",
      "Iteration: 79230, Loss: -137.49446106\n",
      "Iteration: 79240, Loss: -152.291030884\n",
      "Iteration: 79250, Loss: -132.399932861\n",
      "Iteration: 79260, Loss: -132.056091309\n",
      "Iteration: 79270, Loss: -134.520248413\n",
      "Iteration: 79280, Loss: -144.512451172\n",
      "Iteration: 79290, Loss: -130.69921875\n",
      "Iteration: 79300, Loss: -125.431747437\n",
      "Iteration: 79310, Loss: -129.599029541\n",
      "Iteration: 79320, Loss: -140.475280762\n",
      "Iteration: 79330, Loss: -137.315719604\n",
      "Iteration: 79340, Loss: -137.270721436\n",
      "Iteration: 79350, Loss: -120.379043579\n",
      "Iteration: 79360, Loss: -138.991973877\n",
      "Iteration: 79370, Loss: -143.826416016\n",
      "Iteration: 79380, Loss: -145.035171509\n",
      "Iteration: 79390, Loss: -135.352050781\n",
      "Iteration: 79400, Loss: -129.152008057\n",
      "Iteration: 79410, Loss: -135.00189209\n",
      "Iteration: 79420, Loss: -146.212188721\n",
      "Iteration: 79430, Loss: -140.786331177\n",
      "Iteration: 79440, Loss: -135.776489258\n",
      "Iteration: 79450, Loss: -142.570388794\n",
      "Iteration: 79460, Loss: -136.993041992\n",
      "Iteration: 79470, Loss: -138.303100586\n",
      "Iteration: 79480, Loss: -148.401687622\n",
      "Iteration: 79490, Loss: -139.086593628\n",
      "Iteration: 79500, Loss: -135.600326538\n",
      "Iteration: 79510, Loss: -149.281707764\n",
      "Iteration: 79520, Loss: -144.169494629\n",
      "Iteration: 79530, Loss: -144.049194336\n",
      "Iteration: 79540, Loss: -129.573013306\n",
      "Iteration: 79550, Loss: -133.874069214\n",
      "Iteration: 79560, Loss: -132.211914062\n",
      "Iteration: 79570, Loss: -136.454742432\n",
      "Iteration: 79580, Loss: -132.431182861\n",
      "Iteration: 79590, Loss: -155.919326782\n",
      "Iteration: 79600, Loss: -143.500152588\n",
      "Iteration: 79610, Loss: -131.716339111\n",
      "Iteration: 79620, Loss: -146.967926025\n",
      "Iteration: 79630, Loss: -134.801879883\n",
      "Iteration: 79640, Loss: -143.422286987\n",
      "Iteration: 79650, Loss: -131.352783203\n",
      "Iteration: 79660, Loss: -143.947982788\n",
      "Iteration: 79670, Loss: -124.6876297\n",
      "Iteration: 79680, Loss: -132.642028809\n",
      "Iteration: 79690, Loss: -136.659988403\n",
      "Iteration: 79700, Loss: -144.083343506\n",
      "Iteration: 79710, Loss: -147.755981445\n",
      "Iteration: 79720, Loss: -146.431518555\n",
      "Iteration: 79730, Loss: -135.596481323\n",
      "Iteration: 79740, Loss: -151.559677124\n",
      "Iteration: 79750, Loss: -153.230789185\n",
      "Iteration: 79760, Loss: -143.770019531\n",
      "Iteration: 79770, Loss: -131.161590576\n",
      "Iteration: 79780, Loss: -132.089614868\n",
      "Iteration: 79790, Loss: -137.809997559\n",
      "Iteration: 79800, Loss: -142.836990356\n",
      "Iteration: 79810, Loss: -129.66003418\n",
      "Iteration: 79820, Loss: -142.395599365\n",
      "Iteration: 79830, Loss: -143.410186768\n",
      "Iteration: 79840, Loss: -132.840789795\n",
      "Iteration: 79850, Loss: -142.931716919\n",
      "Iteration: 79860, Loss: -127.548362732\n",
      "Iteration: 79870, Loss: -131.731292725\n",
      "Iteration: 79880, Loss: -130.06098938\n",
      "Iteration: 79890, Loss: -137.381362915\n",
      "Iteration: 79900, Loss: -134.233444214\n",
      "Iteration: 79910, Loss: -139.025039673\n",
      "Iteration: 79920, Loss: -137.479278564\n",
      "Iteration: 79930, Loss: -130.698852539\n",
      "Iteration: 79940, Loss: -127.797927856\n",
      "Iteration: 79950, Loss: -137.729766846\n",
      "Iteration: 79960, Loss: -126.099700928\n",
      "Iteration: 79970, Loss: -122.695808411\n",
      "Iteration: 79980, Loss: -159.540466309\n",
      "Iteration: 79990, Loss: -125.985336304\n",
      "Iteration: 80000, Loss: -141.18862915\n",
      "Iteration: 80010, Loss: -146.313262939\n",
      "Iteration: 80020, Loss: -126.716705322\n",
      "Iteration: 80030, Loss: -137.392044067\n",
      "Iteration: 80040, Loss: -126.410919189\n",
      "Iteration: 80050, Loss: -139.110839844\n",
      "Iteration: 80060, Loss: -138.658905029\n",
      "Iteration: 80070, Loss: -139.922332764\n",
      "Iteration: 80080, Loss: -134.550292969\n",
      "Iteration: 80090, Loss: -134.282974243\n",
      "Iteration: 80100, Loss: -136.211181641\n",
      "Iteration: 80110, Loss: -149.946014404\n",
      "Iteration: 80120, Loss: -137.795684814\n",
      "Iteration: 80130, Loss: -128.837982178\n",
      "Iteration: 80140, Loss: -128.964889526\n",
      "Iteration: 80150, Loss: -138.579727173\n",
      "Iteration: 80160, Loss: -133.10446167\n",
      "Iteration: 80170, Loss: -134.760772705\n",
      "Iteration: 80180, Loss: -148.580718994\n",
      "Iteration: 80190, Loss: -132.407409668\n",
      "Iteration: 80200, Loss: -136.676071167\n",
      "Iteration: 80210, Loss: -126.4815979\n",
      "Iteration: 80220, Loss: -135.452407837\n",
      "Iteration: 80230, Loss: -131.363433838\n",
      "Iteration: 80240, Loss: -127.077011108\n",
      "Iteration: 80250, Loss: -129.657989502\n",
      "Iteration: 80260, Loss: -145.891906738\n",
      "Iteration: 80270, Loss: -131.941665649\n",
      "Iteration: 80280, Loss: -140.171264648\n",
      "Iteration: 80290, Loss: -143.160919189\n",
      "Iteration: 80300, Loss: -132.306045532\n",
      "Iteration: 80310, Loss: -130.701095581\n",
      "Iteration: 80320, Loss: -137.745223999\n",
      "Iteration: 80330, Loss: -123.117156982\n",
      "Iteration: 80340, Loss: -138.7162323\n",
      "Iteration: 80350, Loss: -123.305587769\n",
      "Iteration: 80360, Loss: -147.10736084\n",
      "Iteration: 80370, Loss: -135.710235596\n",
      "Iteration: 80380, Loss: -135.183486938\n",
      "Iteration: 80390, Loss: -144.400390625\n",
      "Iteration: 80400, Loss: -142.040435791\n",
      "Iteration: 80410, Loss: -135.350250244\n",
      "Iteration: 80420, Loss: -145.201171875\n",
      "Iteration: 80430, Loss: -143.766998291\n",
      "Iteration: 80440, Loss: -134.060516357\n",
      "Iteration: 80450, Loss: -146.530853271\n",
      "Iteration: 80460, Loss: -138.238464355\n",
      "Iteration: 80470, Loss: -133.010375977\n",
      "Iteration: 80480, Loss: -123.385467529\n",
      "Iteration: 80490, Loss: -124.307632446\n",
      "Iteration: 80500, Loss: -132.798828125\n",
      "Iteration: 80510, Loss: -131.442657471\n",
      "Iteration: 80520, Loss: -138.724853516\n",
      "Iteration: 80530, Loss: -134.75062561\n",
      "Iteration: 80540, Loss: -130.786468506\n",
      "Iteration: 80550, Loss: -138.06829834\n",
      "Iteration: 80560, Loss: -130.097259521\n",
      "Iteration: 80570, Loss: -131.970275879\n",
      "Iteration: 80580, Loss: -131.869140625\n",
      "Iteration: 80590, Loss: -134.726776123\n",
      "Iteration: 80600, Loss: -127.516799927\n",
      "Iteration: 80610, Loss: -120.935546875\n",
      "Iteration: 80620, Loss: -147.064712524\n",
      "Iteration: 80630, Loss: -135.273651123\n",
      "Iteration: 80640, Loss: -139.694274902\n",
      "Iteration: 80650, Loss: -139.493713379\n",
      "Iteration: 80660, Loss: -144.21697998\n",
      "Iteration: 80670, Loss: -138.866821289\n",
      "Iteration: 80680, Loss: -132.969009399\n",
      "Iteration: 80690, Loss: -128.523468018\n",
      "Iteration: 80700, Loss: -137.068725586\n",
      "Iteration: 80710, Loss: -141.038970947\n",
      "Iteration: 80720, Loss: -128.842437744\n",
      "Iteration: 80730, Loss: -138.288513184\n",
      "Iteration: 80740, Loss: -144.852661133\n",
      "Iteration: 80750, Loss: -129.009735107\n",
      "Iteration: 80760, Loss: -128.277557373\n",
      "Iteration: 80770, Loss: -125.208473206\n",
      "Iteration: 80780, Loss: -138.094146729\n",
      "Iteration: 80790, Loss: -139.010559082\n",
      "Iteration: 80800, Loss: -136.968261719\n",
      "Iteration: 80810, Loss: -140.841690063\n",
      "Iteration: 80820, Loss: -140.416091919\n",
      "Iteration: 80830, Loss: -140.318130493\n",
      "Iteration: 80840, Loss: -127.881759644\n",
      "Iteration: 80850, Loss: -128.858520508\n",
      "Iteration: 80860, Loss: -131.2862854\n",
      "Iteration: 80870, Loss: -147.261688232\n",
      "Iteration: 80880, Loss: -142.469619751\n",
      "Iteration: 80890, Loss: -147.546142578\n",
      "Iteration: 80900, Loss: -132.513717651\n",
      "Iteration: 80910, Loss: -133.320251465\n",
      "Iteration: 80920, Loss: -137.406188965\n",
      "Iteration: 80930, Loss: -133.658966064\n",
      "Iteration: 80940, Loss: -137.407623291\n",
      "Iteration: 80950, Loss: -128.24887085\n",
      "Iteration: 80960, Loss: -140.760726929\n",
      "Iteration: 80970, Loss: -127.187042236\n",
      "Iteration: 80980, Loss: -139.161102295\n",
      "Iteration: 80990, Loss: -135.745803833\n",
      "Iteration: 81000, Loss: -134.099060059\n",
      "Iteration: 81010, Loss: -128.513397217\n",
      "Iteration: 81020, Loss: -129.400817871\n",
      "Iteration: 81030, Loss: -140.214538574\n",
      "Iteration: 81040, Loss: -142.289642334\n",
      "Iteration: 81050, Loss: -117.223068237\n",
      "Iteration: 81060, Loss: -139.462249756\n",
      "Iteration: 81070, Loss: -136.966888428\n",
      "Iteration: 81080, Loss: -148.973175049\n",
      "Iteration: 81090, Loss: -136.705963135\n",
      "Iteration: 81100, Loss: -142.655548096\n",
      "Iteration: 81110, Loss: -131.811737061\n",
      "Iteration: 81120, Loss: -137.097045898\n",
      "Iteration: 81130, Loss: -159.978927612\n",
      "Iteration: 81140, Loss: -132.915267944\n",
      "Iteration: 81150, Loss: -136.784362793\n",
      "Iteration: 81160, Loss: -136.766296387\n",
      "Iteration: 81170, Loss: -140.94619751\n",
      "Iteration: 81180, Loss: -135.311965942\n",
      "Iteration: 81190, Loss: -119.112419128\n",
      "Iteration: 81200, Loss: -132.91394043\n",
      "Iteration: 81210, Loss: -141.578292847\n",
      "Iteration: 81220, Loss: -144.091369629\n",
      "Iteration: 81230, Loss: -138.626861572\n",
      "Iteration: 81240, Loss: -139.130065918\n",
      "Iteration: 81250, Loss: -138.510116577\n",
      "Iteration: 81260, Loss: -135.750671387\n",
      "Iteration: 81270, Loss: -156.088272095\n",
      "Iteration: 81280, Loss: -123.91104126\n",
      "Iteration: 81290, Loss: -141.605773926\n",
      "Iteration: 81300, Loss: -141.263961792\n",
      "Iteration: 81310, Loss: -135.074707031\n",
      "Iteration: 81320, Loss: -127.96031189\n",
      "Iteration: 81330, Loss: -150.026855469\n",
      "Iteration: 81340, Loss: -127.848266602\n",
      "Iteration: 81350, Loss: -149.785064697\n",
      "Iteration: 81360, Loss: -119.492523193\n",
      "Iteration: 81370, Loss: -140.535949707\n",
      "Iteration: 81380, Loss: -132.348693848\n",
      "Iteration: 81390, Loss: -142.852233887\n",
      "Iteration: 81400, Loss: -123.675132751\n",
      "Iteration: 81410, Loss: -125.340484619\n",
      "Iteration: 81420, Loss: -138.849975586\n",
      "Iteration: 81430, Loss: -150.498504639\n",
      "Iteration: 81440, Loss: -126.485321045\n",
      "Iteration: 81450, Loss: -133.787139893\n",
      "Iteration: 81460, Loss: -129.406097412\n",
      "Iteration: 81470, Loss: -133.152816772\n",
      "Iteration: 81480, Loss: -132.228103638\n",
      "Iteration: 81490, Loss: -136.367385864\n",
      "Iteration: 81500, Loss: -128.064224243\n",
      "Iteration: 81510, Loss: -132.518035889\n",
      "Iteration: 81520, Loss: -175.929382324\n",
      "Iteration: 81530, Loss: -131.868240356\n",
      "Iteration: 81540, Loss: -135.951202393\n",
      "Iteration: 81550, Loss: -139.57371521\n",
      "Iteration: 81560, Loss: -127.497238159\n",
      "Iteration: 81570, Loss: -142.561019897\n",
      "Iteration: 81580, Loss: -135.165405273\n",
      "Iteration: 81590, Loss: -122.57901001\n",
      "Iteration: 81600, Loss: -144.393310547\n",
      "Iteration: 81610, Loss: -132.565246582\n",
      "Iteration: 81620, Loss: -136.271484375\n",
      "Iteration: 81630, Loss: -142.588043213\n",
      "Iteration: 81640, Loss: -128.190887451\n",
      "Iteration: 81650, Loss: -121.250915527\n",
      "Iteration: 81660, Loss: -138.554229736\n",
      "Iteration: 81670, Loss: -148.078521729\n",
      "Iteration: 81680, Loss: -143.756469727\n",
      "Iteration: 81690, Loss: -133.949203491\n",
      "Iteration: 81700, Loss: -137.902954102\n",
      "Iteration: 81710, Loss: -131.470184326\n",
      "Iteration: 81720, Loss: -147.580825806\n",
      "Iteration: 81730, Loss: -152.119903564\n",
      "Iteration: 81740, Loss: -138.117294312\n",
      "Iteration: 81750, Loss: -143.095275879\n",
      "Iteration: 81760, Loss: -139.713012695\n",
      "Iteration: 81770, Loss: -143.044677734\n",
      "Iteration: 81780, Loss: -140.185577393\n",
      "Iteration: 81790, Loss: -132.555374146\n",
      "Iteration: 81800, Loss: -142.742446899\n",
      "Iteration: 81810, Loss: -143.222946167\n",
      "Iteration: 81820, Loss: -144.414794922\n",
      "Iteration: 81830, Loss: -138.888458252\n",
      "Iteration: 81840, Loss: -132.893157959\n",
      "Iteration: 81850, Loss: -133.561309814\n",
      "Iteration: 81860, Loss: -133.431427002\n",
      "Iteration: 81870, Loss: -128.604629517\n",
      "Iteration: 81880, Loss: -131.498413086\n",
      "Iteration: 81890, Loss: -128.528640747\n",
      "Iteration: 81900, Loss: -151.338165283\n",
      "Iteration: 81910, Loss: -131.368927002\n",
      "Iteration: 81920, Loss: -133.988311768\n",
      "Iteration: 81930, Loss: -146.526000977\n",
      "Iteration: 81940, Loss: -139.031204224\n",
      "Iteration: 81950, Loss: -134.617965698\n",
      "Iteration: 81960, Loss: -141.793640137\n",
      "Iteration: 81970, Loss: -129.772003174\n",
      "Iteration: 81980, Loss: -156.845581055\n",
      "Iteration: 81990, Loss: -135.06741333\n",
      "Iteration: 82000, Loss: -129.371337891\n",
      "Iteration: 82010, Loss: -124.561004639\n",
      "Iteration: 82020, Loss: -142.147674561\n",
      "Iteration: 82030, Loss: -140.426849365\n",
      "Iteration: 82040, Loss: -139.98614502\n",
      "Iteration: 82050, Loss: -111.224723816\n",
      "Iteration: 82060, Loss: -123.332824707\n",
      "Iteration: 82070, Loss: -134.382293701\n",
      "Iteration: 82080, Loss: -141.1534729\n",
      "Iteration: 82090, Loss: -119.793586731\n"
     ]
    }
   ],
   "source": [
    "num_iterations = 1000000\n",
    "recording_interval = 10\n",
    "variational_lower_bound_array = []\n",
    "log_likelihood_array = []\n",
    "KL_term_array = []\n",
    "iteration_array = [i*recording_interval for i in range(num_iterations/recording_interval)]\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    mn_l = mnist.train.next_batch(bs)[0]\n",
    "    x_batch = np.reshape(mn_l, [bs, 28, 28, 1])\n",
    "#    x_batch = sample_a_batch(filename, bs, 64, sb=2, normalize=stats, flattened=False)\n",
    "    _, s = sess.run([optimizer, merged_summary], feed_dict={X: x_batch})\n",
    "    writer.add_summary(s, i)\n",
    "    if (i%recording_interval == 0):\n",
    "        #every 1K iterations record these values\n",
    "        vlb_eval = variational_lower_bound.eval(feed_dict={X: x_batch})\n",
    "        print \"Iteration: {}, Loss: {}\".format(i, vlb_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NEXT CELLS TO BE IGNORED**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#filename = '/run/media/ron/silver_small/twelve_months/3d/S1A_IW_GRDH_1SDV_20160325T083601_20160325T083630_010523_00FA23_6F51.tif'\n",
    "#stats = normalization_parameters(filename)\n",
    "\n",
    "def conv_layer(inp, channels_in, channels_out, vscope, name='conv'):\n",
    "    with tf.name_scope(name):\n",
    "        with tf.variable_scopec(vscope):\n",
    "            tf.Variable(tf.zeros([3, 3, channels_in, channels_out]), name='W')\n",
    "        b = tf.Variable(tf.zeros([channels_out]), name='B')\n",
    "        conv = tf.nn.conv2d(inp, w, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        act = tf.nn.relu(conv + b)\n",
    "        tf.summary.histogram('weights', w)\n",
    "        tf.summary.histogram('biases', b)\n",
    "        tf.summary.histogram('activations', act)\n",
    "        return tf.nn.max_pool(act, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "def conv_t_layer(inp, channels_in, channels_out, name='conv_t'):#, activation=tf.nn.relu):\n",
    "    with tf.name_scope(name):\n",
    "        #w = tf.Variable(tf.zeros([3, 3, channels_out, channels_in]), name='W')\n",
    "        w = conv1\n",
    "        b = tf.Variable(tf.zeros([conv1.get_shape().as_list()[2]]))\n",
    "        \n",
    "        tf.nn.conv2d_transpose(inp, W, tf.stack([]))\n",
    "        \n",
    "        \n",
    "        \n",
    "        b = tf.Variable(tf.zeros([channels_out]), name='B')\n",
    "        batch_size = 32 #tf.shape(inp)[0]\n",
    "        deconv_shape = tf.stack([batch_size, inp.shape[2].value * 2, inp.shape[2].value * 2, channels_out])\n",
    "        conv_t = tf.nn.conv2d_transpose(inp, w, deconv_shape, strides=[1, 2, 2, 1], padding='SAME')\n",
    "        #act = activation(conv_t + b)\n",
    "        act = tf.nn.relu(conv_t + b)\n",
    "        tf.summary.histogram('weights', w)\n",
    "        tf.summary.histogram('biases', b)\n",
    "        tf.summary.histogram('activations', act)\n",
    "        return act#tf.nn.max_pool(act, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "def sample_a_batch(filebase, batchsize, tilesize=128, sb=0, normalize=False, flattened=True):\n",
    "    # can sample for spatio-temporal (single_file = False), and spatial-only case (single_file = True).\n",
    "    import numpy as np\n",
    "    from osgeo import gdal\n",
    "    \n",
    "    if '.' in filebase:\n",
    "        single_file = True\n",
    "        S = gdal.Open(filebase)\n",
    "    else:\n",
    "        single_file = False\n",
    "        S = gdal.Open(filebase + '_1.vrt')\n",
    "        \n",
    "    samples = []\n",
    "    \n",
    "    if single_file:\n",
    "        while len(samples) < batchsize:\n",
    "            RX = np.random.randint(S.RasterXSize-tilesize,size=1)\n",
    "            RY = np.random.randint(S.RasterYSize-tilesize,size=1)\n",
    "            \n",
    "            #A = np.transpose(S.ReadAsArray(RX[0], RY[0], tilesize, tilesize))           \n",
    "            \n",
    "            if sb:\n",
    "                B = S.GetRasterBand(sb)\n",
    "                A = np.transpose(B.ReadAsArray(RX[0], RY[0], tilesize, tilesize))                \n",
    "                #print np.min(A)\n",
    "                if np.min(A) > 0:\n",
    "                    if normalize:\n",
    "                        A = A / normalize[2][sb-1]                        \n",
    "                    A = np.expand_dims(A, 2)                    \n",
    "                    if flattened:\n",
    "                        A = A.flatten()                        \n",
    "                    samples.append(A)\n",
    "            else:\n",
    "                A = np.transpose(S.ReadAsArray(RX[0], RY[0], tilesize, tilesize))\n",
    "                if np.min(A) > 0:\n",
    "                    samples.append(A)\n",
    "        \n",
    "    else: # must be overhauled\n",
    "        while len(samples) < batchsize:\n",
    "            RX = np.random.randint(S.RasterXSize-tilesize,size=1)\n",
    "            RY = np.random.randint(S.RasterYSize-tilesize,size=1) \n",
    "            \n",
    "            skip_loc = False\n",
    "            months = []\n",
    "            \n",
    "            for m in range(1,13):\n",
    "                S = gdal.Open(filebase + '_' + str(m) + '.vrt')\n",
    "                A = np.transpose(S.ReadAsArray(RX[i], RY[i], tilesize, tilesize))\n",
    "                if np.min(A) == 0.0:\n",
    "                    skip_loc = True\n",
    "                    break\n",
    "                else:\n",
    "                    months.append(A)                \n",
    "            if not skip_loc:\n",
    "                months = np.array(months)\n",
    "                samples.append(months)\n",
    "        \n",
    "    return np.array(samples)\n",
    "\n",
    "def normalization_parameters(fn):\n",
    "    from osgeo import gdal\n",
    "    S = gdal.Open(fn)\n",
    "    mns = []\n",
    "    sds = []\n",
    "    maxs = []\n",
    "    \n",
    "    for b in range(S.RasterCount):\n",
    "        B = S.GetRasterBand(b+1)\n",
    "        mn, sd = B.ComputeStatistics(1)[2:4]\n",
    "        mns.append(mn)\n",
    "        sds.append(sd)\n",
    "        maxs.append(B.GetMaximum())\n",
    "        \n",
    "    return mns, sds, maxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('Input'):\n",
    "    X = tf.placeholder(tf.float32, shape=([None, len_edge, len_edge, num_channels]))#bs\n",
    "    tf.summary.image('input_images', X, max_outputs=3)\n",
    "\n",
    "conv1 = conv_layer(X, num_channels, filters[0], 'conv1')\n",
    "conv2 = conv_layer(conv1, conv1.shape[-1].value, filters[1], 'conv2')\n",
    "conv3 = conv_layer(conv2, conv2.shape[-1].value, filters[2], 'conv3')\n",
    "conv4 = conv_layer(conv3, conv3.shape[-1].value, filters[3], 'conv4')\n",
    "\n",
    "#with tf.name_scope('Dense_Encode'):\n",
    "flattened = tf.reshape(conv4, [-1, 2 * 2 * filters[-1]])\n",
    "full1 = fc_layer(flattened, 2 * 2 * filters[-1], h_dim, 'fc1') # channels_in ?????\n",
    "\n",
    "W_mu = weight_variable([h_dim, latent_dim], 'W_mu')\n",
    "b_mu = bias_variable([latent_dim], 'b_mu')\n",
    "mu = FC_layer(full1, W_mu, b_mu)\n",
    "W_logstd = weight_variable([h_dim, latent_dim], 'W_logstd')\n",
    "b_logstd = bias_variable([latent_dim], 'b_logstd')\n",
    "logstd = FC_layer(full1, W_logstd, b_logstd)\n",
    "\n",
    "noise = tf.random_normal([1, latent_dim])\n",
    "z = mu + tf.multiply(noise, tf.exp(.5*logstd))\n",
    "\n",
    "z_visual = tf.reshape(z, [-1, 6, 6, 1])\n",
    "tf.summary.image('latents', z_visual, max_outputs=3)\n",
    "\n",
    "tf.summary.histogram('Latent', z)\n",
    "\n",
    "full2 = fc_layer(z, latent_dim, h_dim, 'fc2')\n",
    "full3 = fc_layer(full2, h_dim, 2 * 2 * filters[-1], 'fc3')# ???????\n",
    "\n",
    "reshaped = tf.reshape(full3, [-1, 2, 2, filters[-1]])\n",
    "\n",
    "conv_t1 = conv_t_layer(reshaped, filters[1], filters[1], 'conv_t1')\n",
    "conv_t2 = conv_t_layer(conv_t1, filters[1], filters[1], 'conv_t2')\n",
    "conv_t3 = conv_t_layer(conv_t2, filters[1], filters[1], 'conv_t3')\n",
    "reconstruction = conv_t_layer(conv_t3, filters[1], 1, 'conv_t4')#, tf.nn.sigmoid)\n",
    "\n",
    "tf.summary.image('reconstructed_images', reconstruction, max_outputs=3) #............"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
