{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalization_parameters(fn):\n",
    "    from osgeo import gdal\n",
    "    print fn\n",
    "    S = gdal.Open(fn)\n",
    "    mns = []\n",
    "    sds = []\n",
    "    maxs = []\n",
    "    \n",
    "    for b in range(S.RasterCount):\n",
    "        B = S.GetRasterBand(b+1)\n",
    "        mn, sd = B.ComputeStatistics(1)[2:4]\n",
    "        mns.append(mn)\n",
    "        sds.append(sd)\n",
    "        maxs.append(B.GetMaximum())\n",
    "        \n",
    "    return([mns, sds, maxs])\n",
    "\n",
    "def sample(filebase, batchsize, tilesize=128, normalize=False, flattened=False):\n",
    "    import numpy as np\n",
    "    from osgeo import gdal\n",
    "    \n",
    "    print filebase\n",
    "    \n",
    "    multisens = False\n",
    "    multires = False\n",
    "    \n",
    "    if type(filebase) == str:\n",
    "        S2_10 = gdal.Open(filebase)\n",
    "        if normalize:\n",
    "            maxima_10 = np.array(normalization_parameters(filebase)[2])\n",
    "        \n",
    "    elif type(filebase) == list:#interpreted as multiple resolutions\n",
    "        multires = True\n",
    "        S2_10 = gdal.Open(filebase[0])\n",
    "        S2_20 = gdal.Open(filebase[1])\n",
    "        tilesize = tilesize/2   \n",
    "        \n",
    "        maxima_10 = np.array(normalization_parameters(filebase[0])[2])\n",
    "        maxima_20 = np.array(normalization_parameters(filebase[1])[2])\n",
    "        \n",
    "        if len(filebase) == 3:            \n",
    "            multisens = True\n",
    "            S1 = gdal.Open(filebase[2])\n",
    "            if normalize:\n",
    "                maxima_S1 = np.array(normalization_parameters(filebase[2])[2])\n",
    "    \n",
    "    samples_10 = []\n",
    "    \n",
    "    if multires:        \n",
    "        samples_20 = []\n",
    "        if multisens:\n",
    "            samples_S1 = []\n",
    "        \n",
    "        while len(samples_10) < batchsize:\n",
    "            RX = np.random.randint(S2_20.RasterXSize-tilesize,size=1)\n",
    "            RY = np.random.randint(S2_20.RasterYSize-tilesize,size=1)\n",
    "            \n",
    "            A_10 = np.transpose(S2_10.ReadAsArray(RX[0] * 2, RY[0] * 2, tilesize * 2, tilesize * 2)).astype(np.float32)\n",
    "            A_20 = np.transpose(S2_20.ReadAsArray(RX[0], RY[0], tilesize, tilesize)).astype(np.float32)\n",
    "            A_S1 = 0\n",
    "            if multisens:\n",
    "                A_S1 = np.transpose(S1.ReadAsArray(RX[0] * 2, RY[0] * 2, tilesize * 2, tilesize * 2)).astype(np.float32)\n",
    "            \n",
    "            if ((np.min(A_10) > 0) & (np.min(A_20) > 0) & (multisens == False)) or ((np.min(A_10) > 0) & (np.min(A_20) > 0) & (np.min(A_S1) > 0)):\n",
    "                if normalize:\n",
    "                    A_10 = A_10 / maxima_10\n",
    "                    A_20 = A_20 / maxima_20\n",
    "                    if multisens:\n",
    "                        A_S1 = A_S1 / maxima_S1\n",
    "                if flattened:\n",
    "                    A_10 = A_10.flatten()\n",
    "                    A_20 = A_20.flatten()\n",
    "                    if multisens:\n",
    "                        A_S1 = A_S1.flatten()\n",
    "                    \n",
    "                samples_10.append(A_10)\n",
    "                samples_20.append(A_20)\n",
    "                if multisens:\n",
    "                    samples_S1.append(A_S1)\n",
    "                    \n",
    "        if multisens:\n",
    "            return([np.array(samples_10), np.array(samples_20), np.array(samples_S1)])\n",
    "        \n",
    "        return([np.array(samples_10), np.array(samples_20)])\n",
    "                \n",
    "    else:\n",
    "        while len(samples_10) < batchsize:\n",
    "            RX = np.random.randint(S2_10.RasterXSize-tilesize,size=1)\n",
    "            RY = np.random.randint(S2_10.RasterYSize-tilesize,size=1)\n",
    "            \n",
    "            A_10 = np.transpose(S2_10.ReadAsArray(RX[0], RY[0], tilesize, tilesize).astype(np.float32))\n",
    "            \n",
    "            if np.min(A_10) > 0:            \n",
    "                if normalize:\n",
    "                    A_10 = A_10 / maxima_10\n",
    "                if flattened:\n",
    "                    A_10 = A_10.flatten()\n",
    "                    \n",
    "                samples_10.append(A_10)\n",
    "                \n",
    "        return(np.array(samples_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attempt = 102\n",
    "\n",
    "bs = 10\n",
    "train_size = 400\n",
    "\n",
    "len_edge = 64\n",
    "num_channels_10 = 4\n",
    "num_channels_20 = 6\n",
    "num_channels_S1 = 2\n",
    "\n",
    "innest = 256\n",
    "inner = 128\n",
    "middle = 128\n",
    "outer = 64\n",
    "\n",
    "tb_imgs_to_display = 4\n",
    "epochs = 1000000\n",
    "\n",
    "testlogpath = './vae_logs/test/' + str(attempt)\n",
    "trainlogpath = './vae_logs/train/' + str(attempt)\n",
    "fn_10 = '/run/media/ron/silver_small/reconst/S2_10_fin.tif'\n",
    "fn_20 = '/run/media/ron/silver_small/reconst/S2_20_fin.tif'\n",
    "fn_S1 = '/run/media/ron/silver_small/reconst/S1_fin.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convolute(inp, name, kernel_size = 3, out_chans = 64, sz = 1):\n",
    "    inp_chans = inp.get_shape().as_list()[-1]\n",
    "    with tf.variable_scope(name) as scope:\n",
    "        W = tf.get_variable('weights', [kernel_size, kernel_size, inp_chans, out_chans], initializer=tf.contrib.layers.xavier_initializer_conv2d(), regularizer=tf.contrib.layers.l2_regularizer(0.0005))#, name='weights')\n",
    "        b = tf.get_variable('biases', [out_chans], initializer=tf.constant_initializer(0.0), regularizer=None, dtype=tf.float32)\n",
    "        conv = tf.nn.conv2d(inp, W, strides=[1, sz, sz, 1], padding='SAME')\n",
    "        conv = tf.contrib.layers.batch_norm(conv, scope=scope) # train?\n",
    "        conv = tf.nn.relu(conv+b)\n",
    "#        conv = tf.nn.dropout(conv, 0.8)\n",
    "    return conv\n",
    "\n",
    "def pooling(inp, name, factor=2):\n",
    "    pool = tf.nn.max_pool(inp, ksize=[1, factor, factor, 1], strides=[1, factor, factor, 1], padding='SAME', name=name)\n",
    "    return pool\n",
    "\n",
    "\n",
    "layer_name_dict = {}\n",
    "def layer_name(base_name):\n",
    "    if base_name not in layer_name_dict:\n",
    "        layer_name_dict[base_name] = 0\n",
    "    layer_name_dict[base_name] += 1\n",
    "    name = base_name + str(layer_name_dict[base_name])\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reconstructions:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#with tf.name_scope('Input'):\n",
    "#    X = tf.placeholder(tf.float32, shape=([None, len_edge, len_edge, num_channels]))#bs\n",
    "#    if num_channels == 2:\n",
    "#        X_show = tf.concat([X, tf.expand_dims(X[:, :, :, 1], 3)], axis=3)\n",
    "#        tf.summary.image('input_images', X_show, max_outputs=tb_imgs_to_display)\n",
    "#    elif num_channels > 3:\n",
    "#        tf.summary.image('input_images', X[:, :, :, 0:3], max_outputs=tb_imgs_to_display)\n",
    "#    else:\n",
    "#        tf.summary.image('input_images', X, max_outputs=tb_imgs_to_display)\n",
    "        \n",
    "        \n",
    "X_10 = tf.placeholder(tf.float32, shape=([None, len_edge, len_edge, num_channels_10]))\n",
    "X_20 = tf.placeholder(tf.float32, shape=([None, len_edge / 2, len_edge / 2, num_channels_20]))\n",
    "X_S1 = tf.placeholder(tf.float32, shape=([None, len_edge, len_edge, num_channels_S1]))\n",
    "\n",
    "tf.summary.image('input_images_S1', tf.concat([X_S1, tf.expand_dims(X_S1[:, :, :, 1], 3)], axis=3), max_outputs=tb_imgs_to_display)\n",
    "tf.summary.image('input_images_S2_10', X_10[:, :, :, 0:3], max_outputs=tb_imgs_to_display)\n",
    "tf.summary.image('input_images_S2_20', X_20[:, :, :, 0:3], max_outputs=tb_imgs_to_display)\n",
    "\n",
    "dw_h_convs = OrderedDict()\n",
    "up_h_convs = OrderedDict()\n",
    "\n",
    "X_20_c = convolute(X_20, layer_name('conv'), 3, outer, sz = 1)\n",
    "X_20_c = convolute(X_20_c, layer_name('conv'), 3, outer, sz = 1)\n",
    "\n",
    "X_10_c = convolute(X_10, layer_name('conv'), 3, outer, sz = 1)\n",
    "X_10_c = convolute(X_10_c,layer_name('conv'), 3, outer, sz = 1)\n",
    "dw_h_convs[0] = pooling(X_10_c, 'pool1')\n",
    "\n",
    "\n",
    "dw_h_convs[1] = tf.concat([dw_h_convs[0], X_20_c], 3)\n",
    "\n",
    "dw_h_convs[1] = convolute(dw_h_convs[1],layer_name('conv'),3,outer)\n",
    "dw_h_convs[1] = convolute(dw_h_convs[1],layer_name('conv'),3,outer)\n",
    "dw_h_convs[2] = pooling(dw_h_convs[1], 'pool2')\n",
    "\n",
    "dw_h_convs[2] = convolute(dw_h_convs[2],layer_name('conv'),3,middle)\n",
    "dw_h_convs[2] = convolute(dw_h_convs[2],layer_name('conv'),3,middle)\n",
    "dw_h_convs[3] = pooling(dw_h_convs[2], 'pool3')\n",
    "\n",
    "dw_h_convs[3] = convolute(dw_h_convs[3],layer_name('conv'),3,inner)\n",
    "dw_h_convs[3] = convolute(dw_h_convs[3],layer_name('conv'),3,inner)\n",
    "dw_h_convs[4] = pooling(dw_h_convs[3], 'pool4')\n",
    "\n",
    "dw_h_convs[4] = convolute(dw_h_convs[4],layer_name('conv'),3,innest)\n",
    "dw_h_convs[4] = convolute(dw_h_convs[4],layer_name('conv'),3,inner)\n",
    "\n",
    "\n",
    "\n",
    "up_h_convs[0] = tf.image.resize_images(dw_h_convs[4], [ dw_h_convs[4].get_shape().as_list()[1]*2, \n",
    "                                                            dw_h_convs[4].get_shape().as_list()[2]*2] )\n",
    "#up_h_convs[0] = tf.concat([up_h_convs[0], dw_h_convs[3] ],3 )\n",
    "up_h_convs[0] = convolute(up_h_convs[0], layer_name('conv'), 3, inner)\n",
    "up_h_convs[0] = convolute(up_h_convs[0], layer_name('conv'), 3, middle)\n",
    "\n",
    "up_h_convs[1] = tf.image.resize_images(up_h_convs[0], [ up_h_convs[0].get_shape().as_list()[1]*2, \n",
    "                                                            up_h_convs[0].get_shape().as_list()[2]*2] ) \n",
    "#up_h_convs[1] = tf.concat([up_h_convs[1], dw_h_convs[2] ],3 ) \n",
    "up_h_convs[1] = convolute(up_h_convs[1], layer_name('conv'), 3, middle)\n",
    "up_h_convs[1] = convolute(up_h_convs[1], layer_name('conv'), 3, outer)\n",
    "\n",
    "up_h_convs[2] = tf.image.resize_images(up_h_convs[1], [ up_h_convs[1].get_shape().as_list()[1]*2, \n",
    "                                                            up_h_convs[1].get_shape().as_list()[2]*2] )\n",
    "#up_h_convs[2] = tf.concat([up_h_convs[2], dw_h_convs[1] ],3 ) \n",
    "up_h_convs[2] = convolute(up_h_convs[2], layer_name('conv'), 3, outer)\n",
    "up_h_convs[2] = convolute(up_h_convs[2], layer_name('conv'), 3, outer)\n",
    "\n",
    "up_h_convs[3] = tf.image.resize_images(up_h_convs[2], [ up_h_convs[2].get_shape().as_list()[2]*2, \n",
    "                                                            up_h_convs[2].get_shape().as_list()[2]*2] )\n",
    "#up_h_convs[3] = tf.concat([up_h_convs[3], X_10_c],3 ) \n",
    "up_h_convs[3] = convolute(up_h_convs[3], layer_name('conv'), 3, outer)\n",
    "up_h_convs[3] = convolute(up_h_convs[3], layer_name('conv'), 3, outer)\n",
    "\n",
    "W_rec = tf.get_variable('weights_rec', [1, 1, outer, num_channels_S1], initializer=tf.contrib.layers.xavier_initializer_conv2d(), regularizer=False)#, name='weights')\n",
    "b_rec = tf.get_variable('biases_rec', [num_channels_S1], initializer=tf.constant_initializer(0.0), regularizer=None, dtype=tf.float32)\n",
    "reconstruction = tf.nn.sigmoid(tf.nn.conv2d(up_h_convs[3], W_rec, strides=[1, 1, 1, 1], padding='SAME') + b_rec)\n",
    "\n",
    "tf.summary.image('Reconstructions', tf.concat([reconstruction, tf.expand_dims(reconstruction[:, :, :, 1], 3)], axis=3), max_outputs=tb_imgs_to_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_flat = tf.contrib.layers.flatten(X_S1)\n",
    "R_flat = tf.contrib.layers.flatten(reconstruction)\n",
    "log_likelihood = tf.reduce_sum(X_flat*tf.log(R_flat + 1e-9)+(1 - X_flat)*tf.log(1 - R_flat + 1e-9), reduction_indices=1)\n",
    "\n",
    "tf.summary.scalar('LogLike', tf.reduce_mean(log_likelihood))\n",
    "\n",
    "optimizer_likeli = tf.train.AdamOptimizer(1e-4).minimize(-log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_summary = tf.summary.merge_all()\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)\n",
    "saver = tf.train.Saver()\n",
    "train_writer = tf.summary.FileWriter(trainlogpath)\n",
    "#valid_writer = tf.summary.FileWriter(testlogpath)\n",
    "#gen_writer = tf.summary.FileWriter(genlogpath)\n",
    "train_writer.add_graph(sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/run/media/ron/silver_small/reconst/S2_10_fin.tif', '/run/media/ron/silver_small/reconst/S2_20_fin.tif', '/run/media/ron/silver_small/reconst/S1_fin.tif']\n",
      "/run/media/ron/silver_small/reconst/S2_10_fin.tif\n",
      "/run/media/ron/silver_small/reconst/S2_20_fin.tif\n",
      "/run/media/ron/silver_small/reconst/S1_fin.tif\n"
     ]
    }
   ],
   "source": [
    "all_10, all_20, all_S1 = sample([fn_10, fn_20, fn_S1], batchsize=400, tilesize=len_edge, normalize=True, flattened=False)\n",
    "#X_all = sample_1s2(fn3, train_size, tilesize=len_edge, normalize=True, flattened=False)\n",
    "#x_valid = sample_1s2(fn3, valid_size, tilesize=len_edge, normalize=True, flattened=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-893ee08c718d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mS1_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_S1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer_likeli\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX_10\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mS2_10_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_20\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mS2_20_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_S1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mS1_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mrecording_interval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "step = bs\n",
    "ep = 0\n",
    "recording_interval = 20\n",
    "for ep in range(epochs):\n",
    "    S2_10_batch = all_10[step-bs:step]\n",
    "    S2_20_batch = all_20[step-bs:step]\n",
    "    S1_batch = all_S1[step-bs:step]\n",
    "    \n",
    "    sess.run([optimizer_likeli], feed_dict={X_10: S2_10_batch, X_20: S2_20_batch, X_S1: S1_batch})\n",
    "    \n",
    "    if (ep%recording_interval == 0):\n",
    "        _, s = sess.run([optimizer_likeli, merged_summary], feed_dict={X_10: S2_10_batch, X_20: S2_20_batch, X_S1: S1_batch})\n",
    "        train_writer.add_summary(s, ep)\n",
    "#        vvv, s = sess.run([validator, merged_summary], feed_dict={X: x_valid})\n",
    "#        vvv, s = sess.run([validator, merged_summary], feed_dict={X: X1_valid, X2: X2_valid})\n",
    "#        valid_writer.add_summary(s, ep)\n",
    "#        \n",
    "#    _, s = sess.run([optimizer, merged_summary], feed_dict={X: x_batch})\n",
    "#    _, s = sess.run([optimizer, merged_summary], feed_dict={X: x1_batch, X2: x2_batch})\n",
    "#    \n",
    "#    if (ep%recording_interval == 0):\n",
    "        \n",
    "#        \n",
    "    step += bs\n",
    "    \n",
    "    if step == train_size:\n",
    "        step = bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
