{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "from keras.layers import Input, Dense, Lambda, Flatten, Reshape, Layer, UpSampling2D, MaxPooling2D\n",
    "from keras.layers import Conv2D, Conv2DTranspose\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from osgeo import gdal\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (16, 64, 64, 2)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (16, 64, 64, 512)     9728        input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (16, 32, 32, 512)     0           conv2d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (16, 32, 32, 512)     2359808     max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)   (16, 16, 16, 512)     0           conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (16, 16, 16, 512)     2359808     max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)   (16, 8, 8, 512)       0           conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (16, 8, 8, 512)       2359808     max_pooling2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)   (16, 4, 4, 512)       0           conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (16, 4, 4, 512)       2359808     max_pooling2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)   (16, 2, 2, 512)       0           conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (16, 2, 2, 512)       2359808     max_pooling2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)   (16, 1, 1, 512)       0           conv2d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (16, 512)             0           max_pooling2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (16, 128)             65664       flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (16, 2)               258         dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (16, 2)               258         dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)                (16, 2)               0           dense_2[0][0]                    \n",
      "                                                                   dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (16, 128)             384         lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (16, 512)             66048       dense_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)              (16, 1, 1, 512)       0           dense_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)   (16, 2, 2, 512)       0           reshape_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)                (16, 2, 2, 512)       2359808     up_sampling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)   (16, 4, 4, 512)       0           conv2d_7[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)                (16, 4, 4, 512)       2359808     up_sampling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)   (16, 8, 8, 512)       0           conv2d_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)                (16, 8, 8, 512)       2359808     up_sampling2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)   (16, 16, 16, 512)     0           conv2d_9[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)               (16, 16, 16, 512)     2359808     up_sampling2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)   (16, 32, 32, 512)     0           conv2d_10[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)               (16, 32, 32, 512)     2359808     up_sampling2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2D)   (16, 64, 64, 512)     0           conv2d_11[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)               (16, 64, 64, 2)       9218        up_sampling2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "custom_variational_layer_1 (Cust [(16, 64, 64, 2), (16 0           input_1[0][0]                    \n",
      "                                                                   conv2d_12[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 23,749,638\n",
      "Trainable params: 23,749,638\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ron/.conda/envs/test1/lib/python2.7/site-packages/ipykernel_launcher.py:109: UserWarning: Output \"custom_variational_layer_1\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"custom_variational_layer_1\" during training.\n"
     ]
    }
   ],
   "source": [
    "img_rows, img_cols, channels = 64, 64, 2\n",
    "num_conv = 3\n",
    "batch_size = 16\n",
    "original_img_size = (img_rows, img_cols, channels)\n",
    "interm_dim = 128\n",
    "latent_dim = 2\n",
    "epsilon_std = 1.0\n",
    "c_fil_n = [512, 512, 512, 512, 512, 512]\n",
    "\n",
    "x = Input(batch_shape=(batch_size,) + original_img_size)\n",
    "\n",
    "conv_1 = Conv2D(c_fil_n[0], 3, padding='same', activation='relu')(x)\n",
    "maxp_1 = MaxPooling2D((2, 2), padding='same')(conv_1)#32\n",
    "\n",
    "conv_2 = Conv2D(c_fil_n[1], 3, padding='same', activation='relu')(maxp_1)\n",
    "maxp_2 = MaxPooling2D((2, 2), padding='same')(conv_2)#16\n",
    "\n",
    "conv_3 = Conv2D(c_fil_n[2], 3, padding='same', activation='relu')(maxp_2)\n",
    "maxp_3 = MaxPooling2D((2, 2), padding='same')(conv_3)#8\n",
    "\n",
    "conv_4 = Conv2D(c_fil_n[3], 3, padding='same', activation='relu')(maxp_3)\n",
    "maxp_4 = MaxPooling2D((2, 2), padding='same')(conv_4)#4\n",
    "\n",
    "conv_5 = Conv2D(c_fil_n[4], 3, padding='same', activation='relu')(maxp_4)\n",
    "maxp_5 = MaxPooling2D((2, 2), padding='same')(conv_5)#2\n",
    "\n",
    "conv_6 = Conv2D(c_fil_n[5], 3, padding='same', activation='relu')(maxp_5)\n",
    "maxp_6 = MaxPooling2D((2, 2), padding='same')(conv_6)#1\n",
    "\n",
    "\n",
    "flat = Flatten()(maxp_6)\n",
    "\n",
    "hidden = Dense(interm_dim, activation='relu')(flat)\n",
    "\n",
    "z_mean = Dense(latent_dim)(hidden)\n",
    "z_log_var = Dense(latent_dim)(hidden)\n",
    "\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(batch_size, latent_dim),\n",
    "                              mean=0., stddev=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_var) * epsilon\n",
    "\n",
    "\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "\n",
    "decoder_hid = Dense(interm_dim, activation='relu')#(z)\n",
    "decoder_upsample = Dense(c_fil_n[5] * 1 * 1, activation='relu')#(hid_decoded)\n",
    "\n",
    "output_shape = (batch_size, 1, 1, c_fil_n[5])\n",
    "\n",
    "decoder_reshape = Reshape(output_shape[1:])#(up_decoded)\n",
    "up_0 = UpSampling2D((2,2))#(decoder_reshaped)#2\n",
    "deconv_0 = Conv2D(c_fil_n[4], 3, padding='same', activation='relu')#(up_0)\n",
    "up_05 = UpSampling2D((2, 2))#(deconv_0)#4\n",
    "deconv_1 = Conv2D(c_fil_n[3], 3, padding='same', activation='relu')#(up_05)\n",
    "up_1 = UpSampling2D((2, 2))#(deconv_1)#8\n",
    "deconv_2 = Conv2D(c_fil_n[2], 3, padding='same', activation='relu')#(up_1)\n",
    "up_2 = UpSampling2D((2, 2))#(deconv_2)#16\n",
    "deconv_3 = Conv2D(c_fil_n[1], 3, padding='same', activation='relu')#(up_2)\n",
    "up_3 = UpSampling2D((2, 2))#(deconv_3)#32\n",
    "deconv_4 = Conv2D(c_fil_n[0], 3, padding='same', activation='relu')#(up_3)\n",
    "up_4 = UpSampling2D((2, 2))#(deconv_4)#64\n",
    "decoder_mean_squash = Conv2D(channels, 3, padding='same', activation='sigmoid')#(up_4)\n",
    "\n",
    "\n",
    "hid_decoded = decoder_hid(z)\n",
    "up_decoded = decoder_upsample(hid_decoded)\n",
    "reshape_decoded = decoder_reshape(up_decoded)\n",
    "up_0_decoded = up_0(reshape_decoded)\n",
    "deconv_0_decoded = deconv_0(up_0_decoded)\n",
    "\n",
    "up_05_decoded = up_05(deconv_0_decoded)\n",
    "deconv_1_decoded = deconv_1(up_05_decoded)\n",
    "up_1_decoded = up_1(deconv_1_decoded)\n",
    "deconv_2_decoded = deconv_2(up_1_decoded)\n",
    "up_2_decoded = up_2(deconv_2_decoded)\n",
    "deconv_3_decoded = deconv_3(up_2_decoded)\n",
    "up_3_decoded = up_3(deconv_3_decoded)\n",
    "deconv_4_decoded = deconv_4(up_3_decoded)\n",
    "up_4_decoded = up_4(deconv_4_decoded)\n",
    "x_decoded_mean_squash = decoder_mean_squash(up_4_decoded)\n",
    "\n",
    "# Custom loss layer\n",
    "class CustomVariationalLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.is_placeholder = True\n",
    "        super(CustomVariationalLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def vae_loss(self, x, x_decoded_mean_squash):\n",
    "        x = K.flatten(x)\n",
    "        x_decoded_mean_squash = K.flatten(x_decoded_mean_squash)\n",
    "        xent_loss = img_rows * img_cols * metrics.binary_crossentropy(x, x_decoded_mean_squash)\n",
    "        kl_loss = - 0.5 * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "        return K.mean(xent_loss + kl_loss)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs[0]\n",
    "        x_decoded_mean_squash = inputs[1]\n",
    "        loss = self.vae_loss(x, x_decoded_mean_squash)\n",
    "        self.add_loss(loss, inputs=inputs)\n",
    "        # We don't use this output.\n",
    "        return x\n",
    "\n",
    "y = CustomVariationalLayer()([x, x_decoded_mean_squash])\n",
    "vae = Model(x, y)\n",
    "vae2 = Model(x, x_decoded_mean_squash)\n",
    "vae.compile(optimizer='rmsprop', lr=0.001, loss=None)#lr=0.001 default\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_a_batch(filebase, batchsize, tilesize=128, sb=False):\n",
    "    # can sample for spatio-temporal (single_file = False), and spatial-only case (single_file = True).\n",
    "    import numpy as np\n",
    "    from osgeo import gdal\n",
    "    \n",
    "    if '.' in filebase:\n",
    "        single_file = True\n",
    "        S = gdal.Open(filebase)\n",
    "    else:\n",
    "        single_file = False\n",
    "        S = gdal.Open(filebase + '_1.vrt')\n",
    "        \n",
    "    samples = []\n",
    "    \n",
    "    if single_file:\n",
    "        while len(samples) < batchsize:\n",
    "            RX = np.random.randint(S.RasterXSize-tilesize,size=1)\n",
    "            RY = np.random.randint(S.RasterYSize-tilesize,size=1)\n",
    "            \n",
    "            A = np.transpose(S.ReadAsArray(RX[0], RY[0], tilesize, tilesize))\n",
    "            if np.min(A) > 0.0:\n",
    "                if sb:\n",
    "                    samples.append(np.expand_dims(A[:, :, 1], 3))\n",
    "                else:\n",
    "                    samples.append(A)\n",
    "        \n",
    "    else:\n",
    "        while len(samples) < batchsize:\n",
    "            RX = np.random.randint(S.RasterXSize-tilesize,size=1)\n",
    "            RY = np.random.randint(S.RasterYSize-tilesize,size=1) \n",
    "            \n",
    "            skip_loc = False\n",
    "            months = []\n",
    "            \n",
    "            for m in range(1,13):\n",
    "                S = gdal.Open(filebase + '_' + str(m) + '.vrt')\n",
    "                A = np.transpose(S.ReadAsArray(RX[i], RY[i], tilesize, tilesize))\n",
    "                if np.min(A) == 0.0:\n",
    "                    skip_loc = True\n",
    "                    break\n",
    "                else:\n",
    "                    months.append(A)                \n",
    "            if not skip_loc:\n",
    "                months = np.array(months)\n",
    "                samples.append(months)\n",
    "        \n",
    "    return np.array(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalization_parameters(fn):\n",
    "    S = gdal.Open(fn)\n",
    "    mns = []\n",
    "    sds = []\n",
    "    maxs = []\n",
    "    \n",
    "    for b in range(S.RasterCount):\n",
    "        B = S.GetRasterBand(b+1)\n",
    "        mn, sd = B.ComputeStatistics(1)[2:4]\n",
    "        mns.append(mn)\n",
    "        sds.append(sd)\n",
    "        maxs.append(B.GetMaximum())\n",
    "        \n",
    "    return mns, sds, maxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = '/run/media/ron/silver_small/twelve_months/3d/S1A_IW_GRDH_1SDV_20160325T083601_20160325T083630_010523_00FA23_6F51.tif'\n",
    "stats = normalization_parameters(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ron/.conda/envs/test1/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:2250: UserWarning: Expected no kwargs, you passed 1\n",
      "kwargs passed to function are ignored with Tensorflow backend\n",
      "  warnings.warn('\\n'.join(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1920 samples, validate on 640 samples\n",
      "Epoch 1/300\n",
      "1920/1920 [==============================] - 70s - loss: 265318477974208576.0000 - val_loss: 304.5987\n",
      "Epoch 2/300\n",
      "1920/1920 [==============================] - 58s - loss: 299.3941 - val_loss: 302.0629\n",
      "Epoch 3/300\n",
      "1920/1920 [==============================] - 58s - loss: 293.4423 - val_loss: 291.3308\n",
      "Epoch 4/300\n",
      "1920/1920 [==============================] - 58s - loss: 292.0728 - val_loss: 288.4126\n",
      "Epoch 5/300\n",
      "1920/1920 [==============================] - 58s - loss: 291.3899 - val_loss: 288.7999\n",
      "Epoch 6/300\n",
      "1920/1920 [==============================] - 58s - loss: 291.0850 - val_loss: 288.7780\n",
      "Epoch 7/300\n",
      "1920/1920 [==============================] - 58s - loss: 290.5521 - val_loss: 288.1045\n",
      "Epoch 8/300\n",
      "1920/1920 [==============================] - 58s - loss: 290.6377 - val_loss: 286.5100\n",
      "Epoch 9/300\n",
      "1920/1920 [==============================] - 58s - loss: 290.2498 - val_loss: 288.8387\n",
      "Epoch 10/300\n",
      "1920/1920 [==============================] - 58s - loss: 290.2886 - val_loss: 286.3978\n",
      "Epoch 11/300\n",
      "1920/1920 [==============================] - 58s - loss: 290.2758 - val_loss: 290.5745\n",
      "Epoch 12/300\n",
      "1920/1920 [==============================] - 58s - loss: 289.9717 - val_loss: 287.5093\n",
      "Epoch 13/300\n",
      "1920/1920 [==============================] - 58s - loss: 289.7088 - val_loss: 287.5488\n",
      "Epoch 14/300\n",
      "1920/1920 [==============================] - 58s - loss: 289.8248 - val_loss: 286.8291\n",
      "Epoch 15/300\n",
      "1920/1920 [==============================] - 58s - loss: 289.6291 - val_loss: 297.9162\n",
      "Epoch 16/300\n",
      "1920/1920 [==============================] - 58s - loss: 289.6279 - val_loss: 286.0305\n",
      "Epoch 17/300\n",
      "1920/1920 [==============================] - 58s - loss: 289.4093 - val_loss: 286.9285\n",
      "Epoch 18/300\n",
      "1920/1920 [==============================] - 58s - loss: 289.6079 - val_loss: 286.0171\n",
      "Epoch 19/300\n",
      "1920/1920 [==============================] - 58s - loss: 289.3690 - val_loss: 286.6969\n",
      "Epoch 20/300\n",
      " 240/1920 [==>...........................] - ETA: 47s - loss: 293.3018"
     ]
    }
   ],
   "source": [
    "#reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "#              patience=5, min_lr=0.001)\n",
    "#model.fit(X_train, Y_train, callbacks=[reduce_lr])\n",
    "#reduce_lr = ReduceLROnPlateau(factor=0.1, patience=3, min_lr=0.000001, verbose=1, mode=min)\n",
    "\n",
    "for i in range(4000):\n",
    "    print i\n",
    "    x_train = sample_a_batch(filename, 64*30, 64, sb=False)\n",
    "    x_test = sample_a_batch(filename, 64*10, 64, sb=False)\n",
    "    \n",
    "    for b in range(2):\n",
    "        x_train[:,:,:,b] = x_train[:,:,:,b] / stats[2][b]\n",
    "        x_test[:,:,:,b] = x_test[:,:,:,b] / stats[2][b]\n",
    "#        x_train[:, :, :, b] = (x_train[:, :, :, b] - stats[0][b]) / stats[1][b]\n",
    "#        x_test[:, :, :, b] = (x_test[:, :, :, b] - stats[0][b]) / stats[1][b]       \n",
    "        \n",
    "    vae.fit(x_train,\n",
    "        shuffle=True,\n",
    "        epochs=300,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_test, x_test))#,\n",
    "#        callbacks=[reduce_lr])\n",
    "#    \n",
    "#    vae.fit_generator(datagen,\n",
    "#        shuffle=True,\n",
    "#        epochs=300,\n",
    "#        batch_size=32,\n",
    "#        validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_rows = 4\n",
    "n_cols = 6\n",
    "\n",
    "vistis = x_train\n",
    "\n",
    "fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(16, 12))\n",
    "plt.setp(axes.flat, xticks=[], yticks=[])\n",
    "\n",
    "reconstructed = vae2.predict(vistis, batch_size=batch_size)\n",
    "\n",
    "s = np.random.randint(150)\n",
    "i = s\n",
    "for col in axes.T:\n",
    "    vv = vistis[i,:,:,1]\n",
    "    vh = vistis[i,:,:,0]\n",
    "    vv_rec = reconstructed[i,:,:,1]\n",
    "    vh_rec = reconstructed[i,:,:,0]\n",
    "    \n",
    "    col[0].imshow(vv)\n",
    "    col[1].imshow(vv_rec)#, clim=(0.0, np.max(vv)))\n",
    "    col[2].imshow(vh)\n",
    "    col[3].imshow(vh_rec)#, clim=(0.0, np.max(vh)))\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "\n",
    "#i = 0\n",
    "#for p in predicted[s:][:n_cols]:\n",
    "#    axes.T[i][1].set_title(str(np.argmax(p)))\n",
    "#    axes.T[i][3].set_title(str(np.argmax(p)))\n",
    "#    i += 1\n",
    "    \n",
    "fig.subplots_adjust(bottom=0.05, right=0.95)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=180,\n",
    "    vertical_flip=True,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "train_generator = datagen.flow(\n",
    "        x_train,  # this is the target directory\n",
    "        target_size=(64, 64),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000 // batch_size,\n",
    "        epochs=50,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=800 // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build a model to project inputs on the latent space\n",
    "encoder = Model(x, z_mean)\n",
    "\n",
    "# display a 2D plot of the digit classes in the latent space\n",
    "x_test_encoded = encoder.predict(x_test, batch_size=batch_size)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1])#, c=y_test)\n",
    "#plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build a digit generator that can sample from the learned distribution\n",
    "#decoder_input = Input(shape=(latent_dim,))\n",
    "#_hid_decoded = decoder_hid(decoder_input)\n",
    "#_up_decoded = decoder_upsample(_hid_decoded)\n",
    "#_reshape_decoded = decoder_reshape(_up_decoded)\n",
    "#_deconv_1_decoded = decoder_deconv_1(_reshape_decoded)\n",
    "#_deconv_2_decoded = decoder_deconv_2(_deconv_1_decoded)\n",
    "#_x_decoded_relu = decoder_deconv_3_upsamp(_deconv_2_decoded)\n",
    "#_x_decoded_mean_squash = decoder_mean_squash(_x_decoded_relu)\n",
    "#generator = Model(decoder_input, _x_decoded_mean_squash)\n",
    "decoder_input = Input(shape=(latent_dim,))\n",
    "_hid_decoded = decoder_hid(decoder_input)\n",
    "_up_decoded = decoder_upsample(_hid_decoded)\n",
    "_reshape_decoded = decoder_reshape(_up_decoded)\n",
    "_up_0_decoded = up_0(_reshape_decoded)\n",
    "_deconv_0_decoded = deconv_0(_up_0_decoded)\n",
    "_up_05_decoded = up_05(_deconv_0_decoded)\n",
    "_deconv_1_decoded = deconv_1(_up_05_decoded)\n",
    "_up_1_decoded = up_1(_deconv_1_decoded)\n",
    "_deconv_2_decoded = deconv_2(_up_1_decoded)\n",
    "_up_2_decoded = up_2(_deconv_2_decoded)\n",
    "_deconv_3_decoded = deconv_3(_up_2_decoded)\n",
    "_up_3_decoded = up_3(_deconv_3_decoded)\n",
    "_deconv_4_decoded = deconv_4(_up_3_decoded)\n",
    "_up_4_decoded = up_4(_deconv_4_decoded)\n",
    "_x_decoded_mean_squash = decoder_mean_squash(_up_4_decoded)\n",
    "generator = Model(decoder_input, _x_decoded_mean_squash)\n",
    "\n",
    "# display a 2D manifold of the digits\n",
    "n = 15  # figure with 15x15 digits\n",
    "digit_size = 64\n",
    "figure = np.zeros((digit_size * n, digit_size * n))\n",
    "# linearly spaced coordinates on the unit square were transformed through the inverse CDF (ppf) of the Gaussian\n",
    "# to produce values of the latent variables z, since the prior of the latent space is Gaussian\n",
    "grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "\n",
    "for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "        z_sample = np.array([[xi, yi]])\n",
    "        z_sample = np.tile(z_sample, batch_size).reshape(batch_size, 2)\n",
    "        x_decoded = generator.predict(z_sample, batch_size=batch_size)\n",
    "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "        figure[i * digit_size: (i + 1) * digit_size,\n",
    "               j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure, cmap='Greys_r')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(vae, open( \"vae_9hour_rms_0.001.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
