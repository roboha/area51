{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fn0 = '/home/ron/Downloads/lil_s2.tif'\n",
    "fn1 = '/run/media/ron/silver_small/s2/S2_10.tif'\n",
    "fn2 = '/run/media/ron/silver_small/s2/S2_20.tif'\n",
    "\n",
    "fn3 = '/run/media/ron/silver_small/s2/S2L2A_10.tif'\n",
    "\n",
    "attempt=58\n",
    "\n",
    "num_channels = 4\n",
    "len_edge = 32 # of higher resolution image\n",
    "bs = 16\n",
    "\n",
    "#h_dim = 1000\n",
    "latent_dim = 30 * 30\n",
    "\n",
    "latvisdim = int(np.sqrt(latent_dim))\n",
    "tb_imgs_to_display = 4\n",
    "\n",
    "train_size = 1600\n",
    "valid_size = 64\n",
    "\n",
    "recording_interval = 500\n",
    "epochs = 1000000\n",
    "\n",
    "testlogpath = './vae_logs/test/' + str(attempt)\n",
    "trainlogpath = './vae_logs/train/' + str(attempt)\n",
    "genlogpath = './vae_logs/gen/' + str(attempt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalization_parameters(fn):\n",
    "    from osgeo import gdal\n",
    "    S = gdal.Open(fn)\n",
    "    mns = []\n",
    "    sds = []\n",
    "    maxs = []\n",
    "    \n",
    "    for b in range(S.RasterCount):\n",
    "        B = S.GetRasterBand(b+1)\n",
    "        mn, sd = B.ComputeStatistics(1)[2:4]\n",
    "        mns.append(mn)\n",
    "        sds.append(sd)\n",
    "        maxs.append(B.GetMaximum())\n",
    "        \n",
    "    return([mns, sds, maxs])\n",
    "\n",
    "def sample_1s2(filebase, batchsize, tilesize=128, normalize=False, flattened=False):\n",
    "    import numpy as np\n",
    "    from osgeo import gdal   \n",
    "    \n",
    "    if type(filebase) == str:\n",
    "        multires = False\n",
    "        S2_10 = gdal.Open(filebase)\n",
    "        if normalize:\n",
    "            maxima_10 = np.array(normalization_parameters(filebase)[2])\n",
    "        \n",
    "    elif type(filebase) == list:#interpreted as multiple resolutions\n",
    "        tilesize = tilesize/2\n",
    "        multires = True\n",
    "        S2_10 = gdal.Open(filebase[0])\n",
    "        S2_20 = gdal.Open(filebase[1])\n",
    "        if normalize:\n",
    "            maxima_10 = np.array(normalization_parameters(filebase[0])[2])\n",
    "            maxima_20 = np.array(normalization_parameters(filebase[1])[2])\n",
    "    \n",
    "    samples_10 = []\n",
    "    \n",
    "    if multires:        \n",
    "        samples_20 = []\n",
    "        \n",
    "        while len(samples_10) < batchsize:\n",
    "            RX = np.random.randint(S2_20.RasterXSize-tilesize,size=1)\n",
    "            RY = np.random.randint(S2_20.RasterYSize-tilesize,size=1)\n",
    "            \n",
    "            A_10 = np.transpose(S2_10.ReadAsArray(RX[0] * 2, RY[0] * 2, tilesize * 2, tilesize * 2)).astype(np.float32)\n",
    "            A_20 = np.transpose(S2_20.ReadAsArray(RX[0], RY[0], tilesize, tilesize)).astype(np.float32)\n",
    "            \n",
    "            if (np.min(A_10) > 0) & (np.min(A_20) > 0):\n",
    "                if normalize:\n",
    "                    A_10 = A_10 / maxima_10\n",
    "                    A_20 = A_20 / maxima_20\n",
    "                if flattened:\n",
    "                    A_10 = A_10.flatten()\n",
    "                    A_20 = A_20.flatten()\n",
    "                    \n",
    "                samples_10.append(A_10)\n",
    "                samples_20.append(A_20)\n",
    "                \n",
    "        return([np.array(samples_10), np.array(samples_20)])\n",
    "                \n",
    "    else:\n",
    "        while len(samples_10) < batchsize:\n",
    "            RX = np.random.randint(S2_10.RasterXSize-tilesize,size=1)\n",
    "            RY = np.random.randint(S2_10.RasterYSize-tilesize,size=1)\n",
    "            \n",
    "            A_10 = np.transpose(S2_10.ReadAsArray(RX[0], RY[0], tilesize, tilesize).astype(np.float32))\n",
    "            \n",
    "            if np.min(A_10) > 0:            \n",
    "                if normalize:\n",
    "                    A_10 = A_10 / maxima_10\n",
    "                if flattened:\n",
    "                    A_10 = A_10.flatten()\n",
    "                    \n",
    "                samples_10.append(A_10)\n",
    "                \n",
    "        return(np.array(samples_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_name_dict = {}\n",
    "def layer_name(base_name):\n",
    "    if base_name not in layer_name_dict:\n",
    "        layer_name_dict[base_name] = 0\n",
    "    layer_name_dict[base_name] += 1\n",
    "    name = base_name + str(layer_name_dict[base_name])\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convolute(inp, name, kernel_size = 3, out_chans = 64, sz = 1):\n",
    "    inp_chans = inp.get_shape().as_list()[-1]\n",
    "    with tf.variable_scope(name) as scope:\n",
    "        W = tf.get_variable('weights', [kernel_size, kernel_size, inp_chans, out_chans], initializer=tf.contrib.layers.xavier_initializer_conv2d(), regularizer=tf.contrib.layers.l2_regularizer(0.0005))#, name='weights')\n",
    "        b = tf.get_variable('biases', [out_chans], initializer=tf.constant_initializer(0.0), regularizer=None, dtype=tf.float32)\n",
    "        conv = tf.nn.conv2d(inp, W, strides=[1, sz, sz, 1], padding='SAME')\n",
    "        conv = tf.contrib.layers.batch_norm(conv, scope=scope) # train?\n",
    "        conv = tf.nn.relu(conv+b)\n",
    "#        conv = tf.nn.dropout(conv, 0.8)\n",
    "    return conv\n",
    "\n",
    "def pooling(inp, name, factor=2):\n",
    "    pool = tf.nn.max_pool(inp, ksize=[1, factor, factor, 1], strides=[1, factor, factor, 1], padding='SAME', name=name)\n",
    "    return pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "innest = 256\n",
    "inner = 128\n",
    "middle = 128\n",
    "outer = 64\n",
    "#outest = 16\n",
    "\n",
    "with tf.name_scope('Input'):\n",
    "    X = tf.placeholder(tf.float32, shape=([None, len_edge, len_edge, num_channels]))#bs\n",
    "    if num_channels == 2:\n",
    "        X_show = tf.concat([X, tf.expand_dims(X[:, :, :, 1], 3)], axis=3)\n",
    "        tf.summary.image('input_images', X_show, max_outputs=tb_imgs_to_display)\n",
    "    elif num_channels > 3:\n",
    "        tf.summary.image('input_images', X[:, :, :, 0:3], max_outputs=tb_imgs_to_display)\n",
    "    else:\n",
    "        tf.summary.image('input_images', X, max_outputs=tb_imgs_to_display)\n",
    "\n",
    "dw_h_convs = OrderedDict()\n",
    "up_h_convs = OrderedDict()\n",
    "\n",
    "#Build the network\n",
    "X_go = X\n",
    "\n",
    "X_go = convolute(X, layer_name('conv'), 3, outer, sz = 1)\n",
    "dw_h_convs[0] = convolute(X_go,layer_name('conv'),3,outer,sz = 1)\n",
    "X_go = pooling(dw_h_convs[0], 'pool1')\n",
    "\n",
    "dw_h_convs[1] = convolute(X_go,layer_name('conv'),3,middle)\n",
    "dw_h_convs[1] = convolute(dw_h_convs[1],layer_name('conv'),3,middle)\n",
    "dw_h_convs[2] = pooling(dw_h_convs[1], 'pool2')\n",
    "\n",
    "dw_h_convs[2] = convolute(dw_h_convs[2],layer_name('conv'),3,inner)\n",
    "dw_h_convs[2] = convolute(dw_h_convs[2],layer_name('conv'),3,inner)\n",
    "dw_h_convs[3] = pooling(dw_h_convs[2], 'pool3')\n",
    "\n",
    "dw_h_convs[3] = convolute(dw_h_convs[3],layer_name('conv'),3,innest)\n",
    "dw_h_convs[3] = convolute(dw_h_convs[3],layer_name('conv'),3,innest)\n",
    "dw_h_convs[4] = pooling(dw_h_convs[3], 'pool4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flattened = tf.reshape(dw_h_convs[4], [-1, 2 * 2 * innest])\n",
    "\n",
    "#W_enc = tf.get_variable('W_enc', [4 * 4 * 512, h_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "#b_enc = tf.get_variable('b_enc', [h_dim], initializer=tf.constant_initializer(0.0), regularizer=None, dtype=tf.float32)\n",
    "#full1 = tf.nn.dropout(tf.nn.relu(tf.contrib.layers.batch_norm(tf.matmul(flattened, W_enc) + b_enc)), 0.5)\n",
    "\n",
    "#W_mu = tf.get_variable('W_mu', [h_dim, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "W_mu = tf.get_variable('W_mu', [2 * 2 * innest, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b_mu = tf.get_variable('b_mu', [latent_dim], initializer=tf.constant_initializer(0.0), regularizer=None, dtype=tf.float32)\n",
    "#mu = tf.matmul(full1, W_mu) + b_mu\n",
    "mu = tf.matmul(flattened, W_mu) + b_mu\n",
    "\n",
    "\n",
    "W_logstd = tf.get_variable('W_logstd', [2 * 2 * innest, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "#W_logstd = tf.get_variable('W_logstd', [h_dim, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b_logstd = tf.get_variable('b_logstd', [latent_dim], initializer=tf.constant_initializer(0.0), regularizer=None, dtype=tf.float32)\n",
    "logstd = tf.matmul(flattened, W_logstd) + b_logstd\n",
    "#logstd = tf.matmul(full1, W_logstd) + b_logstd\n",
    "\n",
    "noise = tf.random_normal([1, latent_dim])\n",
    "z = mu + tf.multiply(noise, tf.exp(.5*logstd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_visual = tf.reshape(z, [-1, latvisdim, latvisdim, 1])\n",
    "tf.summary.image('latents', z_visual, max_outputs=tb_imgs_to_display)\n",
    "\n",
    "#W_dec = tf.get_variable('W_dec', [latent_dim, h_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "#b_dec = tf.get_variable('b_dec', [h_dim], initializer=tf.constant_initializer(0.0), regularizer=None, dtype=tf.float32)\n",
    "#full2 = tf.nn.dropout(tf.nn.relu(tf.contrib.layers.batch_norm(tf.matmul(z, W_dec) + b_dec)), 0.5)\n",
    "\n",
    "W_dec2 = tf.get_variable('W_dec2', [latent_dim, 2 * 2 * innest], initializer=tf.contrib.layers.xavier_initializer())\n",
    "#W_dec2 = tf.get_variable('W_dec2', [h_dim, 4 * 4 * inner], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b_dec2 = tf.get_variable('b_dec2', [2 * 2 * innest], initializer=tf.constant_initializer(0.0), regularizer=None, dtype=tf.float32)\n",
    "\n",
    "#full3 = tf.nn.relu(tf.contrib.layers.batch_norm(tf.matmul(full2, W_dec2) + b_dec2))\n",
    "full3 = tf.nn.relu(tf.contrib.layers.batch_norm(tf.matmul(z, W_dec2) + b_dec2))\n",
    "\n",
    "reshaped = tf.reshape(full3, [-1, 2, 2, innest])\n",
    "\n",
    "up_h_convs[0] = tf.image.resize_images(reshaped, [ reshaped.get_shape().as_list()[1]*2, \n",
    "                                                            reshaped.get_shape().as_list()[2]*2] )\n",
    "\n",
    "#up_h_convs[0] = tf.concat([up_h_convs[0], dw_h_convs[3] ],3 ) \n",
    "\n",
    "up_h_convs[0] = convolute(up_h_convs[0], layer_name('conv'), 3, innest)\n",
    "up_h_convs[0] = convolute(up_h_convs[0], layer_name('conv'), 3, innest)\n",
    "up_h_convs[1] = tf.image.resize_images(up_h_convs[0], [ up_h_convs[0].get_shape().as_list()[1]*2, \n",
    "                                                            up_h_convs[0].get_shape().as_list()[2]*2] ) \n",
    "\n",
    "#up_h_convs[1] = tf.concat([up_h_convs[1], dw_h_convs[2] ],3 ) \n",
    "up_h_convs[1] = convolute(up_h_convs[1], layer_name('conv'), 3, inner)\n",
    "up_h_convs[1] = convolute(up_h_convs[1], layer_name('conv'), 3, inner)\n",
    "up_h_convs[2] = tf.image.resize_images(up_h_convs[1], [ up_h_convs[1].get_shape().as_list()[1]*2, \n",
    "                                                            up_h_convs[1].get_shape().as_list()[2]*2] ) \n",
    "\n",
    "#up_h_convs[2] = tf.concat([up_h_convs[2], dw_h_convs[1] ],3 ) \n",
    "up_h_convs[2] = convolute(up_h_convs[2], layer_name('conv'), 3, middle)\n",
    "up_h_convs[2] = convolute(up_h_convs[2], layer_name('conv'), 3, middle)\n",
    "up_h_convs[3] = tf.image.resize_images(up_h_convs[2], [ up_h_convs[2].get_shape().as_list()[2]*2, \n",
    "                                                            up_h_convs[2].get_shape().as_list()[2]*2] ) \n",
    "\n",
    "#up_h_convs[3] = tf.concat([up_h_convs[3], dw_h_convs[0] ],3 ) \n",
    "up_h_convs[3] = convolute(up_h_convs[3], layer_name('conv'), 3, outer)\n",
    "up_h_convs[3] = convolute(up_h_convs[3], layer_name('conv'), 3, outer)\n",
    "\n",
    "W_rec = tf.get_variable('weights_rec', [1, 1, outer, 4], initializer=tf.contrib.layers.xavier_initializer_conv2d(), regularizer=False)#, name='weights')\n",
    "b_rec = tf.get_variable('biases_rec', [4], initializer=tf.constant_initializer(0.0), regularizer=None, dtype=tf.float32)\n",
    "reconstruction = tf.nn.sigmoid(tf.nn.conv2d(up_h_convs[3], W_rec, strides=[1, 1, 1, 1], padding='SAME') + b_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('reconst'):\n",
    "    if num_channels == 2:\n",
    "        r_show = tf.concat([reconstruction, tf.expand_dims(reconstruction[:, :, :, 1], 3)], axis=3)\n",
    "        tf.summary.image('reconstructed_images', r_show, max_outputs=tb_imgs_to_display)\n",
    "    elif num_channels > 3:\n",
    "        tf.summary.image('reconstructed_images', reconstruction[:, :, :, 0:3], max_outputs=tb_imgs_to_display)\n",
    "    else:\n",
    "        tf.summary.image('reconstructed_images', reconstruction, max_outputs=tb_imgs_to_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_z = tf.placeholder(tf.float32, shape=([None, latent_dim]))\n",
    "_up_h_convs = OrderedDict()\n",
    "\n",
    "#_full2 = tf.nn.dropout(tf.nn.relu(tf.contrib.layers.batch_norm(tf.matmul(_z, W_dec) + b_dec)), 0.5)\n",
    "_full3 = tf.nn.relu(tf.contrib.layers.batch_norm(tf.matmul(_z, W_dec2) + b_dec2))\n",
    "_reshaped = tf.reshape(_full3, [-1, 2, 2, innest])\n",
    "\n",
    "_up_h_convs[0] = tf.image.resize_images(_reshaped, [ _reshaped.get_shape().as_list()[1]*2, \n",
    "                                                            _reshaped.get_shape().as_list()[2]*2] )\n",
    "_up_h_convs[0] = convolute(_up_h_convs[0], layer_name('conv'), 3, innest)\n",
    "_up_h_convs[0] = convolute(_up_h_convs[0], layer_name('conv'), 3, innest)\n",
    "\n",
    "_up_h_convs[1] = tf.image.resize_images(_up_h_convs[0], [ _up_h_convs[0].get_shape().as_list()[1]*2, \n",
    "                                                            _up_h_convs[0].get_shape().as_list()[2]*2] ) \n",
    "\n",
    "_up_h_convs[1] = convolute(_up_h_convs[1], layer_name('conv'), 3, inner)\n",
    "_up_h_convs[1] = convolute(_up_h_convs[1], layer_name('conv'), 3, inner)\n",
    "_up_h_convs[2] = tf.image.resize_images(_up_h_convs[1], [ _up_h_convs[1].get_shape().as_list()[1]*2, \n",
    "                                                            _up_h_convs[1].get_shape().as_list()[2]*2] ) \n",
    "\n",
    "_up_h_convs[2] = convolute(_up_h_convs[2], layer_name('conv'), 3, middle)\n",
    "_up_h_convs[2] = convolute(_up_h_convs[2], layer_name('conv'), 3, middle)\n",
    "_up_h_convs[3] = tf.image.resize_images(_up_h_convs[2], [ _up_h_convs[2].get_shape().as_list()[2]*2, \n",
    "                                                            _up_h_convs[2].get_shape().as_list()[2]*2] ) \n",
    "_up_h_convs[3] = convolute(_up_h_convs[3], layer_name('conv'), 3, outer)\n",
    "_up_h_convs[3] = convolute(_up_h_convs[3], layer_name('conv'), 3, outer)\n",
    "\n",
    "_reconstruction = tf.nn.sigmoid(tf.nn.conv2d(_up_h_convs[3], W_rec, strides=[1, 1, 1, 1], padding='SAME') + b_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_flat = tf.contrib.layers.flatten(X)\n",
    "R_flat = tf.contrib.layers.flatten(reconstruction)\n",
    "log_likelihood = tf.reduce_sum(X_flat*tf.log(R_flat + 1e-9)+(1 - X_flat)*tf.log(1 - R_flat + 1e-9), reduction_indices=1)\n",
    "\n",
    "\n",
    "#if multires_filters > 0:\n",
    "#    X2_flat = tf.contrib.layers.flatten(X2)\n",
    "#    R2_flat = tf.contrib.layers.flatten(reconstruction_low)\n",
    "#    \n",
    "#    log_likelihood2 = tf.reduce_sum(X2_flat*tf.log(R2_flat + 1e-9)+(1 - X2_flat)*tf.log(1 - R2_flat + 1e-9), reduction_indices=1)\n",
    "#    log_likelihood = log_likelihood + log_likelihood2\n",
    "\n",
    "#log_likelihood = tf.reduce_sum(X_flat*tf.log(R_flat + 1e-9)+(1 - X_flat)*tf.log(1 - R_flat + 1e-9), reduction_indices=1)\n",
    "tf.summary.scalar('LogLike', tf.reduce_mean(log_likelihood))\n",
    "\n",
    "KL_term = -.5*tf.reduce_sum(1 + 2*logstd - tf.pow(mu,2) - tf.exp(2*logstd), reduction_indices=1)\n",
    "tf.summary.scalar('KL', tf.reduce_mean(KL_term))\n",
    "\n",
    "variational_lower_bound = tf.reduce_mean(log_likelihood - KL_term)\n",
    "tf.summary.scalar('cost', variational_lower_bound)\n",
    "\n",
    "validator = tf.cast(variational_lower_bound, tf.int32) # alibi\n",
    "optimizer = tf.train.AdamOptimizer(1e-4).minimize(-variational_lower_bound)\n",
    "optimizer_likeli = tf.train.AdamOptimizer(1e-4).minimize(-log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_summary = tf.summary.merge_all()\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)\n",
    "saver = tf.train.Saver()\n",
    "train_writer = tf.summary.FileWriter(trainlogpath)\n",
    "valid_writer = tf.summary.FileWriter(testlogpath)\n",
    "#gen_writer = tf.summary.FileWriter(genlogpath)\n",
    "train_writer.add_graph(sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_all = sample_1s2(fn3, train_size, tilesize=len_edge, normalize=True, flattened=False)\n",
    "x_valid = sample_1s2(fn3, valid_size, tilesize=len_edge, normalize=True, flattened=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_all = sample_1s2(fn3, train_size*30, tilesize=len_edge, normalize=True, flattened=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-4c4610b54c99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mvalid_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_summary\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m#    _, s = sess.run([optimizer, merged_summary], feed_dict={X: x1_batch, X2: x2_batch})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "step = bs\n",
    "ep = 0\n",
    "for ep in range(epochs):\n",
    "#    print ep\n",
    "    x_batch = X_all[step-bs:step]\n",
    "#    x1_batch = X1_all[step-bs:step]\n",
    "#    x2_batch = X2_all[step-bs:step]\n",
    "    \n",
    "    if (ep%recording_interval == 0):\n",
    "        vvv, s = sess.run([validator, merged_summary], feed_dict={X: x_valid})\n",
    "#        vvv, s = sess.run([validator, merged_summary], feed_dict={X: X1_valid, X2: X2_valid})\n",
    "        valid_writer.add_summary(s, ep)\n",
    "        \n",
    "    _, s = sess.run([optimizer, merged_summary], feed_dict={X: x_batch})\n",
    "#    _, s = sess.run([optimizer, merged_summary], feed_dict={X: x1_batch, X2: x2_batch})\n",
    "    \n",
    "    if (ep%recording_interval == 0):\n",
    "        train_writer.add_summary(s, ep)\n",
    "        \n",
    "    step += bs\n",
    "    \n",
    "    if step == train_size:\n",
    "        step = bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_mu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_mu = np.random.normal(size=[bs, latent_dim])\n",
    "hi = sess.run([_reconstruction], feed_dict={_z: z_mu})\n",
    "#train_writer.add_summary(s, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f18de84b210>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f18de8a98d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(hi[0][10, :, :, ::-1][:, :, 1:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
