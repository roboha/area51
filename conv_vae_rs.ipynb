{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np #matrix math\n",
    "import math\n",
    "import tensorflow as tf #machine learning\n",
    "import matplotlib.pyplot as plt #plotting\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attempt=6\n",
    "num_channels = 4\n",
    "len_edge = 64\n",
    "bs = 16\n",
    "n_filters = [num_channels, 128, 128, 128, 256, 256]\n",
    "h_dim = 128\n",
    "latent_dim = 10 * 10\n",
    "\n",
    "inedge = len_edge / (2 ** (len(n_filters)-1))\n",
    "latvisdim = int(np.sqrt(latent_dim))\n",
    "tb_imgs_to_display = 4\n",
    "\n",
    "train_size = 3200\n",
    "recording_interval = 1000\n",
    "epochs = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "#mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "\n",
    "#filename = '/run/media/ron/silver_small/twelve_months/3d/S1A_IW_GRDH_1SDV_20160325T083601_20160325T083630_010523_00FA23_6F51.tif'\n",
    "#filename = '/home/ron/Documents/local51/S1A_IW_GRDH_1SDV_20160325T083601_20160325T083630_010523_00FA23_6F51.tif'\n",
    "filename='/media/ramdisk/lil_s2.tif'\n",
    "#filename = '/run/media/ron/silver_small/twelve_months/3d/S1A_IW_GRDH_1SDV_20160325T083601_20160325T083630_010523_00FA23_6F51.tif'\n",
    "#filename='/media/ramdisk/smaller.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_a_batch(filebase, batchsize, tilesize=128, sb=0, normalize=False, flattened=True):\n",
    "    # can sample for spatio-temporal (single_file = False), and spatial-only case (single_file = True).\n",
    "    import numpy as np\n",
    "    from osgeo import gdal\n",
    "    \n",
    "    if '.' in filebase:\n",
    "        single_file = True\n",
    "        S = gdal.Open(filebase)\n",
    "    else:\n",
    "        single_file = False\n",
    "        S = gdal.Open(filebase + '_1.vrt')\n",
    "        \n",
    "    samples = []\n",
    "    \n",
    "    if single_file:\n",
    "        while len(samples) < batchsize:\n",
    "            RX = np.random.randint(S.RasterXSize-tilesize,size=1)\n",
    "            RY = np.random.randint(S.RasterYSize-tilesize,size=1)    \n",
    "            \n",
    "            if sb:\n",
    "                B = S.GetRasterBand(sb)\n",
    "                A = np.transpose(B.ReadAsArray(RX[0], RY[0], tilesize, tilesize), dtype=np.float32)                \n",
    "                #print np.min(A)\n",
    "                if np.min(A) > 0:\n",
    "                    if normalize:\n",
    "                        A = A / normalize[2][sb-1]                        \n",
    "                    A = np.expand_dims(A, 2)                    \n",
    "                    if flattened:\n",
    "                        A = A.flatten()                        \n",
    "                    samples.append(A)\n",
    "            else:\n",
    "                A = np.transpose(S.ReadAsArray(RX[0], RY[0], tilesize, tilesize)).astype(np.float32)\n",
    "                if np.min(A) > 0:\n",
    "                    if normalize:\n",
    "                        for b in range(A.shape[2]):\n",
    "                            A[:, :, b] = A[:, :, b] / float(normalize[2][b])\n",
    "                        if flattened:\n",
    "                            A = A.flatten()\n",
    "                            \n",
    "                        samples.append(A)\n",
    "        \n",
    "    else: # must be overhauled\n",
    "        while len(samples) < batchsize:\n",
    "            RX = np.random.randint(S.RasterXSize-tilesize,size=1)\n",
    "            RY = np.random.randint(S.RasterYSize-tilesize,size=1) \n",
    "            \n",
    "            skip_loc = False\n",
    "            months = []\n",
    "            \n",
    "            for m in range(1,13):\n",
    "                S = gdal.Open(filebase + '_' + str(m) + '.vrt')\n",
    "                A = np.transpose(S.ReadAsArray(RX[i], RY[i], tilesize, tilesize))\n",
    "                if np.min(A) == 0.0:\n",
    "                    skip_loc = True\n",
    "                    break\n",
    "                else:\n",
    "                    months.append(A)                \n",
    "            if not skip_loc:\n",
    "                months = np.array(months)\n",
    "                samples.append(months)\n",
    "        \n",
    "    return np.array(samples)\n",
    "\n",
    "def normalization_parameters(fn):\n",
    "    from osgeo import gdal\n",
    "    S = gdal.Open(fn)\n",
    "    mns = []\n",
    "    sds = []\n",
    "    maxs = []\n",
    "    \n",
    "    for b in range(S.RasterCount):\n",
    "        B = S.GetRasterBand(b+1)\n",
    "        mn, sd = B.ComputeStatistics(1)[2:4]\n",
    "        mns.append(mn)\n",
    "        sds.append(sd)\n",
    "        maxs.append(B.GetMaximum())\n",
    "        \n",
    "    return mns, sds, maxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape, name):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial, name=name)\n",
    "\n",
    "def bias_variable(shape, name):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial, name=name)\n",
    "    \n",
    "def fc_layer(inp, channels_in, channels_out, name='fc'):\n",
    "    with tf.name_scope(name):\n",
    "        w = tf.Variable(tf.zeros([channels_in, channels_out]), name='W')\n",
    "        b = tf.Variable(tf.zeros([channels_out]), name='B')\n",
    "        return tf.nn.relu(tf.matmul(inp, w) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('Input'):\n",
    "    X = tf.placeholder(tf.float32, shape=([None, len_edge, len_edge, num_channels]))#bs\n",
    "    if num_channels == 2:\n",
    "        X_show = tf.concat([X, tf.expand_dims(X[:, :, :, 1], 3)], axis=3)\n",
    "        tf.summary.image('input_images', X_show, max_outputs=tb_imgs_to_display)\n",
    "    elif num_channels > 3:\n",
    "        tf.summary.image('input_images', X[:, :, :, 0:3], max_outputs=tb_imgs_to_display)\n",
    "    else:\n",
    "        tf.summary.image('input_images', X, max_outputs=tb_imgs_to_display)\n",
    "\n",
    "cur_input = X\n",
    "\n",
    "Ws = []    \n",
    "shapes = []\n",
    "\n",
    "for l, n_out in enumerate(n_filters[1:]):\n",
    "    n_input = cur_input.get_shape().as_list()[3]\n",
    "    shapes.append(cur_input.get_shape().as_list())\n",
    "    with tf.name_scope('conv_indecon_' + str(l)):\n",
    "        with tf.variable_scope(str(l)):\n",
    "            W = tf.get_variable('weights', [3, 3, n_input, n_out], initializer=tf.contrib.layers.xavier_initializer_conv2d())#, name='weights')\n",
    "            b = tf.Variable(tf.zeros([n_out]), name='bias')\n",
    "            tf.summary.histogram('weights', W)\n",
    "            tf.summary.histogram('biases', b)\n",
    "            Ws.append(W)\n",
    "            conv = tf.nn.conv2d(cur_input, W, strides=[1, 2, 2, 1], padding='SAME')\n",
    "            act = tf.nn.relu(conv+b)#tf.nn.relu(conv,b)\n",
    "            tf.summary.histogram('activations', act)\n",
    "        cur_input = act\n",
    "\n",
    "with tf.name_scope('Dense'):\n",
    "    with tf.name_scope('Fully_Encode'):\n",
    "        flattened = tf.reshape(cur_input, [-1, inedge * inedge * n_filters[-1]])\n",
    "        W_enc = tf.get_variable('W_enc', [inedge * inedge * n_filters[-1], h_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b_enc = bias_variable([h_dim], 'b_enc')        \n",
    "        full1 = tf.nn.relu(tf.matmul(flattened, W_enc) + b_enc)\n",
    "        tf.summary.histogram('weights', W_enc)\n",
    "        tf.summary.histogram('biases', b_enc)\n",
    "        tf.summary.histogram('activations', full1)\n",
    "    with tf.name_scope('Mu'):\n",
    "        W_mu = tf.get_variable('W_mu', [h_dim, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b_mu = bias_variable([latent_dim], 'b_mu')\n",
    "        mu = tf.matmul(full1, W_mu) + b_mu\n",
    "    with tf.name_scope('Logstd'):\n",
    "        W_logstd = tf.get_variable('W_logstd', [h_dim, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b_logstd = bias_variable([latent_dim], 'b_logstd')\n",
    "        logstd = tf.matmul(full1, W_logstd) + b_logstd\n",
    "    with tf.name_scope('VAE_final'):\n",
    "        noise = tf.random_normal([1, latent_dim])\n",
    "        z = mu + tf.multiply(noise, tf.exp(.5*logstd))\n",
    "    with tf.name_scope('Fully_Decode'):\n",
    "        \n",
    "        W_dec1 = tf.get_variable('W_dec1', [latent_dim, h_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b_dec1 = bias_variable([h_dim], 'b_dec1')\n",
    "        \n",
    "        full2 = tf.nn.relu(tf.matmul(z, W_dec1) + b_dec1)\n",
    "        \n",
    "        tf.summary.histogram('weights_1', W_dec1)\n",
    "        tf.summary.histogram('biases_1', b_dec1)\n",
    "        tf.summary.histogram('activations_1', full2)\n",
    "        \n",
    "        W_dec2 = tf.get_variable('W_dec2', [h_dim, inedge * inedge * n_filters[-1]], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b_dec2 = bias_variable([inedge * inedge * n_filters[-1]], 'b_dec2')\n",
    "        \n",
    "        full3 = tf.nn.relu(tf.matmul(full2, W_dec2) + b_dec2)\n",
    "        \n",
    "        tf.summary.histogram('weights_2', W_dec2)\n",
    "        tf.summary.histogram('biases_2', b_dec2)\n",
    "        tf.summary.histogram('activations_2', full3)\n",
    "        reshaped = tf.reshape(full3, [-1, inedge, inedge, n_filters[-1]])\n",
    "        \n",
    "z_visual = tf.reshape(z, [-1, latvisdim, latvisdim, 1])\n",
    "tf.summary.image('latents', z_visual, max_outputs=tb_imgs_to_display)\n",
    "tf.summary.histogram('Latent', z)\n",
    "\n",
    "Ws.reverse()\n",
    "shapes.reverse()\n",
    "cur_input = reshaped\n",
    "\n",
    "for l, shape in enumerate(shapes):\n",
    "    cur_name = 'deconv' + str(l)  \n",
    "    W = Ws[l]    \n",
    "    with tf.name_scope('conv_indecon_' + str(len(Ws)-(l+1))):\n",
    "        b = tf.Variable(tf.zeros([W.get_shape().as_list()[2]]), name='bias_dec_'+str(l))\n",
    "        dec = tf.nn.conv2d_transpose(cur_input, W, tf.stack([bs, shape[1], shape[2], shape[3]]), strides=[1,2,2,1], padding='SAME')\n",
    "        if l+1 < len(shapes):\n",
    "            act = tf.nn.relu(dec+b)\n",
    "            cur_input = act\n",
    "\n",
    "with tf.name_scope('reconst'):\n",
    "    reconstruction = tf.nn.sigmoid(dec + b)\n",
    "    if num_channels == 2:\n",
    "        r_show = tf.concat([reconstruction, tf.expand_dims(reconstruction[:, :, :, 1], 3)], axis=3)\n",
    "        tf.summary.image('reconstructed_images', r_show, max_outputs=tb_imgs_to_display)\n",
    "    elif num_channels > 3:\n",
    "        tf.summary.image('reconstructed_images', reconstruction[:, :, :, 0:3], max_outputs=tb_imgs_to_display)\n",
    "    else:\n",
    "        tf.summary.image('reconstructed_images', reconstruction, max_outputs=tb_imgs_to_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_flat = tf.contrib.layers.flatten(X)\n",
    "R_flat = tf.contrib.layers.flatten(reconstruction)\n",
    "\n",
    "log_likelihood = tf.reduce_sum(X_flat*tf.log(R_flat + 1e-9)+(1 - X_flat)*tf.log(1 - R_flat + 1e-9), reduction_indices=1)\n",
    "tf.summary.scalar('LogLike', tf.reduce_mean(log_likelihood))\n",
    "\n",
    "KL_term = -.5*tf.reduce_sum(1 + 2*logstd - tf.pow(mu,2) - tf.exp(2*logstd), reduction_indices=1)\n",
    "tf.summary.scalar('KL', tf.reduce_mean(KL_term))\n",
    "\n",
    "variational_lower_bound = tf.reduce_mean(log_likelihood - KL_term)\n",
    "tf.summary.scalar('cost', variational_lower_bound)\n",
    "\n",
    "\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "starter_learning_rate = 0.1\n",
    "learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step, 5000, 0.96, staircase=True)\n",
    "#learning_rate = tf.train.exponential_decay(0.5, )\n",
    "optimizer = tf.train.AdamOptimizer(0.1).minimize(-variational_lower_bound, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged_summary = tf.summary.merge_all()\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)\n",
    "saver = tf.train.Saver()\n",
    "writer = tf.summary.FileWriter('./vae_logs2/' + str(attempt))\n",
    "writer.add_graph(sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stats = normalization_parameters(filename)\n",
    "X_all = sample_a_batch(filename, train_size, len_edge, sb=None, normalize=stats, flattened=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Infinity in summary histogram for: Latent\n\t [[Node: Latent = HistogramSummary[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Latent/tag, Dense/VAE_final/add/_61)]]\n\nCaused by op u'Latent', defined at:\n  File \"/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-9b6c27949897>\", line 74, in <module>\n    tf.summary.histogram('Latent', z)\n  File \"/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/tensorflow/python/summary/summary.py\", line 209, in histogram\n    tag=scope.rstrip('/'), values=values, name=scope)\n  File \"/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/tensorflow/python/ops/gen_logging_ops.py\", line 139, in _histogram_summary\n    name=name)\n  File \"/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Infinity in summary histogram for: Latent\n\t [[Node: Latent = HistogramSummary[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Latent/tag, Dense/VAE_final/add/_61)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b8af299cda6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mx_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_summary\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Infinity in summary histogram for: Latent\n\t [[Node: Latent = HistogramSummary[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Latent/tag, Dense/VAE_final/add/_61)]]\n\nCaused by op u'Latent', defined at:\n  File \"/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-9b6c27949897>\", line 74, in <module>\n    tf.summary.histogram('Latent', z)\n  File \"/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/tensorflow/python/summary/summary.py\", line 209, in histogram\n    tag=scope.rstrip('/'), values=values, name=scope)\n  File \"/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/tensorflow/python/ops/gen_logging_ops.py\", line 139, in _histogram_summary\n    name=name)\n  File \"/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Infinity in summary histogram for: Latent\n\t [[Node: Latent = HistogramSummary[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Latent/tag, Dense/VAE_final/add/_61)]]\n"
     ]
    }
   ],
   "source": [
    "step = bs\n",
    "ep = 0\n",
    "for ep in range(epochs):\n",
    "    x_batch = X_all[step-bs:step]\n",
    "    _, s = sess.run([optimizer, merged_summary], feed_dict={X: x_batch})\n",
    "    step += bs\n",
    "    \n",
    "    if (ep%recording_interval == 0):\n",
    "        writer.add_summary(s, ep)    \n",
    "    if step == train_size:\n",
    "        step = bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_path = saver.save(sess, \"./2nd_save.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#decoder test:\n",
    "Z_to_decode = \n",
    "_full2 = tf.nn.relu(tf.matmul(Z_to_decode, W_dec1) + b_dec1)\n",
    "_full3 = tf.nn.relu(tf.matmul(_full2, W_dec2) + b_dec2)\n",
    "_reshaped = tf.reshape(_full3, [-1, inedge, inedge, n_filters[-1]])\n",
    "\n",
    "_cur_input = _reshaped\n",
    "\n",
    "for l, shape in enumerate(shapes):\n",
    "    W = Ws[l]\n",
    "    _dec = tf.nn.conv2d_transpose(_cur_input, W, tf.stack([bs, shape[1], shape[2], shape[3]]), strides=[1,2,2,1], padding='SAME')\n",
    "    if l+1 < len(shapes):\n",
    "        act = tf.nn.relu(_dec+b)\n",
    "        cur_input = act\n",
    "        \n",
    "_reconstruction = tf.nn.sigmoid(_dec + b)\n",
    "    if num_channels == 2:\n",
    "        r_show = tf.concat([_reconstruction, tf.expand_dims(_reconstruction[:, :, :, 1], 3)], axis=3)\n",
    "        tf.summary.image('reconstructed_images', r_show, max_outputs=tb_imgs_to_display)\n",
    "    elif num_channels > 3:\n",
    "        tf.summary.image('reconstructed_images', _reconstruction[:, :, :, 0:3], max_outputs=tb_imgs_to_display)\n",
    "    else:\n",
    "        tf.summary.image('reconstructed_images', _reconstruction, max_outputs=tb_imgs_to_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IGNORE FOLLOWING CELLS:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pickle\n",
    "cifars = []\n",
    "for i in range(1, 6):\n",
    "    with open('/home/ron/Downloads/cifar-10-batches-py/data_batch_' + str(i), mode='rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        raw_images = data[b'data']\n",
    "        cls = np.array(data[b'labels'])        \n",
    "        raw_float = np.array(raw_images, dtype=float) / 255.0\n",
    "        images = raw_float.reshape([-1, 3, len_edge, len_edge])\n",
    "        images = images.transpose([0, 2, 3, 1])        \n",
    "        cifars = cifars + list(images)        \n",
    "cifars = np.array(cifars)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
