{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fn0 = '/home/ron/Downloads/lil_s2.tif'\n",
    "fn1 = '/run/media/ron/silver_small/s2/S2_10.tif'\n",
    "fn2 = '/run/media/ron/silver_small/s2/S2_20.tif'\n",
    "\n",
    "fn3 = '/run/media/ron/silver_small/s2/S2L2A_10.tif'\n",
    "\n",
    "attempt=67\n",
    "\n",
    "num_channels = 4\n",
    "len_edge = 16 # of higher resolution image\n",
    "bs = 320\n",
    "\n",
    "#h_dim = 1000\n",
    "latent_dim = 30 * 30\n",
    "\n",
    "latvisdim = int(np.sqrt(latent_dim))\n",
    "tb_imgs_to_display = 4\n",
    "\n",
    "train_size = 640\n",
    "valid_size = 320\n",
    "\n",
    "recording_interval = 100\n",
    "epochs = 1000000\n",
    "\n",
    "testlogpath = './vae_logs/test/' + str(attempt)\n",
    "trainlogpath = './vae_logs/train/' + str(attempt)\n",
    "genlogpath = './vae_logs/gen/' + str(attempt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalization_parameters(fn):\n",
    "    from osgeo import gdal\n",
    "    S = gdal.Open(fn)\n",
    "    mns = []\n",
    "    sds = []\n",
    "    maxs = []\n",
    "    \n",
    "    for b in range(S.RasterCount):\n",
    "        B = S.GetRasterBand(b+1)\n",
    "        mn, sd = B.ComputeStatistics(1)[2:4]\n",
    "        mns.append(mn)\n",
    "        sds.append(sd)\n",
    "        maxs.append(B.GetMaximum())\n",
    "        \n",
    "    return([mns, sds, maxs])\n",
    "\n",
    "def sample_1s2(filebase, batchsize, tilesize=128, normalize=False, flattened=False):\n",
    "    import numpy as np\n",
    "    from osgeo import gdal   \n",
    "    \n",
    "    if type(filebase) == str:\n",
    "        multires = False\n",
    "        S2_10 = gdal.Open(filebase)\n",
    "        if normalize:\n",
    "            maxima_10 = np.array(normalization_parameters(filebase)[2])\n",
    "        \n",
    "    elif type(filebase) == list:#interpreted as multiple resolutions\n",
    "        tilesize = tilesize/2\n",
    "        multires = True\n",
    "        S2_10 = gdal.Open(filebase[0])\n",
    "        S2_20 = gdal.Open(filebase[1])\n",
    "        if normalize:\n",
    "            maxima_10 = np.array(normalization_parameters(filebase[0])[2])\n",
    "            maxima_20 = np.array(normalization_parameters(filebase[1])[2])\n",
    "    \n",
    "    samples_10 = []\n",
    "    \n",
    "    if multires:        \n",
    "        samples_20 = []\n",
    "        \n",
    "        while len(samples_10) < batchsize:\n",
    "            RX = np.random.randint(S2_20.RasterXSize-tilesize,size=1)\n",
    "            RY = np.random.randint(S2_20.RasterYSize-tilesize,size=1)\n",
    "            \n",
    "            A_10 = np.transpose(S2_10.ReadAsArray(RX[0] * 2, RY[0] * 2, tilesize * 2, tilesize * 2)).astype(np.float32)\n",
    "            A_20 = np.transpose(S2_20.ReadAsArray(RX[0], RY[0], tilesize, tilesize)).astype(np.float32)\n",
    "            \n",
    "            if (np.min(A_10) > 0) & (np.min(A_20) > 0):\n",
    "                if normalize:\n",
    "                    A_10 = A_10 / maxima_10\n",
    "                    A_20 = A_20 / maxima_20\n",
    "                if flattened:\n",
    "                    A_10 = A_10.flatten()\n",
    "                    A_20 = A_20.flatten()\n",
    "                    \n",
    "                samples_10.append(A_10)\n",
    "                samples_20.append(A_20)\n",
    "                \n",
    "        return([np.array(samples_10), np.array(samples_20)])\n",
    "                \n",
    "    else:\n",
    "        while len(samples_10) < batchsize:\n",
    "            RX = np.random.randint(S2_10.RasterXSize-tilesize,size=1)\n",
    "            RY = np.random.randint(S2_10.RasterYSize-tilesize,size=1)\n",
    "            \n",
    "            A_10 = np.transpose(S2_10.ReadAsArray(RX[0], RY[0], tilesize, tilesize).astype(np.float32))\n",
    "            \n",
    "            if np.min(A_10) > 0:            \n",
    "                if normalize:\n",
    "                    A_10 = A_10 / maxima_10\n",
    "                if flattened:\n",
    "                    A_10 = A_10.flatten()\n",
    "                    \n",
    "                samples_10.append(A_10)\n",
    "                \n",
    "        return(np.array(samples_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_name_dict = {}\n",
    "def layer_name(base_name):\n",
    "    if base_name not in layer_name_dict:\n",
    "        layer_name_dict[base_name] = 0\n",
    "    layer_name_dict[base_name] += 1\n",
    "    name = base_name + str(layer_name_dict[base_name])\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convolute(inp, name, kernel_size = 3, out_chans = 64, sz = 1):\n",
    "    inp_chans = inp.get_shape().as_list()[-1]\n",
    "    with tf.variable_scope(name) as scope:\n",
    "        W = tf.get_variable('weights', [kernel_size, kernel_size, inp_chans, out_chans], initializer=tf.contrib.layers.xavier_initializer_conv2d(), regularizer=tf.contrib.layers.l2_regularizer(0.0005))#, name='weights')\n",
    "        b = tf.get_variable('biases', [out_chans], initializer=tf.constant_initializer(0.0), regularizer=None, dtype=tf.float32)\n",
    "        conv = tf.nn.conv2d(inp, W, strides=[1, sz, sz, 1], padding='SAME')\n",
    "        conv = tf.contrib.layers.batch_norm(conv, scope=scope) # train?\n",
    "        conv = tf.nn.relu(conv+b)\n",
    "#        conv = tf.nn.dropout(conv, 0.8)\n",
    "    return conv\n",
    "\n",
    "def pooling(inp, name, factor=2):\n",
    "    pool = tf.nn.max_pool(inp, ksize=[1, factor, factor, 1], strides=[1, factor, factor, 1], padding='SAME', name=name)\n",
    "    return pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "innest = 256\n",
    "inner = 128\n",
    "middle = 128\n",
    "outer = 64\n",
    "#outest = 16\n",
    "\n",
    "with tf.name_scope('Input'):\n",
    "    X = tf.placeholder(tf.float32, shape=([None, len_edge, len_edge, num_channels]))#bs\n",
    "    if num_channels == 2:\n",
    "        X_show = tf.concat([X, tf.expand_dims(X[:, :, :, 1], 3)], axis=3)\n",
    "        tf.summary.image('input_images', X_show, max_outputs=tb_imgs_to_display)\n",
    "    elif num_channels > 3:\n",
    "        tf.summary.image('input_images', X[:, :, :, 0:3], max_outputs=tb_imgs_to_display)\n",
    "    else:\n",
    "        tf.summary.image('input_images', X, max_outputs=tb_imgs_to_display)\n",
    "\n",
    "dw_h_convs = OrderedDict()\n",
    "up_h_convs = OrderedDict()\n",
    "\n",
    "#Build the network\n",
    "X_go = X\n",
    "\n",
    "X_go = convolute(X, layer_name('conv'), 3, outer, sz = 1)\n",
    "dw_h_convs[0] = convolute(X_go,layer_name('conv'),3,outer,sz = 1)\n",
    "X_go = pooling(dw_h_convs[0], 'pool1')\n",
    "\n",
    "dw_h_convs[1] = convolute(X_go,layer_name('conv'),3,middle)\n",
    "dw_h_convs[1] = convolute(dw_h_convs[1],layer_name('conv'),3,middle)\n",
    "dw_h_convs[2] = pooling(dw_h_convs[1], 'pool2')\n",
    "\n",
    "dw_h_convs[2] = convolute(dw_h_convs[2],layer_name('conv'),3,inner)\n",
    "dw_h_convs[2] = convolute(dw_h_convs[2],layer_name('conv'),3,inner)\n",
    "dw_h_convs[3] = pooling(dw_h_convs[2], 'pool3')\n",
    "\n",
    "dw_h_convs[3] = convolute(dw_h_convs[3],layer_name('conv'),3,innest)\n",
    "dw_h_convs[3] = convolute(dw_h_convs[3],layer_name('conv'),3,innest)\n",
    "dw_h_convs[4] = pooling(dw_h_convs[3], 'pool4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened = tf.reshape(dw_h_convs[4], [-1, 1 * 1 * innest])\n",
    "\n",
    "#W_enc = tf.get_variable('W_enc', [4 * 4 * 512, h_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "#b_enc = tf.get_variable('b_enc', [h_dim], initializer=tf.constant_initializer(0.0), regularizer=None, dtype=tf.float32)\n",
    "#full1 = tf.nn.dropout(tf.nn.relu(tf.contrib.layers.batch_norm(tf.matmul(flattened, W_enc) + b_enc)), 0.5)\n",
    "\n",
    "#W_mu = tf.get_variable('W_mu', [h_dim, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "W_mu = tf.get_variable('W_mu', [1 * 1 * innest, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b_mu = tf.get_variable('b_mu', [latent_dim], initializer=tf.constant_initializer(0.0), regularizer=None, dtype=tf.float32)\n",
    "#mu = tf.matmul(full1, W_mu) + b_mu\n",
    "mu = tf.matmul(flattened, W_mu) + b_mu\n",
    "\n",
    "\n",
    "W_logstd = tf.get_variable('W_logstd', [1 * 1 * innest, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "#W_logstd = tf.get_variable('W_logstd', [h_dim, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b_logstd = tf.get_variable('b_logstd', [latent_dim], initializer=tf.constant_initializer(0.0), regularizer=None, dtype=tf.float32)\n",
    "logstd = tf.matmul(flattened, W_logstd) + b_logstd\n",
    "#logstd = tf.matmul(full1, W_logstd) + b_logstd\n",
    "\n",
    "noise = tf.random_normal([1, latent_dim])\n",
    "z = mu + tf.multiply(noise, tf.exp(.5*logstd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z_visual = tf.reshape(z, [-1, latvisdim, latvisdim, 1])\n",
    "tf.summary.image('latents', z_visual, max_outputs=tb_imgs_to_display)\n",
    "\n",
    "#W_dec = tf.get_variable('W_dec', [latent_dim, h_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "#b_dec = tf.get_variable('b_dec', [h_dim], initializer=tf.constant_initializer(0.0), regularizer=None, dtype=tf.float32)\n",
    "#full2 = tf.nn.dropout(tf.nn.relu(tf.contrib.layers.batch_norm(tf.matmul(z, W_dec) + b_dec)), 0.5)\n",
    "\n",
    "W_dec2 = tf.get_variable('W_dec2', [latent_dim, 1 * 1 * innest], initializer=tf.contrib.layers.xavier_initializer())\n",
    "#W_dec2 = tf.get_variable('W_dec2', [h_dim, 4 * 4 * inner], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b_dec2 = tf.get_variable('b_dec2', [1 * 1 * innest], initializer=tf.constant_initializer(0.0), regularizer=None, dtype=tf.float32)\n",
    "\n",
    "#full3 = tf.nn.relu(tf.contrib.layers.batch_norm(tf.matmul(full2, W_dec2) + b_dec2))\n",
    "full3 = tf.nn.relu(tf.contrib.layers.batch_norm(tf.matmul(z, W_dec2) + b_dec2))\n",
    "\n",
    "reshaped = tf.reshape(full3, [-1, 1, 1, innest])\n",
    "\n",
    "up_h_convs[0] = tf.image.resize_images(reshaped, [ reshaped.get_shape().as_list()[1]*2, \n",
    "                                                            reshaped.get_shape().as_list()[2]*2] )\n",
    "\n",
    "#up_h_convs[0] = tf.concat([up_h_convs[0], dw_h_convs[3] ],3 ) \n",
    "\n",
    "up_h_convs[0] = convolute(up_h_convs[0], layer_name('conv'), 3, innest)\n",
    "up_h_convs[0] = convolute(up_h_convs[0], layer_name('conv'), 3, innest)\n",
    "up_h_convs[1] = tf.image.resize_images(up_h_convs[0], [ up_h_convs[0].get_shape().as_list()[1]*2, \n",
    "                                                            up_h_convs[0].get_shape().as_list()[2]*2] ) \n",
    "\n",
    "#up_h_convs[1] = tf.concat([up_h_convs[1], dw_h_convs[2] ],3 ) \n",
    "up_h_convs[1] = convolute(up_h_convs[1], layer_name('conv'), 3, inner)\n",
    "up_h_convs[1] = convolute(up_h_convs[1], layer_name('conv'), 3, inner)\n",
    "up_h_convs[2] = tf.image.resize_images(up_h_convs[1], [ up_h_convs[1].get_shape().as_list()[1]*2, \n",
    "                                                            up_h_convs[1].get_shape().as_list()[2]*2] ) \n",
    "\n",
    "#up_h_convs[2] = tf.concat([up_h_convs[2], dw_h_convs[1] ],3 ) \n",
    "up_h_convs[2] = convolute(up_h_convs[2], layer_name('conv'), 3, middle)\n",
    "up_h_convs[2] = convolute(up_h_convs[2], layer_name('conv'), 3, middle)\n",
    "up_h_convs[3] = tf.image.resize_images(up_h_convs[2], [ up_h_convs[2].get_shape().as_list()[2]*2, \n",
    "                                                            up_h_convs[2].get_shape().as_list()[2]*2] ) \n",
    "\n",
    "#up_h_convs[3] = tf.concat([up_h_convs[3], dw_h_convs[0] ],3 ) \n",
    "up_h_convs[3] = convolute(up_h_convs[3], layer_name('conv'), 3, outer)\n",
    "up_h_convs[3] = convolute(up_h_convs[3], layer_name('conv'), 3, outer)\n",
    "\n",
    "W_rec = tf.get_variable('weights_rec', [1, 1, outer, 4], initializer=tf.contrib.layers.xavier_initializer_conv2d(), regularizer=False)#, name='weights')\n",
    "b_rec = tf.get_variable('biases_rec', [4], initializer=tf.constant_initializer(0.0), regularizer=None, dtype=tf.float32)\n",
    "reconstruction = tf.nn.sigmoid(tf.nn.conv2d(up_h_convs[3], W_rec, strides=[1, 1, 1, 1], padding='SAME') + b_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('reconst'):\n",
    "    if num_channels == 2:\n",
    "        r_show = tf.concat([reconstruction, tf.expand_dims(reconstruction[:, :, :, 1], 3)], axis=3)\n",
    "        tf.summary.image('reconstructed_images', r_show, max_outputs=tb_imgs_to_display)\n",
    "    elif num_channels > 3:\n",
    "        tf.summary.image('reconstructed_images', reconstruction[:, :, :, 0:3], max_outputs=tb_imgs_to_display)\n",
    "    else:\n",
    "        tf.summary.image('reconstructed_images', reconstruction, max_outputs=tb_imgs_to_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_flat = tf.contrib.layers.flatten(X)\n",
    "R_flat = tf.contrib.layers.flatten(reconstruction)\n",
    "log_likelihood = tf.reduce_sum(X_flat*tf.log(R_flat + 1e-9)+(1 - X_flat)*tf.log(1 - R_flat + 1e-9), reduction_indices=1)\n",
    "\n",
    "\n",
    "#if multires_filters > 0:\n",
    "#    X2_flat = tf.contrib.layers.flatten(X2)\n",
    "#    R2_flat = tf.contrib.layers.flatten(reconstruction_low)\n",
    "#    \n",
    "#    log_likelihood2 = tf.reduce_sum(X2_flat*tf.log(R2_flat + 1e-9)+(1 - X2_flat)*tf.log(1 - R2_flat + 1e-9), reduction_indices=1)\n",
    "#    log_likelihood = log_likelihood + log_likelihood2\n",
    "\n",
    "#log_likelihood = tf.reduce_sum(X_flat*tf.log(R_flat + 1e-9)+(1 - X_flat)*tf.log(1 - R_flat + 1e-9), reduction_indices=1)\n",
    "tf.summary.scalar('LogLike', tf.reduce_mean(log_likelihood))\n",
    "\n",
    "KL_term = -.5*tf.reduce_sum(1 + 2*logstd - tf.pow(mu,2) - tf.exp(2*logstd), reduction_indices=1)\n",
    "tf.summary.scalar('KL', tf.reduce_mean(KL_term))\n",
    "\n",
    "variational_lower_bound = tf.reduce_mean(log_likelihood - KL_term)\n",
    "tf.summary.scalar('cost', variational_lower_bound)\n",
    "\n",
    "validator = tf.cast(variational_lower_bound, tf.int32) # alibi\n",
    "optimizer = tf.train.AdamOptimizer(1e-4).minimize(-variational_lower_bound)\n",
    "optimizer_likeli = tf.train.AdamOptimizer(1e-4).minimize(-log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_z = tf.placeholder(tf.float32, shape=([None, latent_dim]))\n",
    "_up_h_convs = OrderedDict()\n",
    "\n",
    "#_full2 = tf.nn.dropout(tf.nn.relu(tf.contrib.layers.batch_norm(tf.matmul(_z, W_dec) + b_dec)), 0.5)\n",
    "_full3 = tf.nn.relu(tf.contrib.layers.batch_norm(tf.matmul(_z, W_dec2) + b_dec2))\n",
    "_reshaped = tf.reshape(_full3, [-1, 1, 1, innest])\n",
    "\n",
    "_up_h_convs[0] = tf.image.resize_images(_reshaped, [ _reshaped.get_shape().as_list()[1]*2, \n",
    "                                                            _reshaped.get_shape().as_list()[2]*2] )\n",
    "_up_h_convs[0] = convolute(_up_h_convs[0], layer_name('conv'), 3, innest)\n",
    "_up_h_convs[0] = convolute(_up_h_convs[0], layer_name('conv'), 3, innest)\n",
    "\n",
    "_up_h_convs[1] = tf.image.resize_images(_up_h_convs[0], [ _up_h_convs[0].get_shape().as_list()[1]*2, \n",
    "                                                            _up_h_convs[0].get_shape().as_list()[2]*2] ) \n",
    "\n",
    "_up_h_convs[1] = convolute(_up_h_convs[1], layer_name('conv'), 3, inner)\n",
    "_up_h_convs[1] = convolute(_up_h_convs[1], layer_name('conv'), 3, inner)\n",
    "_up_h_convs[2] = tf.image.resize_images(_up_h_convs[1], [ _up_h_convs[1].get_shape().as_list()[1]*2, \n",
    "                                                            _up_h_convs[1].get_shape().as_list()[2]*2] ) \n",
    "\n",
    "_up_h_convs[2] = convolute(_up_h_convs[2], layer_name('conv'), 3, middle)\n",
    "_up_h_convs[2] = convolute(_up_h_convs[2], layer_name('conv'), 3, middle)\n",
    "_up_h_convs[3] = tf.image.resize_images(_up_h_convs[2], [ _up_h_convs[2].get_shape().as_list()[2]*2, \n",
    "                                                            _up_h_convs[2].get_shape().as_list()[2]*2] ) \n",
    "_up_h_convs[3] = convolute(_up_h_convs[3], layer_name('conv'), 3, outer)\n",
    "_up_h_convs[3] = convolute(_up_h_convs[3], layer_name('conv'), 3, outer)\n",
    "\n",
    "_reconstruction = tf.nn.sigmoid(tf.nn.conv2d(_up_h_convs[3], W_rec, strides=[1, 1, 1, 1], padding='SAME') + b_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('reconstt'):\n",
    "    if num_channels == 2:\n",
    "        _r_show = tf.concat([_reconstruction, tf.expand_dims(_reconstruction[:, :, :, 1], 3)], axis=3)\n",
    "        tf.summary.image('gen_images', _r_show, max_outputs=tb_imgs_to_display)\n",
    "    elif num_channels > 3:\n",
    "        tf.summary.image('gen_images', _reconstruction[:, :, :, 0:3], max_outputs=tb_imgs_to_display)\n",
    "    else:\n",
    "        tf.summary.image('gen_images', _reconstruction, max_outputs=tb_imgs_to_display)\n",
    "        \n",
    "with tf.name_scope('reconstt'):\n",
    "    gensum = tf.summary.merge(['gen_images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged_summary = tf.summary.merge_all()\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)\n",
    "saver = tf.train.Saver()\n",
    "train_writer = tf.summary.FileWriter(trainlogpath)\n",
    "valid_writer = tf.summary.FileWriter(testlogpath)\n",
    "#gen_writer = tf.summary.FileWriter(genlogpath)\n",
    "train_writer.add_graph(sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_all = sample_1s2(fn3, train_size, tilesize=len_edge, normalize=True, flattened=False)\n",
    "x_valid = sample_1s2(fn3, valid_size, tilesize=len_edge, normalize=True, flattened=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_all = sample_1s2(fn3, train_size*20, tilesize=len_edge, normalize=True, flattened=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-51fa16f5d7e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mx_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_summary\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mrecording_interval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ron/.conda/envs/tensorflow_latest/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "step = bs\n",
    "ep = 0\n",
    "for ep in range(epochs):\n",
    "#    print ep\n",
    "    x_batch = X_all[step-bs:step]\n",
    "    \n",
    "    _, s = sess.run([optimizer, merged_summary], feed_dict={X: x_batch})\n",
    "    \n",
    "    if (ep%recording_interval == 0):\n",
    "        train_writer.add_summary(s, ep)\n",
    "        vvv, s = sess.run([validator, merged_summary], feed_dict={X: x_valid})\n",
    "        valid_writer.add_summary(s, ep)        \n",
    "#        z_mu = np.random.normal(size=[bs, latent_dim])\n",
    "#        s = sess.run([gensum], feed_dict={_z: z_mu})\n",
    "#        gen_writer.add_summary(s, ep)\n",
    "        \n",
    "    step += bs\n",
    "\n",
    "    if step == train_size:\n",
    "        step = bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z_mu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z_mu = np.random.normal(size=[bs, latent_dim])\n",
    "hi = sess.run([_reconstruction], feed_dict={_z: z_mu})\n",
    "#train_writer.add_summary(s, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6bac0a4d50>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEt5JREFUeJzt3X2MXOV1x/HvmdnZV6/Xb9iAbYJdUVQStQW5iCSIRqWl\nhiKcSvkD2rQQIqGopYUqFSJFaqL+lTRt+holokBKWwRRCTQoggaXJKoqFYpxDMaYgHkJ2BjbsOyu\n931eTv+Ya7S77NrzPHPn2s7z+0irnZ25Z5+zd/bMvXPvPPeYuyMi6Smd7ARE5ORQ8YskSsUvkigV\nv0iiVPwiiVLxiyRKxS+SKBW/SKJU/CKJ6ip0sO4+r/QtD44rdUekaXGfXOwzC45xGlFj1Szutbde\nCl8fjUY5aixvRG4fItZjRAgA9amZ8JjZqaixYj8Q29UV8cc1JoNDarMz1GvVlgYrtPgrfcvZ/PHf\nCY7rPXtVcEy5pxocA/ALle7gmHppImqsd8sDUXEjvWuCYyamlkWNVZ/pj4orVXqDY7pKcdU/8sKr\nwTFjb/w4aqyZ2agw1q3tCY5pjIfn+NZLz7W8rHb7RRLVVvGb2VYz+4mZ7TOz2/NKSkQ6L7r4zawM\nfB24ErgAuM7MLsgrMRHprHa2/BcD+9z9VXefBR4AtuWTloh0WjvFvx54c87P+7P7ROQ00PEDfmZ2\nk5ntMLMdsadXRCR/7RT/AWDjnJ83ZPfN4+53uvsWd99S7u5rYzgRyVM7xf80cJ6ZbTKzbuBa4JF8\n0hKRTov+kI+718zsZuD7QBm4x9335JaZiHRUW5/wc/dHgUdzykVECqRP+IkkSsUvkqhCJ/b0lGHz\nQPi0qLHdrU9WOGbYR4JjAEaXhU8u6RqIO4tR7Qmf/ALQ1VMPjhkcjjvNWvXRqLi1EROr+mcHo8Z6\nbd+h4Jixt8eixnKLK5npWvhzPXBW+IQxK7W+3rXlF0mUil8kUSp+kUSp+EUSpeIXSZSKXyRRKn6R\nRKn4RRKl4hdJlIpfJFEqfpFEqfhFElXoxJ5qo8bh6eHguP1rwydhVJeHtzoC+PnKdHDMmFeixpr0\n8O5AAOOHwtfhoNeixlpWipsQVJoI367MRLSnAhg6J7wV2fLxuL5bM9Xw1mAAIxENpOxA+KSqRrX1\nSV/a8oskSsUvkigVv0ii2mnXtdHMfmhmL5jZHjO7Jc/ERKSz2jngVwM+7+47zWwQeMbMtrv7Cznl\nJiIdFL3ld/eD7r4zu30U2IvadYmcNnJ5z29m5wIXAk8t8tj77bpqs3GnSUQkf20Xv5ktA74D3Oru\nHzghP7ddV1d3T7vDiUhO2ip+M6vQLPz73P2hfFISkSK0c7TfgLuBve7+tfxSEpEitLPl/zjwe8Cv\nmdmu7OuqnPISkQ5rp1Hn/wDhHS5E5JSgT/iJJKrQWX3uxsxs+Ay4Wm/4a9TUy68FxwA8PTMeHFMv\nx83qK68Kn40G0Bexv1UZinuqaysbUXFdETMdp/e/GzXW8KHZ8LHqsWee4mZilnvCZ1WWI/6vmofi\nWqMtv0iiVPwiiVLxiyRKxS+SKBW/SKJU/CKJUvGLJErFL5IoFb9IolT8IolS8YskSsUvkqhiJ/bU\ny1SPDgXHra6ET7aZnoxrTzXdiGjjFDFpA6BvRdxr71A5/FqI/RY31sSKuLZWU4PhOXZ3x80QXxkx\n12ZkuPW2VnPVx0ai4mq18PVfWrYsfKBS6y2+tOUXSZSKXyRRKn6RROVx6e6ymf3YzL6XR0IiUow8\ntvy30OzWIyKnkXav278B+C3grnzSEZGitLvl/1vgNiDuQm8ictK007TjauCwuz9zguXe79VXr07F\nDiciOWu3acc1ZvY68ADN5h3/tnChub36ypW+NoYTkTy106L7C+6+wd3PBa4FfuDun84tMxHpKJ3n\nF0lULp/td/cfAT/K43eJSDG05RdJVLGz+hoNZqYnguPOq4YfKOyu9AbHAEzPhs/2Gh+N7Fd6OC7H\nye7wHH0wbnbe0Ym4uNmIP23Zmrj2ZZMj4f/G1Ubcum/UwmcrAvh4eEuxgc2DwTGlrsOtLxv820Xk\nZ4KKXyRRKn6RRKn4RRKl4hdJlIpfJFEqfpFEqfhFEqXiF0mUil8kUSp+kUSp+EUSpeIXSVSxs/q8\nQX32aHDce1PhMwG7G3H980amwmfMlXvjZqOd2RcXV7VKcMxgI242mlXirs1aq4XPdOw/Grc+pg/2\nBMfUJ9ZFjVUpRTQGBOq194JjVncvD475qbW+DrXlF0mUil8kUe027VhhZg+a2YtmttfMPppXYiLS\nWe2+5/874D/d/VNm1g3055CTiBQguvjNbAi4DLgBwN1ngfBrFYnISdHObv8m4AjwraxL711mNpBT\nXiLSYe0UfxdwEfANd78QmABuX7jQvHZd9ek2hhORPLVT/PuB/e7+VPbzgzRfDOaZ166rHHfFVBHJ\nXzvtut4G3jSz87O7LgdeyCUrEem4do/2/xFwX3ak/1XgM+2nJCJFaKv43X0XsCWnXESkQPqEn0ii\nCp3YU2/UODo1Ehw3NPjh8LFmXw+OASjNvBMcM7gmbrLHpnM2RsUdqgwHx/T3hE+OAlg2GLd96OkJ\nj7NGeFs2gJmh8LNIy3rDJwMB9JZWR8WNT4dPkOq3qeCYEq2Poy2/SKJU/CKJUvGLJErFL5IoFb9I\nolT8IolS8YskSsUvkigVv0iiVPwiiVLxiyRKxS+SKBW/SKKKbdfVqFGdPBwcN1a7NDhm3WDcJcOG\nquExfWvirlg+dM7ZUXGsDL9O6lQpfLYiQGN4VVTc7LvhMf5W1FDUI9q5lUprosbqtbiZh5Mevv5n\nxj04xgMmD2rLL5IoFb9Iotpt1/UnZrbHzJ43s/vNTJfnFTlNRBe/ma0H/hjY4u4fAcrAtXklJiKd\n1e5ufxfQZ2ZdNPv0RR6yEZGitXPd/gPAXwFvAAeBUXd/PK/ERKSz2tntXwlso9mz72xgwMw+vchy\n77fr8kYtPlMRyVU7u/2/Drzm7kfcvQo8BHxs4UJz23VZqdCPFYjIcbRT/G8Al5hZv5kZzXZde/NJ\nS0Q6rZ33/E/RbM65E9id/a47c8pLRDqs3XZdXwS+mFMuIlIgfcJPJFEqfpFEFXz4vU69djQ4amz4\nUHBM78BkcAzAqr7Z4JhaX1wfvGk7GBXXT3gPt+pseAzA4bdGo+JG91hwTHViPGqsashUtkytHNdz\nb2rmvai4roh2jtMRZ8YbARMBteUXSZSKXyRRKn6RRKn4RRKl4hdJlIpfJFEqfpFEqfhFEqXiF0mU\nil8kUSp+kUSp+EUSVfx1tUrhLYiqI7uDY3wgfLIHQHmoHBxjtbjX0J5a+FgAk0emg2NGJsInLAFM\nDdej4mr18L9tZCZugpSXw9d/afBI1FjVo+HrHmD1GeEtLUanKsEx9UbrE6q05RdJlIpfJFEnLH4z\nu8fMDpvZ83PuW2Vm283s5ez7ys6mKSJ5a2XL/8/A1gX33Q484e7nAU9kP4vIaeSExe/u/w0ML7h7\nG3Bvdvte4JM55yUiHRb7nn+dux+7BtXbwLqc8hGRgrR9qs/d3cyWPH9nZjcBNwGoY4/IqSN2y3/I\nzM4CyL4fXmrB+e264s5ri0j+Yov/EeD67Pb1wHfzSUdEitLKqb77gf8Fzjez/Wb2WeDLwG+Y2cs0\nG3Z+ubNpikjeTvgm3N2vW+Khy3PORUQKpE/4iSRKxS+SqELPvTlQJbyNU8OrwTFT5ZngGIB3unrC\ng8p9UWOVjkSMBVSmfyU4xrrjnuq1lbgWWqNDbwXHTEwtixprciJ8NuAKj2vnNlGPmy3qM6uCY476\nu8Ex9Ubr+WnLL5IoFb9IolT8IolS8YskSsUvkigVv0iiVPwiiVLxiyRKxS+SKBW/SKJU/CKJUvGL\nJKrgi+pVwNcGR5VWhI80HjGBCKB2+MzgmC5fHzXW8MzZUXF95U3BMQP9b0SNdWTi9ai4uoVPxpo9\nVIsaa3o8/PJwB2qjUWPNRLZmq4/2B8dUloevQ/fW2+Fpyy+SKBW/SKJU/CKJiu3V91Uze9HMnjOz\nh80s4l25iJxMsb36tgMfcfdfBF4CvpBzXiLSYVG9+tz9cXc/dmj2SWBDB3ITkQ7K4z3/jcBjSz1o\nZjeZ2Q4z2+GN8FMXItIZbRW/md0B1ID7llpmfruuSjvDiUiOoj/kY2Y3AFcDl3vIJwtE5JQQVfxm\nthW4DfhV98hrIIvISRXbq+8fgUFgu5ntMrNvdjhPEclZbK++uzuQi4gUSJ/wE0lUsbP6rEy5O7xt\nUXnyzfCY2cHgGAAbfyc4Zs1Q+KwygKmJsai44dprwTGlyfeixlpRjTukY1Ph7dIqk7NRY5VmwmcD\nTtamo8aq+1BUHNXw7exAJXwmoFnr42jLL5IoFb9IolT8IolS8YskSsUvkigVv0iiVPwiiVLxiyRK\nxS+SKBW/SKJU/CKJUvGLJErFL5KoQmf1dVXKrFofPivqQ/19wTHVo8MnXmgR0x4++63U3xs1loW3\nBQTAxw8Hx9StETXWyEzc9sEmwuNK5fDnGWBgMLxtROPoSNRY5ca6qLgzVq8Jjulauyw4Zvjt1nsy\nassvkigVv0iiotp1zXns82bmZha+TyMiJ1Vsuy7MbCNwBRDX+F1ETqqodl2Zv6F5+W5ds1/kNBT1\nnt/MtgEH3P3ZFpZ9v11XoxZ+XTcR6YzgU31m1g/8Gc1d/hNy9zuBOwG6B1ZrL0HkFBGz5f85YBPw\nrJm9TrND706z2LPWInIyBG/53X03sPbYz9kLwBZ3D7/mtYicNLHtukTkNBfbrmvu4+fmlo2IFEaf\n8BNJVKETexr1WSaGw1tvvVqpB8fMjo0GxwD0DG0Ijumy8AkYANW4bl1MjYVPJPJqT9RYXdVqXNxM\neOutrlJ42y2AUn0iOKbmFjVWozcubqIn/JDYqrNWhg+0t/X8tOUXSZSKXyRRKn6RRKn4RRKl4hdJ\nlIpfJFEqfpFEqfhFEqXiF0mUil8kUSp+kUSp+EUSpeIXSZS5F3dZPTM7Avx0iYfXAKfC1YCUx3zK\nY75TPY8PufsZrfyCQov/eMxsh7tvUR7KQ3kUk4d2+0USpeIXSdSpVPx3nuwEMspjPuUx389MHqfM\ne34RKdaptOUXkQIVWvxmttXMfmJm+8zs9kUe7zGzb2ePP2Vm53Ygh41m9kMze8HM9pjZLYss8wkz\nGzWzXdnXn+edx5yxXjez3dk4OxZ53Mzs77N18pyZXZTz+OfP+Tt3mdmYmd26YJmOrY/FWsCb2Soz\n225mL2ffF72SpZldny3zspld34E8vmpmL2br/WEzW7FE7HGfwxzy+JKZHZiz/q9aIva49fUB7l7I\nF1AGXgE2A93As8AFC5b5A+Cb2e1rgW93II+zgIuy24PAS4vk8QngewWtl9eBNcd5/CrgMcCAS4Cn\nOvwcvU3zXHEh6wO4DLgIeH7OfX8J3J7dvh34yiJxq4BXs+8rs9src87jCqAru/2VxfJo5TnMIY8v\nAX/awnN33Ppa+FXklv9iYJ+7v+rus8ADwLYFy2wD7s1uPwhcbmZx10pegrsfdPed2e2jwF5gfZ5j\n5Gwb8C/e9CSwwszO6tBYlwOvuPtSH8TKnS/eAn7u/8G9wCcXCf1NYLu7D7v7e8B2YGueebj74+5+\n7HriT9LsS9lRS6yPVrRSX/MUWfzrgbkX7d/PB4vu/WWylT4KrO5UQtnbiguBpxZ5+KNm9qyZPWZm\nH+5UDoADj5vZM2Z20yKPt7Le8nItcP8SjxW1PgDWufvB7PbbwLpFlilyvQDcSHMPbDEneg7zcHP2\n9uOeJd4GBa+PZA/4mdky4DvAre6+sH3GTpq7vr8E/APwHx1M5VJ3vwi4EvhDM7usg2Mtycy6gWuA\nf1/k4SLXxzze3Kc9qaekzOwOoAbct8QinX4Ov0GzO/YvAweBv87jlxZZ/AeAjXN+3pDdt+gyZtYF\nDAHv5p2ImVVoFv597v7Qwsfdfczdx7PbjwIVM1uTdx7Z7z+QfT8MPExz922uVtZbHq4Edrr7oUVy\nLGx9ZA4de2uTfT+8yDKFrBczuwG4Gvjd7IXoA1p4Dtvi7ofcve7uDeCflvj9weujyOJ/GjjPzDZl\nW5lrgUcWLPMIcOyo7aeAHyy1wmNlxxDuBva6+9eWWObMY8cazOximuupEy9CA2Y2eOw2zQNMzy9Y\n7BHg97Oj/pcAo3N2ifN0HUvs8he1PuaY+39wPfDdRZb5PnCFma3MdoOvyO7LjZltBW4DrnH3ySWW\naeU5bDePucd4fnuJ399Kfc2XxxHKgCOZV9E8uv4KcEd231/QXLkAvTR3O/cB/wds7kAOl9LcjXwO\n2JV9XQV8DvhctszNwB6aR0yfBD7WofWxORvj2Wy8Y+tkbi4GfD1bZ7uBLR3IY4BmMQ/Nua+Q9UHz\nBecgUKX5PvWzNI/zPAG8DPwXsCpbdgtw15zYG7P/lX3AZzqQxz6a76OP/Z8cOxN1NvDo8Z7DnPP4\n1+y5f45mQZ+1MI+l6ut4X/qEn0iikj3gJ5I6Fb9IolT8IolS8YskSsUvkigVv0iiVPwiiVLxiyTq\n/wHRdH8c8JRB9QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6bac103f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(hi[0][8, :, :, ::-1][:, :, 1:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
